---
title: The Physics of Wall Street (James Owen Weatherall)
author: E
date: '2017-08-17'
summaryOn: true
summary: 'Hola, this is el summary'
categories: []
tags:
  - books
  - review
showDate: no
draft: yes
---


*Simons created Renaissance’s signature fund in 1988, with another mathematician named James Ax. They called it Medallion, after the prestigious mathematics prizes that Ax and Simons had won in the sixties and seventies. Over the next decade, the fund earned an unparalleled 2,478.6% return, blowing every other hedge fund in the world out of the water. To give a sense of how extraordinary this is, George Soros’s Quantum Fund, the next most successful fund during this time, earned a mere 1,710.1% over the same period. Medallion’s success didn’t let up in the next decade, either — over the lifetime of the fund, Medallion’s returns have averaged almost 40% a year, after fees that are twice as high as the industry average. (Compare this to Berkshire Hathaway, which averaged a 20% return from when Buffett turned it into an investment firm in 1967 until 2010.) Today Simons is one of the wealthiest men in the world. According to the 2011 Forbes ranking, his net worth is $10.6 billion, a figure that puts Simons’s checking account in the same range as that of some high-powered investment firms.*  

- Page 3 (location ~ 39-47)    

*Hedge funds are supposed to work by creating counterbalanced portfolios. The simplest version of the idea is to buy one asset while simultaneously selling another asset as a kind of insurance policy. Often, one of these assets is what is known as a derivative. Derivatives are contracts based on some other kind of security, such as stocks, bonds, or commodities. For instance, one kind of derivative is called a futures contract. If you buy a futures contract on, say, grain, you are agreeing to buy the grain at some fixed future time, for a price that you settle on now. The value of a grain future depends on the value of grain — if the price of grain goes up, then the value of your grain futures should go up too, since the price of buying grain and holding it for a while should also go up. If grain prices drop, however, you may be stuck with a contract that commits you to paying more than the market price of grain when the futures contract expires. In many cases (though not all), there is no actual grain exchanged when the contract expires; instead, you simply exchange cash corresponding to the discrepancy between the price you agreed to pay and the current market price. Derivatives have gotten a lot of attention recently, most of it negative. But they aren’t new. They have been around for at least four thousand years, as testified by clay tablets found in ancient Mesopotamia (modern-day Iraq) that recorded early futures contracts.*  

- Page 4 (location ~ 54-64)    

*The funds’ strategies were calibrated so that no matter what happened, they would eke out a small profit — with virtually no chance of significant loss. Or at least, that was how they were supposed to work. But when markets opened on Monday, August 6, 2007, all hell broke loose. The hedge fund portfolios that were designed to make money, no matter what, tanked. The positions that were supposed to go up all went down. Bizarrely, the positions that were supposed to go up if everything else went down also went down. Essentially all of the major quant funds were hit, hard. Every strategy they used was suddenly vulnerable, whether in stocks, bonds, currency, or commodities. Millions of dollars started flying out the door. As the week progressed, the strange crisis worsened. Despite their training and expertise, none of the traders at the quant funds had any idea what was going on. By Wednesday matters were desperate. One large fund at Morgan Stanley, called Process Driven Trading, lost $300 million that day alone. Another fund, Applied Quantitative Research Capital Management, lost $500 million. An enormous, highly secretive Goldman Sachs fund called Global Alpha was down $1.5 billion on the month so far. The Dow Jones, meanwhile, went up 150 points, since the stocks that the quant funds had bet against all rallied. Something had gone terribly, terribly wrong.*  

- Page 6 (location ~ 80-90)    

*I began thinking about this book during the fall of 2008. In the year since the quant crisis, the U.S. economy had entered a death spiral, with century-old investment banks like Bear Stearns and Lehman Brothers imploding as markets collapsed. Like many other people, I was captivated by the news of the meltdown. I read about it obsessively. One thing in particular about the coverage jumped out at me. In article after article, I came across the legions of quants: physicists and mathematicians who had come to Wall Street and changed it forever. The implication was clear: physicists on Wall Street were responsible for the collapse. Like Icarus, they had flown too high and fallen. Their waxen wings were “complex mathematical models” imported from physics — tools that promised unlimited wealth in the halls of academia, but that melted when faced with the real-life vicissitudes of Wall Street. Now we were all paying the price.*  

- Page 7 (location ~ 101-107)    

*So I started digging. As a physicist, I figured I would start by tracking down the people who first came up with the idea that physics could be used to understand markets. I wanted to know what the connections between physics and finance were supposed to be, but I also wanted to know how the ideas had taken hold, how physicists had come to be a force on the Street. The story I uncovered took me from turn-of-the-century Paris to government labs during World War II, from blackjack tables in Las Vegas to Yippie communes on the Pacific coast. The connections between physics and modern financial theory — and economics more broadly — run surprisingly deep. This book tells the story of physicists in finance. The recent crisis is part of the story, but in many ways it’s a minor part. This is not a book about the meltdown. There have been many of those, some even focusing on the role that quants played and how the crisis affected them. This book is about something bigger. It is about how the quants came to be, and about how to understand the “complex mathematical models” that have become central to modern finance. Even more importantly, it is a book about the future of finance. It’s about why we should look to new ideas from physics and related fields to solve the ongoing economic problems faced by countries around the world. It’s a story that should change how we think about economic policy forever.*  

- Page 8 (location ~ 120-130)    

*There’s one shop in New York that remembers its roots. It’s Renaissance, the financial management firm that doesn’t hire finance experts. The year 2008 hammered a lot of banks and funds. In addition to Bear Stearns and Lehman Brothers, the insurance giant AIG as well as dozens of hedge funds and hundreds of banks either shut down or teetered at the precipice, including quant fund behemoths worth tens of billions of dollars like Citadel Investment Group. Even the traditionalists suffered: Berkshire Hathaway faced its largest loss ever, of about 10% book value per share — while the shares themselves halved in value. But not everyone was a loser for the year. Meanwhile, Jim Simons’s Medallion Fund earned 80%, even as the financial industry collapsed around him. The physicists must be doing something right.*  

- Page 10 (location ~ 140-145)    

*Just a few blocks east from the Palais Garnier lay the beating heart of the French empire: the Paris Bourse, the capital’s principal financial exchange. It was housed in a palace built by Napoleon as a temple to money, the Palais Brongniart. Its outside steps were flanked by statues of its idols: Justice, Commerce, Agriculture, Industry. Majestic neoclassical columns guarded its doors. Inside, its cavernous main hall was large enough to fit hundreds of brokers and staff members. For an hour each day they met beneath ornately carved reliefs and a massive skylight to trade the permanent government bonds, called rentes, that had funded France’s global ambitions for a century. Imperial and imposing, it was the center of the city at the center of the world. Or so it would have seemed to Louis Bachelier as he approached it for the first time, in 1892. He was in his early twenties, an orphan from the provinces. He had just arrived in Paris, fresh from his mandatory military service, to resume his education at the University of Paris.*  

- Page 10 (location ~ 152-159)    

*He repeated the mantra — just an elaborate game of chance — as he pushed forward into the throng. “Who is this guy?” Paul Samuelson asked himself, for the second time in as many minutes. He was sitting in his office, in the economics department at MIT. The year was 1955, or thereabouts. Laid out in front of him was a half-century-old PhD dissertation, written by a Frenchman whom Samuelson was quite sure he had never heard of. Bachelor, Bacheler. Something like that. He looked at the front of the document again. Louis Bachelier. It didn’t ring any bells. Its author’s anonymity notwithstanding, the document open on Samuelson’s desk was astounding. Here, fifty-five years previously, Bachelier had laid out the mathematics of financial markets. Samuelson’s first thought was that his own work on the subject over the past several years — the work that was supposed to form one of his students’ dissertation — had lost its claim to originality. But it was more striking even than that. By 1900, this Bachelier character had apparently worked out much of the mathematics that Samuelson and his students were only now adapting for use in economics — mathematics that Samuelson thought had been developed far more recently, by mathematicians whose names Samuelson knew by heart because they were tied to the concepts they had supposedly invented. Weiner processes. Kolmogorov’s equations. Doob’s martingales. Samuelson thought this was cutting-edge stuff, twenty years old at the most. But there it all was, in Bachelier’s thesis. How come Samuelson had never heard of him? Samuelson’s interest in Bachelier had begun*  

- Page 12 (location ~ 171-183)    

*He repeated the mantra — just an elaborate game of chance — as he pushed forward into the throng. “Who is this guy?” Paul Samuelson asked himself, for the second time in as many minutes. He was sitting in his office, in the economics department at MIT. The year was 1955, or thereabouts. Laid out in front of him was a half-century-old PhD dissertation, written by a Frenchman whom Samuelson was quite sure he had never heard of. Bachelor, Bacheler. Something like that. He looked at the front of the document again. Louis Bachelier. It didn’t ring any bells. Its author’s anonymity notwithstanding, the document open on Samuelson’s desk was astounding. Here, fifty-five years previously, Bachelier had laid out the mathematics of financial markets. Samuelson’s first thought was that his own work on the subject over the past several years — the work that was supposed to form one of his students’ dissertation — had lost its claim to originality. But it was more striking even than that. By 1900, this Bachelier character had apparently worked out much of the mathematics that Samuelson and his students were only now adapting for use in economics — mathematics that Samuelson thought had been developed far more recently, by mathematicians whose names Samuelson knew by heart because they were tied to the concepts they had supposedly invented. Weiner processes. Kolmogorov’s equations. Doob’s martingales. Samuelson thought this was cutting-edge stuff, twenty years old at the most. But there it all was, in Bachelier’s thesis. How come Samuelson had never heard of him? Samuelson’s interest in Bachelier had begun a few days before, when he received a postcard from his friend Leonard “Jimmie” Savage, then a professor of statistics at the University of Chicago. Savage had just finished writing a textbook on probability and statistics and had developed an interest in the history of probability theory along the way. He had been poking around the university library for early-twentieth-century work on probability when he came across a textbook from 1914 that he had never seen before. When he flipped through it, Savage realized that, in addition to some pioneering work on probability, the book had a few chapters dedicated to what the author called “speculation” — literally, probability theory as applied to market speculation. Savage guessed (correctly) that if he had never come across this work before, his friends in economics departments likely hadn’t either, and so he sent out a series of postcards asking if anyone knew of Bachelier.*  

- Page 12 (location ~ 171-189)    

*Gambling during the Middle Ages and the Renaissance was built around a rough notion of odds and payoffs, similar to how modern horseraces are constructed. If you were a bookie offering someone a bet, you might advertise odds in the form of a pair of numbers, such as “10 to 1” or “3 to 2,” which would reflect how unlikely the thing you were betting on was. (Odds of 10 to 1 would mean that if you bet 1 dollar, or pound, or guilder, and you won, you would receive 10 dollars, pounds, or guilders in winnings, plus your original bet; if you lost, you would lose the dollar, etc.) But these numbers were based largely on a bookie’s gut feeling about how the bet would turn out. Cardano believed there was a more rigorous way to understand betting, at least for some simple games. In the spirit of his times, he wanted to bring modern mathematics to bear on his favorite subject. In 1526, while still in his twenties, Cardano wrote a book that outlined the first attempts at a systematic theory of probability. He focused on games involving dice. His basic insight was that, if one assumed a die was just as likely to land with one face showing as another, one could work out the precise likelihoods of all sorts of combinations occurring, essentially by counting. So, for instance, there are six possible outcomes of rolling a standard die; there is precisely one way in which to yield the number 5. So the mathematical odds of yielding a 5 are 1 in 6 (corresponding to betting odds of 5 to 1). But what about yielding a sum of 10 if you roll two dice? There are 6 × 6 = 36 possible outcomes, of which 3 correspond to a sum of 10. So the odds of yielding a sum of 10 are 3 in 36 (corresponding to betting odds of 33 to*  

- Page 13 (location ~ 197-209)    

*Gambling during the Middle Ages and the Renaissance was built around a rough notion of odds and payoffs, similar to how modern horseraces are constructed. If you were a bookie offering someone a bet, you might advertise odds in the form of a pair of numbers, such as “10 to 1” or “3 to 2,” which would reflect how unlikely the thing you were betting on was. (Odds of 10 to 1 would mean that if you bet 1 dollar, or pound, or guilder, and you won, you would receive 10 dollars, pounds, or guilders in winnings, plus your original bet; if you lost, you would lose the dollar, etc.) But these numbers were based largely on a bookie’s gut feeling about how the bet would turn out. Cardano believed there was a more rigorous way to understand betting, at least for some simple games. In the spirit of his times, he wanted to bring modern mathematics to bear on his favorite subject. In 1526, while still in his twenties, Cardano wrote a book that outlined the first attempts at a systematic theory of probability. He focused on games involving dice. His basic insight was that, if one assumed a die was just as likely to land with one face showing as another, one could work out the precise likelihoods of all sorts of combinations occurring, essentially by counting. So, for instance, there are six possible outcomes of rolling a standard die; there is precisely one way in which to yield the number 5. So the mathematical odds of yielding a 5 are 1 in 6 (corresponding to betting odds of 5 to 1). But what about yielding a sum of 10 if you roll two dice? There are 6 × 6 = 36 possible outcomes, of which 3 correspond to a sum of 10. So the odds of yielding a sum of 10 are 3 in 36 (corresponding to betting odds of 33 to 3).*  

- Page 13 (location ~ 197-209)    

*One of the things that Pascal and Fermat’s correspondence produced was a way of precisely calculating the odds of winning dice bets of the sort that gave de Méré trouble. (Cardano’s system also accounted for this kind of dice game, but no one knew about it when de Méré became interested in these questions.) They were able to show that de Méré’s first strategy was good because the chance that you would roll a 6 if you rolled a die four times was slightly better than 50% — more like 51.7747%. De Méré’s second strategy, though, wasn’t so great because the chance that you would roll a pair of 6s if you rolled two dice twenty-four times was only about 49.14%, less than 50%. This meant that the second strategy was slightly less likely to win than to lose, whereas de Méré’s first strategy was slightly more likely to win. De Méré was thrilled to incorporate the insights of the two great mathematicians, and from then on he stuck with his first strategy.*  

- Page 16 (location ~ 234-240)    

*So what do probabilities tell us, if they don’t guarantee anything about how often something is going to happen? If de Méré had thought to ask this question, he would have had to wait a long time for an answer. Half a century, in fact. The first person who figured out how to think about the relationship between probabilities and the frequency of events was a Swiss mathematician named Jacob Bernoulli, shortly before his death in 1705. What Bernoulli showed was that if the probability of getting heads is 50%, then the probability that the percentage of heads you actually got would differ from 50% by any given amount got smaller and smaller the more times you flipped the coin. You were more likely to get 50% heads if you flipped the coin 100 times than if you flipped it just twice. There’s something fishy about this answer, though, since it uses ideas from probability to say what probabilities mean. If this seems confusing, it turns out you can do a little better. Bernoulli didn’t realize this (in fact, it wasn’t fully worked out until the twentieth century), but it is possible to prove that if the chance of getting heads when you flip a coin is 50%, and you flip a coin an infinite number of times, then it is (essentially) certain that half of the times will be heads. Or, for de Méré’s strategy, if he played his dice game an infinite number of times, betting on 6 in every game, he would be essentially guaranteed to win 51.7477% of the games.*  

- Page 17 (location ~ 248-258)    

*More ironic still is that one of the things he’s most famous for is a bet that bears his name. At the end of 1654, Pascal had a mystical experience that changed his life. He stopped working on mathematics and devoted himself entirely to Jansenism, a controversial Christian movement prominent in France in the seventeenth century. He began to write extensively on theological matters. Pascal’s Wager, as it is now called, first appeared in a note among his religious writings. He argued that you could think of the choice of whether to believe in God as a kind of gamble: either the Christian God exists or he doesn’t, and a person’s beliefs amount to a bet one way or the other. But before taking any bet, you want to know what the odds are and what happens if you win versus what happens if you lose. As Pascal reasoned, if you bet that God exists and you live your life accordingly, and you’re right, you spend eternity in paradise. If you’re wrong, you just die and nothing happens. So, too, if you bet against God and you win. But if you bet against God and you lose, you are damned to perdition. When he thought about it this way, Pascal decided the decision was an easy one. The downside of atheism was just too scary.*  

- Page 17 (location ~ 260-268)    

*After finishing his undergraduate degree, Bachelier stayed at the University of Paris for his doctorate. His work attracted the attention of the best minds of the day, and he began to work on a dissertation — the one Samuelson later discovered, on speculation in financial markets — with Henri Poincaré, perhaps the most famous mathematician and physicist in France at the time. Poincaré was an ideal person to mentor Bachelier. He had made substantial contributions to every field he had come in contact with, including pure mathematics, astronomy, physics, and engineering. Although he did attend a grande école as an undergraduate, like Bachelier he had done his graduate work at the University of Paris. He also had experience working outside of academia, as a mine inspector. Indeed, for most of his life he continued to work as a professional mining engineer, ultimately becoming the chief engineer of the French Corps de Mines, and so he was able to fully appreciate the importance of working on applied mathematics, even in areas so unusual (for the time) as finance. It would have been virtually impossible for Bachelier to produce his dissertation without a supervisor who was as wide-ranging and ecumenical as Poincaré. And more, Poincaré’s enormous success had made him a cultural and political figure in France, someone who could serve as a highly influential advocate for a student whose research was difficult to situate in the then-current academic world.*  

- Page 19 (location ~ 285-296)    

*By any intellectual standard, Bachelier’s thesis was an enormous success — and it seems that, despite what happened next, Bachelier knew as much. Professionally, however, it was a disaster. The problem was the audience. Bachelier was at the leading edge of a coming revolution — after all, he had just invented mathematical finance — with the sad consequence that none of his contemporaries were in a position to properly appreciate what he had done. Instead of a community of like-minded scholars, Bachelier was evaluated by mathematicians and mathematically oriented physicists. In later times, even these groups might have been sympathetic to Bachelier’s project. But in 1900, Continental mathematics was deeply inward-looking. The general perception among mathematicians was that mathematics was just emerging from a crisis that had begun to take shape around 1860. During this period many well-known theorems were shown to contain errors, which led mathematicians to fret that the foundation of their discipline was crumbling. At issue, in particular, was the question of whether suitably rigorous methods could be identified, so as to be sure that the new results flooding academic journals were not themselves as flawed as the old.*  

- Page 20 (location ~ 299-308)    

*Imagine the sun shining through a window in a dusty attic. If you focus your eyes in the right way, you can see minute dust particles dancing in the column of light. They seem suspended in the air. If you watch carefully, you can see them occasionally twitching and changing directions, drifting upward as often as down. If you were able to look closely enough, with a microscope, say, you would be able to see that the particles were constantly jittering. This seemingly random motion, according to the Roman poet Titus Lucretius (writing in about 60 B.C.), shows that there must be tiny, invisible particles — he called them “primordial bits” — buffeting the specks of dust from all directions and pushing them first in one direction and then another. Two thousand years later, Albert Einstein made a similar argument in favor of the existence of atoms. Only he did Lucretius one better: he developed a mathematical framework that allowed him to precisely describe the trajectories a particle would take if its twitches and jitters were really caused by collisions with still-smaller particles. Over the course of the next six years, French physicist Jean-Baptiste Perrin developed an experimental method to track particles suspended in a fluid with enough precision to show that they indeed followed paths of the sort Einstein predicted. These experiments were enough to persuade the remaining skeptics that atoms did indeed exist. Lucretius’s contribution, meanwhile, went largely unappreciated. The kind of paths that Einstein was interested in are examples of Brownian motion, named after Scottish botanist Robert Brown, who noted the random movement of pollen grains suspended in water in 1826. The mathematical treatment of Brownian motion is often called a random walk — or sometimes, more evocatively, a drunkard’s walk. Imagine a man coming out of a bar in Cancun, an open bottle of sunscreen dribbling from his back pocket. He walks forward for a few steps, and then there’s a good chance that he will stumble in one direction or another. He steadies himself, takes another step, and then stumbles once again. The direction in which the man stumbles is basically random, at least insofar as it has nothing to do with his purported destination. If the man stumbles often enough, the path traced by the sunscreen dripping on the ground as he weaves his way back to his hotel (or just as likely in another direction entirely) will look like the path of a dust particle floating in the sunlight.*  

- Page 22 (location ~ 323-340)    

*This is the question Bachelier answered in his thesis. He showed that if a stock price undergoes a random walk, the probability of its taking any given value after a certain period of time is given by a curve known as a normal distribution, or a bell curve. As its name suggests, this curve looks like a bell, rounded at the top and widening at the bottom. The tallest part of this curve is centered at the starting price, which means that the most likely scenario is that the price will be somewhere near where it began. Farther out from this center peak, the curve drops off quickly, indicating that large changes in price are less likely. As the stock price takes more steps on the random walk, however, the curve progressively widens and becomes less tall overall, indicating that over time, the chances that the stock will vary from its initial value increase. A picture is priceless here, so look at Figure 1 to see how this works.*  

- Page 24 (location ~ 356-362)    

*Thinking of stock movements in terms of random walks is astoundingly modern, and it seems Bachelier was essentially unprecedented in conceiving of the market in this way. And yet on some level, the idea seems crazy (perhaps explaining why no one else entertained it). Sure, you might say, I believe the mathematics. If stock prices move randomly, then the theory of random walks is well and good. But why would you ever assume that markets move randomly? Prices go up on good news; they go down on bad news. There’s nothing random about it. Bachelier’s basic assumption, that the likelihood of the price ticking up at a given instant is always equal to the likelihood of its ticking down, is pure bunk. This thought was not lost on Bachelier. As someone intimately familiar with the workings of the Paris exchange, Bachelier knew just how strong an effect information could have on the prices of securities. And looking backward from any instant in time, it is easy to point to good news or bad news and use it to explain how the market moves. But Bachelier was interested in understanding the probabilities of future prices, where you don’t know what the news is going to be. Some future news might be predictable based on things that are already known. After all, gamblers are very good at setting odds on things like sports events and political elections — these can be thought of as predictions of the likelihoods of various outcomes to these chancy events. But how does this predictability factor into market behavior? Bachelier reasoned that any predictable events would already be reflected in the current price of a stock or bond. In other words, if you had reason to think that something would happen in the future that would ultimately make a share of Microsoft worth more — say, that Microsoft would invent a new kind of computer, or would win a major lawsuit — you should be willing to pay more for that Microsoft stock now than someone who didn’t think good things would happen to Microsoft, since you have reason to expect the stock to go up.*  

- Page 25 (location ~ 374-388)    

*Information that makes positive future events seem likely pushes prices up now; information that makes negative future events seem likely pushes prices down now. But if this reasoning is right, Bachelier argued, then stock prices must be random. Think of what happens when a trade is executed at a given price. This is where the rubber hits the road for a market. A trade means that two people — a buyer and a seller — were able to agree on a price. Both buyer and seller have looked at the available information and have decided how much they think the stock is worth to them, but with an important caveat: the buyer, at least according to Bachelier’s logic, is buying the stock at that price because he or she thinks that in the future the price is likely to go up. The seller, meanwhile, is selling at that price because he or she thinks the price is more likely to go down. Taking this argument one step further, if you have a market consisting of many informed investors who are constantly agreeing on the prices at which trades should occur, the current price of a stock can be interpreted as the price that takes into account all possible information. It is the price at which there are just as many informed people willing to bet that the price will go up as are willing to bet that the price will go down. In other words, at any moment, the current price is the price at which all available information suggests that the probability of the stock ticking up and the probability of the stock ticking down are both 50%. If markets work the way Bachelier argued they must, then the random walk hypothesis isn’t crazy at all. It’s a necessary part of what makes markets run.*  

- Page 26 (location ~ 388-400)    

*But even if markets aren’t always efficient, as they surely aren’t, and even if sometimes prices get quite far out of whack with the values of the goods being traded, as they surely do, the efficient market hypothesis offers a foothold for anyone trying to figure out how markets work. It’s an assumption, an idealization. A good analogy is high school physics, which often takes place in a world with no friction and no gravity. Of course, there’s no such world. But a few simplifying assumptions can go a long way toward making an otherwise intractable problem solvable — and once you solve the simplified problem, you can begin to ask how much damage your simplifying assumptions do. If you want to understand what happens when two hockey pucks bump into each other on an ice rink, assuming there’s no friction won’t get you into too much trouble. On the other hand, assuming there’s no friction when you fall off a bicycle could lead to some nasty scrapes. The situation is the same when you try to model financial markets: Bachelier begins by assuming something like the efficient market hypothesis, and he makes amazing headway. The next step, which Bachelier left to later generations of people trying to understand finance, is to figure out when the assumption of market efficiency fails, and to come up with new ways to understand the market when it does.*  

- Page 27 (location ~ 409-418)    

*In many ways, Samuelson was the ideal person to discover Bachelier and to effectively spread his ideas. Samuelson proved to be one of the most influential economists of the twentieth century. He won the second Nobel Prize in economics, in 1970, for “raising the level of analysis in economic science,” the prize committee’s code for “turning economics into a mathematical discipline.” Indeed, although he studied economics both as an undergraduate at the University of Chicago and as a graduate student at Harvard, he was deeply influenced by a mathematical physicist and statistician named E. B. Wilson. Samuelson met Wilson while still a graduate student. At the time, Wilson was a professor of “vital statistics” at the Harvard School of Public Health, but he had spent the first twenty years of his career as a physicist and engineer at MIT. Wilson had been the last student of J. W. Gibbs, the first great American mathematical physicist — indeed, the first recipient of an American PhD in engineering, in 1863 from Yale. Gibbs is most famous for having helped lay the foundations of thermodynamics and statistical mechanics, which attempt to explain the behavior of ordinary objects like tubs of water and car engines in terms of their microscopic parts.*  

- Page 28 (location ~ 426-434)    

*One of the central aims of thermodynamics is to offer a description of how the behavior of particles, the small constituents of ordinary matter, can be aggregated to describe larger-scale objects. A major part of this analysis is identifying variables like temperature or pressure that don’t make sense with regard to individual particles but can nonetheless be used to characterize their collective behavior. Samuelson pointed out that economics can be thought of in essentially the same way: an economy is built out of people going around making ordinary economic decisions. The trick to understanding large-scale economics — macroeconomics — is to try to identify variables that characterize the economy as a whole — the inflation rate, for instance — and then work out the relationship of these variables to the individuals who make up the economy. In 1947, Samuelson published a book based on his dissertation at Harvard, called Foundations of Economic Analysis. Samuelson’s book was groundbreaking in a way that Bachelier’s thesis never could have been. When Bachelier was studying, economics was only barely a professional discipline. In the nineteenth century, it was basically a subfield of political philosophy. Numbers played little role until the 1880s, and even then they entered only because some philosophers became interested in measuring the world’s economies to better compare them. When Bachelier wrote his thesis, there was essentially no field of economics to revolutionize — and of the few economists there were, virtually none would have been able to understand and appreciate the mathematics Bachelier used.*  

- Page 29 (location ~ 436-447)    

*In modern parlance, what Bachelier provided in his thesis was a model for how market prices change with time, what we would now call the random walk model. The term model made its way into economics during the 1930s, with the work of another physicist turned economist, Jan Tinbergen. (Samuelson was the second Nobelist in economics; Tinbergen was the first.) The term was already being used in physics, to refer to something just shy of a full physical theory. A theory, at least as it is usually thought of in physics, is an attempt to completely and accurately describe some feature of the world. A model, meanwhile, is a kind of simplified picture of how a physical process or system works. This was more or less how Tinbergen used the term in economics, too, although his models were designed specifically to devise ways of predicting relationships between economic variables, such as the relationship between interest rates and inflation or between different wages at a single firm and the overall productivity of that firm. (Tinbergen famously argued that a company would become less productive if the income of the highest-paid employee was more than five times the income of the lowest-paid employee — a rule of thumb largely forgotten today.) Unlike in physics, where one often works with full-blown theories, mathematical economics deals almost exclusively with models.*  

- Page 30 (location ~ 457-467)    

*By the time the Cootner book was published in 1964, the idea that market prices follow a random walk was well entrenched, and many economists recognized that Bachelier was responsible for it. But the random walk model wasn’t the punch line of Bachelier’s thesis. He thought of it as preliminary work in the service of his real goal, which was developing a model for pricing options. An option is a kind of derivative that gives the person who owns the option the right to buy (or sometimes sell) a specific security, such as a stock or bond, at a predetermined price (called the strike price), at some future time (the expiration date). When you buy an option, you don’t buy the underlying stock directly. You buy the right to trade that stock at some point in the future, but at a price that you agree to in the present. So the price of an option should correspond to the value of the right to buy something at some time in the future. Even in 1900, it was obvious to anyone interested in trading that the value of an option had to have something to do with the value of the underlying security, and it also had to have something to do with the strike price.*  

- Page 31 (location ~ 467-475)    

*Bachelier’s answer was built on the idea of a fair bet. A bet is considered fair, in probability theory, if the average outcome for both people involved in the bet is zero. This means that, on average, over many repeated bets, both players should break even. An unfair bet, meanwhile, is when one player is expected to lose money in the long run. Bachelier argued that an option is itself a kind of bet. The person selling the option is betting that between the time the option is sold and the time it expires, the price of the underlying security will fall beneath the strike price. If that happens, the seller wins the bet — that is, makes a profit on the option. The option buyer, meanwhile, is betting that at some point the price of the underlying security will exceed the strike price, in which case the buyer makes a profit, by exercising the option and immediately selling the underlying security. So how much should an option cost? Bachelier reasoned that a fair price for an option would be the price that would make it a fair bet. In general, to figure out whether a bet is fair, you need to know the probability of every given outcome, and you need to know how much you would gain (or lose) if that outcome occurred. How much you gain or lose is easy to work out, since it’s just the difference between the strike price on the option and the market price for the underlying security. But with the random walk model in hand, Bachelier also knew how to calculate the probabilities that a given stock would exceed (or fail to exceed) the strike price in a given time window. Putting these two elements together, Bachelier showed just how to calculate the fair price of an option. Problem solved.*  

- Page 32 (location ~ 479-491)    

*There’s an important point to emphasize here. One often hears that markets are unpredictable because they are random. There is a sense in which this is right, and Bachelier knew it. Bachelier’s random walk model indicates that you can’t predict whether a given stock is going to go up or down, or whether your portfolio will profit. But there’s another sense in which some features of markets are predictable precisely because they are random. It’s because markets are random that you can use Bachelier’s model to make probabilistic predictions, which, because of the law of large numbers — the mathematical result that Bernoulli discovered, linking probabilities with frequency — give you information about how markets will behave in the long run. This kind of prediction is useless for someone speculating on markets directly, because it doesn’t let the speculator pick which stocks will be the winners and which the losers. But that doesn’t mean that statistical predictions can’t help investors — just consider Bachelier’s options pricing model, where the assumption that markets for the underlying assets are random is the key to its effectiveness.*  

- Page 33 (location ~ 491-499)    

*Over the next five years, Du Pont embarked on a crash program to scale up production and commercialize the new fiber. Nylon began life as an invention in a pure research lab (even though, under Bolton’s direction, Carothers was looking for such fibers). As such, it represented cutting-edge technology, based on the most advanced chemistry of the time. But it was not long before it was transformed into a commercially viable, industrially produced product. This process was essentially new: as much as nylon represented a major breakthrough in polymer chemistry, Du Pont’s commercialization program was an equally important innovation in the industrialization of basic research. A few important features distinguished the process. First, it required close collaboration among the academic scientists in the central research unit, the industrial scientists in the various departments’ research divisions, and the chemical engineers responsible for building a new plant and actually producing the nylon. As the different teams came together to solve one problem after another, the traditional boundaries between basic and applied research, and between research and engineering, broke down. Second, Du Pont developed all of the stages of manufacturing of the polymer in parallel. That is, instead of waiting until the team fully understood the first stage of the process (say, the chemical reaction by which the polymer was actually produced) and only then moving on to the next step (say, developing a method for spinning the polymer into a fiber), teams worked on all of these problems at once, each team taking the others’ work as a “black box” that would produce a fixed output by some not-yet-known method. Working in this way further encouraged collaboration between different kinds of scientists and engineers because there was no way to distinguish an initial basic research stage from later implementation and application stages. All of these occurred at once. Finally, Du Pont began by focusing on a single product: women’s hosiery. Other uses of the new fiber, including lingerie and carpets, to name a few, were put off until later. This deepened everyone’s focus, at every level of the organization. By 1939, Du Pont was ready to reveal the product; by 1940, the company could produce enough of it to sell. The story of nylon shows how the scientific atmosphere at Du Pont changed, first gradually and then rapidly as the 1930s came to a close, to one in which pure and applied work were closely aligned and both were valued. But how did this affect Osborne, who didn’t work at Du Pont? By the time nylon reached shelves in the United States, Europe was already engaged in a growing war effort — and the U.S. government was beginning to realize that it might not be able to remain neutral. In 1939, Einstein wrote a letter to Roosevelt warning that the Germans were likely to develop a nuclear weapon, prompting Roosevelt to launch a research initiative, in collaboration with the United Kingdom, on the military uses of uranium.*  

- Page 40 (location ~ 606-627)    

*After the Japanese attack on Pearl Harbor, on December 7, 1941, and Germany’s declaration of war on the United States four days later, work on nuclear weapons research accelerated rapidly. Work on uranium continued, but in the meantime, a group of physicists working at Berkeley had isolated a new element — plutonium — that could also be used in nuclear weapons and that could, at least in principle, be mass produced more easily than uranium. Early in 1942, Nobel laureate Arthur Compton secretly convened a group of physicists at the University of Chicago, working under the cover of the “Metallurgical Laboratory” (Met Lab), to study this new element and to determine how to incorporate it into a nuclear bomb. By August 1942, the Met Lab had produced a few milligrams of plutonium. The next month, the Manhattan Project began in earnest: General Leslie Groves of the Army Corps of Engineers was assigned command of the nuclear weapons project; Groves promptly made Berkeley physicist J. Robert Oppenheimer, who had been a central part of the Met Lab’s most important calculations, head of the effort. The Manhattan Project was the single largest scientific endeavor ever embarked on: at its height, it employed 130,000 people, and it cost a total of $2 billion (about $22 billion in today’s dollars). The country’s entire physics community rapidly mobilized for war, with research departments at most major universities taking part in some way, and with many physicists relocating to the new secret research facility at Los Alamos. Groves had a lot on his plate. But one of the very biggest problems involved scaling up production of plutonium from the few milligrams the Met Lab had produced to a level sufficient for the mass production of bombs. It is difficult to overstate the magnitude of this challenge. Ultimately, sixty thousand people, nearly half of the total staff working on the Manhattan Project, would be devoted to plutonium production. When Groves took over in September 1942, the Stone and Webster Engineering Corporation had already been contracted to build a large-scale plutonium enrichment plant in Hanford, Washington, but Compton, who still ran the Met Lab, didn’t think Stone and Webster was up to the task. Compton voiced his concern, and Groves agreed that Stone and Webster didn’t have the right kind of experience for the job. But then, where could you find a company capable of taking a few milligrams of a brand-new, cutting-edge material and building a production facility that could churn out tons of the stuff, fast?*  

- Page 41 (location ~ 628-645)    

*Osborne began “Brownian Motion in the Stock Market” with a thought experiment. “Let us imagine a statistician,” he wrote, “trained perhaps in astronomy and totally unfamiliar with finance, is handed a page of the Wall Street Journal containing the N.Y. Stock Exchange transactions for a given day.” Osborne began thinking about the stock market around 1956, after his wife, Doris (also an astronomer), had given birth to a second set of twins — the Osbornes’ eighth and ninth children, respectively. Osborne decided he had better start thinking about financing the future. One can easily imagine Osborne going down to the store and picking up a copy of the day’s Wall Street Journal. He would have brought it home, sat down at the kitchen table, and opened it to the pages that reported the previous day’s transactions. Here he would have found hundreds, perhaps thousands, of pieces of numerical data, in columns labeled with strange, undefined terms. The statistician trained in astronomy wouldn’t have known what the labels meant, or how to interpret the data, but that was fine. Numerical data didn’t scare him. After all, he’d seen page after page of data recording the nightly motions of the heavens. The difficulty was figuring out how the numbers related to each other, determining which numbers gave information about which other numbers, and seeing if he could make any predictions. He would, in effect, be building a model from a set of experimental data, which he’d done dozens of other times. So Osborne would have adjusted his glasses, rolled up his sleeves, and dived right in. Lo and behold, he discovered some familiar patterns: the numbers corresponding to price behaved just like a collection of particles, moving randomly in a fluid. As far as Osborne could tell, these numbers could have come from dust exhibiting Brownian motion. In many ways, Osborne’s first, and most lasting, contribution to the theory of stock market behavior recapitulated Bachelier’s thesis. But there was a big difference. Bachelier argued that from moment to moment stock prices were as likely to go up by a certain small amount as to go down by that same amount. From this he determined that stock prices would have a normal distribution. But Osborne dismissed this idea immediately. (Samuelson did, too — in fact, he called this aspect of Bachelier’s work absurd.) A simple way to test the hypothesis that the probabilities governing future stock prices are determined by a normal distribution would be to select a random collection of stocks and plot their prices. If Bachelier’s hypothesis were correct, one would expect the stock prices to form an approximate bell curve. But when Osborne tried this, he discovered that prices don’t follow a normal distribution at all! In other words, if you looked at the data, Bachelier’s findings were ruled out right away. (To his credit, Bachelier did examine empirical data, but a certain unusual feature of the market for rentes — specifically, that their prices changed very slowly, and never by very much — made his model seem more effective than it actually was.) So what did Osborne’s price distribution look like? It looked like a hump with a long tail on one side, but virtually no tail on the other side. This shape doesn’t look much like a bell, but it was familiar enough to Osborne. It’s what you get, not if prices themselves are normally distributed, but if the rate of return is normally distributed. The rate of return on a stock can be thought of as the average percentage by which the price changes each instant. Suppose you took $200, deposited $100 in a savings account, and used the other $100 to buy some stock. A year from now, you probably wouldn’t have the $200 (you might have more or less), because of interest accrued in the savings account, and because of changes in the price of the stock that you purchased. The rate of return on the stock can be thought of as the interest rate that your bank would have had to pay (or charge) to keep the balances in your two accounts equal. It is a way of capturing the change in the price of a stock relative to its initial price. The rate of return on a stock is related to the change in price by a mathematical operation known as a logarithm. For this reason, if rates of return are normally distributed, the probability distribution of stock prices should be given by something known as a log-normal distribution. (See Figure 2 for what this looks like.) The log-normal distribution was the funny-looking hump with a tail that Osborne found when he plotted actual stock prices.*  

- Page 45 (location ~ 690-722)    

*Osborne argued that rates of return, not prices, are normally distributed. Since price and rate of return are related by a logarithm, Osborne’s model implies that prices should be log-normally distributed. These plots show what these two distributions look like at some time in the future, for a stock whose price is $10 now. Plot (a) is an example of a normal distribution over rates of return, and plot (b) is the associated log-normal distribution for the prices, given those probabilities for rates of return. Note that on this model, rates of return can be negative, but prices never are. Osborne had another reason for believing that the rate of return, not the price itself, should undergo a random walk. He argued that investors don’t really care about the absolute movement of stocks. Instead, they care about the percentage change. Imagine that you have a stock that is worth $10, and it goes up by $1. You’ve just made 10%. Now imagine the stock is worth $100. If it goes up by $1, you’re happy — but not as happy, since you’ve made only 1%, even though you’ve made a dollar in both cases. If the stock starts at $100, it has to go all the way up to $110 for an investor to be as pleased as if the $10 stock went up to $11. And logarithms respect this relativized valuation: they have the nice property that the difference between log(10) and log(11) is equal to the difference between log(100) and log(110). In other words, the rate of return is the same for a stock that begins at $10 and goes up to $11 as for a stock that begins at $100 and goes up to $110. Statisticians would say that the logarithm of price has an “equal interval” property: the difference between the logarithms of two prices corresponds to the difference in psychological sensation of gain or loss corresponding to the two prices.*  

- Page 48 (location ~ 728-741)    

*You might notice that the argument in the last paragraph, which is just the argument Osborne gave in “Brownian Motion in the Stock Market,” has a slightly surprising feature: it says that we should be interested in the logarithms of prices because logarithms of prices better reflect how investors feel about their gains and losses. In other words, it’s not the objective value of the change in a stock price that matters, it’s how an investor reacts to the price change. In fact, Osborne’s motivation for choosing logarithms of price as his primary variable*  

- Page 49 (location ~ 742-745)    

*explain how subjects react to different physical stimuli. In a series of experiments, Weber asked*  

- Page 49 (location ~ 746-747)    

*You might notice that the argument in the last paragraph, which is just the argument Osborne gave in “Brownian Motion in the Stock Market,” has a slightly surprising feature: it says that we should be interested in the logarithms of prices because logarithms of prices better reflect how investors feel about their gains and losses. In other words, it’s not the objective value of the change in a stock price that matters, it’s how an investor reacts to the price change. In fact, Osborne’s motivation for choosing logarithms of price as his primary variable was a psychological principle known as the Weber-Fechner law. The Weber-Fechner law was developed by nineteenth-century psychologists Ernst Weber and Gustav Fechner to explain how subjects react to different physical stimuli. In a series of experiments, Weber asked blindfolded men to hold weights. He would gradually add more weight to the weights the men were already holding, and the men were supposed to say when they felt an increase. It turned out that if a subject started out holding a small weight — just a few grams — he could tell when a few more grams were added. But if the subject started out with a larger weight, a few more grams wouldn’t be noticed. It turned out that the smallest noticeable change was proportional to the starting weight.*  

- Page 49 (location ~ 742-750)    

*So, as Osborne saw it, the fact that investors seem to care about percentage change rather than absolute change reflected a general psychological fact. More recently, people have criticized mathematical modeling of financial markets using methods from physics on the grounds that the stock market is composed of people, not quarks or pulleys. Physics is fine for billiard balls and inclined planes, even for space travel and nuclear reactors, but as Newton said, it cannot predict the madness of men. This kind of criticism draws heavily on ideas from a field known as behavioral economics, which attempts to understand economics by drawing on psychology and sociology. From this point of view, markets are all about the foibles of human beings — they cannot be reduced to the formulas of physics and mathematics. For this reason alone, Osborne’s argument is historically interesting, and I think telling. It shows that mathematical modeling of financial markets is not only consistent with thinking about markets in terms of the psychology of investors, but that the best mathematical models will be ones that, like Osborne’s and unlike Bachelier’s, take psychology into account. Of course, Osborne’s psychology was primitive, even by the standards of 1959. (The Weber-Fechner law was already a century old when Osborne applied it, and much subsequent research had been conducted on how human subjects register change.) Modern economics can draw on far more sophisticated theories of psychology than the Weber-Fechner law, and later in the book we will see some examples where it has. But bringing in new insights from psychology and related fields only strengthens our ability to use mathematics to reliably model financial markets, by guiding us to make more realistic assumptions and by helping us identify situations where the current crop of models might be expected to fail.*  

- Page 50 (location ~ 752-765)    

*Einstein proposed a simple way of figuring out the lower bound for the total amount of dark matter in the universe. He argued that the density of dark matter in the universe as a whole was at least as much as the density within a galaxy (or rather, a group of galaxies known as a cluster). Osborne decided he didn’t buy the argument. For one, Einstein seemed to be making a series of bad assumptions. Worse still, the best evidence that anyone had in 1946 showed that most dark matter was restricted to certain parts of a galaxy, with basically no dark matter in empty space (this still seems to be true). So if anything, you should expect the density of dark matter to be higher in a galaxy than in space as a whole. By 1946, most people, if they disagreed with an argument of Einstein’s pertaining to relativity and astrophysics, would assume they had misunderstood something. Einstein was already a cultural icon. But Osborne took no heed of such things. When he understood something, he understood it, and no amount of reputation or authority could intimidate him. So Osborne wrote Einstein a letter in which he very politely suggested that Einstein’s argument didn’t make any sense. Einstein replied by restating his argument from the book. So Osborne wrote again. Einstein conceded that his argument was problematic but thought the conclusion remained sound, and so he offered another argument. Once again, Osborne refuted it. At the end of a half-dozen-letter correspondence, it was clear that Einstein was unconvinced by Osborne. But it was equally clear to Osborne that Einstein’s argument in the book failed, and that he didn’t have any other good arguments up his sleeve.* [*I think most physicists today, if they read the letters, would say that Osborne got the better of the exchange.]*  

- Page 51 (location ~ 772-785)    

*He published “Brownian Motion in the Stock Market” in a journal called Operations Research. It was not an economics journal, but enough economists and economically minded mathematicians read it that Osborne’s research quickly garnered attention. Some of this was positive, but it was not unambiguously so. Indeed, when Osborne published his first paper on finance, he was unaware of Bachelier or Samuelson, or any of a handful of economists who had, in one way or another, anticipated the idea that stock prices are random. Many economists pointed out his lack of originality — so many that Osborne was forced to publish a second paper just a few months after the first, in which he presented a brief history of the idea that markets are random, giving full credit to Bachelier for coming up with the idea first, but also defending his own formulation. Osborne stood his ground, and rightfully so. Despite connections with earlier work, his papers on randomness in the stock market were sufficiently original that Samuelson later gave him credit for developing the modern version of the random walk hypothesis at the same time that Samuelson and his students were working on it. More importantly still, Osborne approached his model as a true empirical scientist, trained to handle data. He developed and applied a series of statistical tests designed to corroborate his version of the Brownian motion model. Other researchers, such as the statistician Maurice Kendall, who in 1953 showed that stock prices were as likely to go up as to go down, had done empirical work on the randomness of stock prices. But Osborne was the first to demonstrate the importance of the log-normal distribution to markets. He was also the first to clearly articulate a model for how stock market randomness worked and how it could be used to derive probabilities for future prices (and rates of return), all while providing convincing data that this particular model of the markets captured how markets really behave.*  

- Page 52 (location ~ 786-800)    

*Osborne’s first attempt at a dissertation was on a topic in astronomy. (Usually graduate students write a dissertation proposal. Osborne ignored this step. He wrote entire dissertations.) He brought the dissertation to the physics department head, who promptly rejected it because too many people were interested in the topic and Osborne’s research wasn’t original enough. So Osborne wrote a second dissertation, based on his research on the stock market. The department head rejected this, too, on the grounds that it wasn’t physics. As Osborne would later put it, “You are supposed to do original research, but if you get too original, they don’t know what’s going on.” Stock market research may have been acceptable work for a physicist within the government research community, where applied work of any stripe was highly valued. But it still wasn’t “physics” from the perspective of a traditional academic department. And so, though Osborne was received more favorably by the scientific community than Bachelier, he was still something of a maverick for working on financial modeling. Even after having two dissertations rejected, Osborne wasn’t ready to give up. He sent “Brownian Motion in the Stock Market” off to Operations Research and set to writing a third dissertation.*  

- Page 53 (location ~ 811-820)    

*Some market forces, like the details of how an exchange works or the interactions of traders, can affect how prices change over the course of a day. These are like the fast fluctuations that salmon experience from one river bend to the next. But there are other forces affecting markets, things like business cycles and government interest rates, that become apparent only when you step back and look at a longer time period. These are slow fluctuations. It turned out the financial world was the perfect place to look for data that could be used to test Osborne’s ideas about how these different kinds of fluctuations affect one another. The process worked in the other direction, too. After developing the migratory salmon model in the context of stock market prices, and after tweaking the model to better fit the data he had used to test it, he applied it to a problem in physics. Osborne proposed a new model for deep ocean currents. Specifically, he was able to explain how the random motion of water molecules (fast fluctuations in the language of the salmon paper) could give rise to variations in apparently systematic large-scale phenomena, like currents (slow fluctuations). For Osborne, work in physics and finance were intrinsically linked.*  

- Page 55 (location ~ 842-851)    

*Later, people would look at Osborne’s work and see something more optimistic. If you know that stock prices are essentially random, then, as Bachelier pointed out, you can figure out the value of options or other derivatives based on those stocks. Osborne didn’t take his work in this direction — at least, not until the late 1970s, when others had already made similar moves. Instead, he spent much of the rest of his career trying to figure out the ways in which stock prices aren’t random. In other words, after tying himself to the enormously controversial claim that stock prices represent “unrelieved bedlam” (his words, in many of his articles), Osborne systematically and exhaustively searched for order and predictability. He had some limited success. He showed that the volume of trading — the number of trades that take place in any given stretch of time — isn’t constant, as one would naively assume in a Brownian motion model. Instead, there are peaks in volume at the beginning and end of a trading day, over the course of an average trading week, and over the course of a month. (All of these variations, incidentally, represent just the kind of “slow fluctuations” Osborne had explored with his migratory salmon — applied not to prices, but to numbers of trades.) These variations arise from what Osborne took to be another principle of market psychology, that investors have limited attention spans. They get interested in a stock, they make a lot of trades and send the volume of trades way up, and then they gradually stop paying attention and volume decreases. If you allow for variations in volume, you have to change the underlying assumptions of the random walk model, and you get a new, more accurate model of how stock prices evolve, which Osborne called the “extended Brownian motion” model.*  

- Page 57 (location ~ 859-872)    

*In the mid-sixties, Osborne and a collaborator showed that at any instant, the chances that a stock will go up are not necessarily the same as the chances that the stock will go down. This assumption, you’ll recall, was an essential part of the Brownian motion model, where a step in one direction is assumed to be just as likely as a step in the other. Osborne showed that if a stock went up a little bit, its next motion was much more likely to be a move back down than another move up. Likewise, if a stock went down, it was much more likely to go up in value in its next change. That is, from moment to moment the market is much more likely to reverse itself than to continue on a trend. But there was another side to this coin. If a stock moved in the same direction twice, it was much more likely to continue in that direction than if it had moved in a given direction only once. Osborne argued that the infrastructure of the trading floor was responsible for this kind of non-randomness, and Osborne went on to suggest a model for how prices change that took this kind of behavior into account. This was a hallmark of Osborne’s work, and it was one of the reasons he’s such an important figure in the story of physics and finance. The idea that prices are equally likely to move up or down was part of Osborne’s version of the efficient market hypothesis, a central assumption of his original model. When he realized this assumption didn’t hold, he began to look for ways to tweak the model to account for a more realistic assumption, based on what he had learned about real markets. Osborne was explicit from the beginning that this was his methodology, in keeping with the kinds of theoretical work he was familiar with in astronomy and fluid dynamics. In those fields, most problems are much too hard to solve all at once. Instead, you begin by studying the data and then make simplifying assumptions to derive simple models. But this is only the first step. Next, you check carefully to find places where your simplifying assumptions break down and try to figure out, again by focusing on the data, how these failures of your assumptions produce problems for the model’s predictions. When Osborne described his original Brownian motion model, he specifically indicated what assumptions he was making.*  

- Page 57 (location ~ 872-889)    

*Osborne noticed that a great preponderance of ordinary investors placed their orders at whole-number prices — $10, or $11 say. But stocks were valued in units of 1/8 of a dollar. This meant that a trader could look at his book and see that there were a lot of people who wanted to buy a stock at, say, $10. He could then buy it at $10 1/8, knowing that at the end of the day the stock wouldn’t drop below $10 because there were so many people willing to buy at that threshold. So at worst, the trader would lose $1/8; at best, the stock would go up, and he could make a lot. Conversely, he could see that a lot of people wanted to sell at, say, $11, and so he could sell at $10 7/8 with confidence that the most he could lose would be $1/8 if the stock went up instead of down. This meant that if you went through a day’s trades and looked for trades at $1/8 above or below whole-dollar amounts, you could gather which stocks the experts thought were “hot” because so many other people were interested.*  

- Page 59 (location ~ 904-910)    

*Szolem must have hoped his dramatic gesture would knock some sense into his young nephew. But the plan backfired magnificently. Benoît took the paper — a review of a recent book by a Harvard linguist named George Kingsley Zipf — and studied it carefully on his way home. Zipf was a famously eccentric character and few took him seriously. He had spent his career arguing for a universal law of physical, social, and linguistic phenomena. Zipf’s law said that if you constructed a list of all the things in some natural category, say, all of the cities in France, or all of the libraries in the world, and ranked them according to their size — you might rank cities by population; libraries, by collection size — you would always find that the size of each thing on the list was related to its rank on the list. In particular, the second thing on each list would always be about half the size of the first thing, the third thing on the list would be about a third the size of the first thing, and so on. The review that Benoît read focused on a particular example of the law in action: Zipf had gone through and counted how often various words appeared in various texts. He then showed that if you ordered the words by how often they appeared in a piece of writing, you usually found that the most common word appeared about twice as often as the second most common word, three times as often as the third most common word, and so on for all of the words in the document.*  

- Page 61 (location ~ 934-944)    

*Szolem was right that Zipf’s work was just the kind of thing his nephew would be interested in. But he was wrong that it was trash — or at least that it was all trash. Zipf’s law is a peculiar combination of estimation and numerology and Zipf was a crank. But there was a gem hidden in his book: Zipf had worked out a formula that could be used to calculate how often a particular word would appear in a book, given its rank on the list and the total number of different words appearing in the text. Mandelbrot quickly realized that the formula could be improved upon, and moreover that it had some unexpected and interesting mathematical properties. Despite the resistance of the brightest lights in the mathematical establishment, his uncle included, Mandelbrot wrote a dissertation on Zipf’s law and its applications. He did so without an advisor and received his degree only by pushing his thesis through the university’s bureaucratic channels himself. It was highly irregular.*  

- Page 62 (location ~ 944-951)    

*Mandelbrot was a revolutionary. Even today, decades after his most important papers, his ideas remain radical, with mainstream scientists in many fields still debating them. The situation is particularly striking in economics, where Mandelbrot’s central ideas have gone down like a bitter pill. If they are correct, almost everything traditional economists believe about markets is fundamentally flawed. It didn’t help that Mandelbrot was uncompromising, both as a person and as a scientist, never bending to academic pressures. He often found himself at the fringes of respectability: esteemed, though never as highly as he deserved; criticized and dismissed as much for his style as for the unconventionality of his work. Yet over the past four decades, as Wall Street and the scientific community have encountered new, seemingly insurmountable challenges, Mandelbrot’s insights into randomness have seemed ever more prescient — and more essential to understand.*  

- Page 63 (location ~ 956-963)    

*In the immediate aftermath of World War I, mathematics in Poland was dominated by a brilliant young mathematician named Waclaw Sierpinski. Sierpinski worked on a topic known as set theory. He was militant about his preferred style of mathematics and powerful enough to dictate the terms of success for any graduate student in Warsaw. Later in life, Szolem may have seemed unbearably rigid to the geometrically minded Mandelbrot, but Sierpinski was too formal even for Szolem. Refusing to work on the topics Sierpinski required, Szolem fled to Paris, where the prevailing mathematical ideology was more in line with his own. Ironically, Sierpinski was also the discoverer of an unusual geometrical object known as the Sierpinski triangle — an early example of a fractal. It wasn’t until Mandelbrot arrived in Paris that he had the opportunity to interact with his famous mathematician uncle. Mandelbrot was eleven years old. Though the two would later have their differences, their early relationship was deeply formative. Since Mandelbrot spoke little French, he was placed two grades behind his age level. To keep him interested in his education and to encourage his talents, Szolem fed him bits of mathematics. It was largely Szolem’s influence during this period that pushed Mandelbrot toward mathematics. Despite the difficult economic and political situation, under Szolem’s tutelage Benoît found a way to thrive in his new home. Unfortunately, it would not last. In 1940, Germany invaded France. And once again, the Mandelbrots were forced to*  

- Page 65 (location ~ 983-995)    

*In the immediate aftermath of World War I, mathematics in Poland was dominated by a brilliant young mathematician named Waclaw Sierpinski. Sierpinski worked on a topic known as set theory. He was militant about his preferred style of mathematics and powerful enough to dictate the terms of success for any graduate student in Warsaw. Later in life, Szolem may have seemed unbearably rigid to the geometrically minded Mandelbrot, but Sierpinski was too formal even for Szolem. Refusing to work on the topics Sierpinski required, Szolem fled to Paris, where the prevailing mathematical ideology was more in line with his own. Ironically, Sierpinski was also the discoverer of an unusual geometrical object known as the Sierpinski triangle — an early example of a fractal. It wasn’t until Mandelbrot arrived in Paris that he had the opportunity to interact with his famous mathematician uncle. Mandelbrot was eleven years old. Though the two would later have their differences, their early relationship was deeply formative. Since Mandelbrot spoke little French, he was placed two grades behind his age level. To keep him interested in his education and to encourage his talents, Szolem fed him bits of mathematics. It was largely Szolem’s influence during this period that pushed Mandelbrot toward mathematics. Despite the difficult economic and political situation, under Szolem’s tutelage Benoît found a way to thrive in his new home. Unfortunately, it would not last. In 1940, Germany invaded France. And once again, the Mandelbrots were forced to flee.*  

- Page 65 (location ~ 983-995)    

*How long is Britain’s coastline? This might seem like a simple question — one that could be easily settled, say, by a team of competent surveyors. As it turns out, however, the question is more complicated than it appears. There’s a deep puzzle built into it, sometimes known as the coastline paradox. To figure out the length of a coastline, you need to take some measurements, presumably with some sort of ruler. The puzzle concerns how long your ruler needs to be. Suppose you started with a single enormous ruler that stretched from Cape Wrath, at the northernmost tip of Scotland, all the way down to Penzance, at the southwestern tip of Cornwall. This would give you an estimate of the length of the coastline.*  

- Page 65 (location ~ 995-1000)    

*A coastline is hardly a straight line. The coast of Britain dips in at the Bristol Channel and the Irish Sea, jutting out again near Wales, so taking one very long ruler isn’t going to give an accurate measurement. To get a better measurement, you would want to use a somewhat smaller ruler — one that could easily accommodate the additional length that the various peninsulas and bays add to the coast. You might try adding up the distances from, say, Penzance to Bristol, and then from Bristol to St. David’s in Wales, and then from St. David’s to Carmel Head at the northwestern tip of Wales, and so on all the way up the coast. This total distance would be a lot longer than the first distance you calculated, but it would be more accurate. Now, though, a pattern begins to emerge. This smaller ruler, it turns out, underestimates the length in the same way the original long ruler did. Using the smaller ruler, you miss Cardigan Bay altogether, not to mention the dozens of smaller harbors and inlets along the Cornish and Welsh coasts. To account for these features, which turn out to add rather a lot of distance, you need a smaller ruler still. But again, the same problem arises. In fact, no matter what size ruler you pick, the answer you get by measuring the coastline with that ruler is always too small. In other words, you can always get a larger answer to the question by picking a smaller ruler. This is where the paradox arises. It is often the case that choosing more precise instruments gives you a better measurement of something. You can get a sense of how hot a pot of water is by sticking your finger in it. An alcohol thermometer would do the job even better, and a high-tech digital thermometer would bring the accuracy to within a fraction of a degree. There is a sense in which the imprecise tools are adding measurement error, and as you devise better and better instruments, you home in on the real temperature. But with a coastline, no matter how precise your measuring device — that is, no matter how small your ruler — your measurement is always much too small. In some sense, a coastline doesn’t have a length, or at least not in the way that simple shapes like a line or a circle do. Mandelbrot addressed the coastline paradox in a groundbreaking paper in 1967. It was one of his first attempts to describe a fractal shape — as, indeed, a coastline turns out to be, though Mandelbrot didn’t coin the term until 1975. Coastlines (and other fractals) are remarkable from a mathematical point of view because they have a property called self-similarity. To say that something is self-similar is to say that it is composed of pieces that look just like the whole; these pieces in turn are composed of still smaller pieces that also look like the whole, and so on ad infinitum. If you begin with the whole west coast of Britain and carve it up into several pieces, you will notice that each of these also looks like a coastline; just like the full coastline, the smaller stretches of coast have their own little inlets and peninsulas. And if you break up one of these smaller bits of coast further, the still-smaller pieces exhibit all the same features of the larger structures. Once you start looking for self-similarity, you quickly realize it’s a ubiquitous feature of nature. A mountaintop looks much like a whole mountain in miniature; a tree branch looks like a little tree, with smaller branches of its own; river systems are built out of smaller rivers and estuaries. The principle even seems to extend to the social world. As Mandelbrot later pointed out, a battle is made up of smaller skirmishes, and a war is composed of battles, each a microcosm of the war as a whole.*  

- Page 66 (location ~ 1000-1027)    

*Life during wartime is an unpredictable thing. In Thomas Pynchon’s novel Gravity’s Rainbow, one of the characters, Roger Mexico, is a statistician charged with keeping track of where the V-2 rockets land in London during the final days of the Third Reich. He finds that the rockets are falling according to a particular statistical distribution — the one you would expect if they were equally likely to fall anywhere in the city. Mexico is surrounded by people desperate to control their lives, to save themselves from the rockets’ whimsical paths. To these onlookers, Mexico’s charts and graphs hint at some underlying pattern, something they might use to predict where the next rocket will fall. Some areas of the city seem to be hit quite often. Others, rarely. But to assume that these patterns say anything about where the next rocket will fall is to commit the same fallacy as the roulette player who is convinced that a particular number is “due.” Mexico knows this. And yet he, too, finds the data seductive, as though the very randomness of the pattern holds the key to its power. And it does, at least if you happen to be standing on the street where the next rocket falls. Yet mathematically, this sort of randomness is mild. The V-2 rockets were fired systematically, several a day, aimed roughly at London. Working out the odds of how many rockets would land on St. Paul’s Cathedral or in Hammersmith was a lot like working out how many times a roulette ball would fall into red 25. Indeed, many of the situations we think of as random are like this. So many, in fact, that it’s easy to fall prey to the idea that all random events are like coin tosses or simple casino games.*  

- Page 70 (location ~ 1060-1072)    

*This assumption underlies much of modern financial theory. Think back to when Bachelier was imagining how stock prices would change over time if they underwent a random walk. Every few moments, the price would tick up or down by some small amount as though God were flipping a coin. Bachelier discovered that if this was a good approximation of what was happening, the distribution of prices would look like a bell curve, a normal distribution. Osborne of course pointed out that this wasn’t quite right; really, you expect the prices to change by some fixed percentage each time God flips his coin, rather than some fixed amount. This modification led to the observations that rates of return should be normally distributed and prices should be log-normally distributed. The normal distribution shows up in all sorts of places in nature. If you took the heights of all of the men in a given part of the world and plotted how many of them were 5 feet 6 inches, how many 5 feet 7 inches, and so on, you would get a normal distribution. If you used a thousand thermometers and tried to take your temperature with each of them, the results would look like a normal distribution. If you played a coin-flipping game in which you got a dollar every time the coin landed heads, and you lost a dollar every time it landed tails, the probabilities governing your profits after many plays would look like a normal distribution. This is convenient: normal distributions are easy to understand and to work with. For instance, if something is normally distributed and your sample is large enough, the sample’s average value tends to converge to a particular number; white men, on average, are about 5 feet 9 inches, and unless you are ill, the thousand thermometers’ readings will average 98.6 degrees Fahrenheit. Your average profits in the coin-tossing game will converge to zero.*  

- Page 70 (location ~ 1072-1085)    

*This rule can be thought of as the law of large numbers for probability distributions — a generalization of the principle discovered by Bernoulli, linking probabilities to the long-run frequencies with which events occur. It says that if something is governed by certain probability distributions, as men’s heights are governed by a normal distribution, then once you have a large enough sample, new instances aren’t going to affect the average value very much. Once you have measured many men’s heights in a given region of the world, measuring one more man won’t change the average height by much. Not all probability distributions satisfy the law of large numbers, however. The location of the drunken vacationer in Cancun does — he is taking a random walk, so on average, he will stay right where he started, just as the average profits from a coin-tossing game converge to zero. But what if instead of a drunk trying to walk to his hotel, you had a drunken firing squad? Each member stands, rifle in hand, facing a wall. (For argument’s sake, assume the wall is infinitely long.) Just like the drunk walking, the drunks on the firing squad are equally liable to stumble one way as another. When each one steadies himself to shoot the rifle, he could be pointing in any direction at all. The bullet might hit the wall directly in front of him, or it might hit the wall 100 feet to his right (or it might go off in the entirely opposite direction, missing the wall completely).*  

- Page 71 (location ~ 1085-1095)    

*Suppose the group engages in target practice, firing a few thousand shots. If you make a note of where each bullet hits the wall (counting only the ones that hit), you can use this information to come up with a distribution that corresponds to the probability that any given bullet will hit any given part of the wall. When you compare this distribution to the plain old normal distribution, you’ll notice that it’s quite different. The drunken firing squad’s bullets hit the middle part of the wall most of the time — more often, in fact, than the normal distribution would have predicted. But the bullets also hit very distant parts of the wall surprisingly often — much, much more often than the normal distribution would have predicted. This probability distribution is called a Cauchy distribution. Because the left and right sides of the distribution don’t go to zero as quickly as in a normal distribution (because bullets hit distant parts of the wall quite often), a Cauchy distribution is said to have “fat tails.” (You can see what the Cauchy distribution looks like in Figure*  

- Page 72 (location ~ 1096-1103)    

*Suppose the group engages in target practice, firing a few thousand shots. If you make a note of where each bullet hits the wall (counting only the ones that hit), you can use this information to come up with a distribution that corresponds to the probability that any given bullet will hit any given part of the wall. When you compare this distribution to the plain old normal distribution, you’ll notice that it’s quite different. The drunken firing squad’s bullets hit the middle part of the wall most of the time — more often, in fact, than the normal distribution would have predicted. But the bullets also hit very distant parts of the wall surprisingly often — much, much more often than the normal distribution would have predicted. This probability distribution is called a Cauchy distribution. Because the left and right sides of the distribution don’t go to zero as quickly as in a normal distribution (because bullets hit distant parts of the wall quite often), a Cauchy distribution is said to have “fat tails.” (You can see what the Cauchy distribution looks like in Figure 3.)*  

- Page 72 (location ~ 1096-1103)    

*Liberation came in the summer of 1944. By the end of August, the Mandelbrots had moved back to Paris. Though he had been in Lyon for only six months, a single academic term, Mandelbrot’s experience there changed the course of his life. He learned an enormous amount and discovered an unusual gift for geometry, but more importantly, he had reclaimed his education. He decided to continue his preparations for the grande école examinations, and in 1944, he was admitted to one of the most prestigious preparatory schools in Paris. After performing well on the exams, he gained entrance to several grandes écoles, including the most selective of all, the École Normale Supérieure. He attended the École Normale Supérieure for two days before deciding that he couldn’t bear life in an ivory tower. His time away from the academy had made him all too conscious of real-world problems. Mandelbrot immediately transferred to the more practical and scientifically oriented École Polytechnique. The choice augured Mandelbrot’s path through academia: in each instance, faced with a choice between the pure and the applied, Mandelbrot chose the applied. In doing so, he brought his “freakish” geometrical gifts to bear on applied problems that had previously been overlooked, or that had seemed too difficult to crack. Like Bachelier before him, Mandelbrot asked questions that had never before occurred to anyone with his mathematical abilities — and he found answers that changed how scientists see the world.*  

- Page 76 (location ~ 1164-1175)    

*After another awkward attempt or two, Mandelbrot realized that something was wrong. He backed up and pointed to the graph on the board. “Isn’t that a wealth distribution plot?” Puzzled, Houthakker explained that the drawing on his board had been from a meeting with a graduate student earlier in the day, during which Houthakker and the student were discussing historical data on cotton prices. The picture was a graph of daily returns from cotton markets. Houthakker went on to explain that he had been working on cotton markets for a while now, but the data weren’t cooperating with theory. By this time, Bachelier’s work had been rediscovered and economists had begun to accept that markets undergo a random walk, as Bachelier and Osborne had argued. Houthakker was interested in verifying this hypothesis by looking at historical data. If the random walk thesis was correct, you should see many small price changes over the course of a day or a week or a month, but very few large ones. What Houthakker’s data showed, however, was not what the theory predicted: he was seeing too many very small changes, but also far too many very large ones. Worse, he was struggling to come up with a value for the average price change, as Bachelier’s theory predicted must exist. Every time Houthakker looked at a new set of data, the average would change, often dramatically. In other words, cotton prices seemed to behave more like a drunken firing squad than a drunken vacationer. Mandelbrot was intrigued. He asked Houthakker if he could look more closely at the data, and Houthakker agreed; in fact, Houthakker told Mandelbrot that he could have it all, since he was ready to abandon the project.*  

- Page 80 (location ~ 1221-1233)    

*After another awkward attempt or two, Mandelbrot realized that something was wrong. He backed up and pointed to the graph on the board. “Isn’t that a wealth distribution plot?” Puzzled, Houthakker explained that the drawing on his board had been from a meeting with a graduate student earlier in the day, during which Houthakker and the student were discussing historical data on cotton prices. The picture was a graph of daily returns from cotton markets. Houthakker went on to explain that he had been working on cotton markets for a while now, but the data weren’t cooperating with theory. By this time, Bachelier’s work had been rediscovered and economists had begun to accept that markets undergo a random walk, as Bachelier and Osborne had argued. Houthakker was interested in verifying this hypothesis by looking at historical data. If the random walk thesis was correct, you should see many small price changes over the course of a day or a week or a month, but very few large ones. What Houthakker’s data showed, however, was not what the theory predicted: he was seeing too many very small changes, but also far too many very large ones. Worse, he was struggling to come up with a value for the average price change, as Bachelier’s theory predicted must exist. Every time Houthakker looked at a new set of data, the average would change, often dramatically. In other words, cotton prices seemed to behave more like a drunken firing squad than a drunken vacationer. Mandelbrot was intrigued. He asked Houthakker if he could look more closely at the data, and Houthakker agreed; in fact, Houthakker told Mandelbrot that he could have it all, since he was ready to abandon the project. Back at IBM, Mandelbrot had a small team of programmers tear through boxes of Houthakker’s cotton data,*  

- Page 80 (location ~ 1221-1234)    

*Lévy’s work on random processes had led him to study a class of probability distribution now called Lévy-stable distributions. The normal and Cauchy distributions are both examples of Lévy-stable distributions, but Lévy showed that there is a spectrum of randomness, ranging between the two. (In fact, there are even wilder varieties of randomness than the Cauchy distribution.) Wildness can be captured by a number, usually called alpha, that characterizes the tails of a Lévy-stable distribution (see Figure 4). Normal distributions have an alpha of 2; Cauchy distributions have an alpha of 1. The lower the number, the more wildly random the process (and the fatter the tails). Distributions that have alpha of 1 or less don’t satisfy the law of large numbers — in fact, it isn’t possible to even define the average value for a quantity that wild. Distributions with alpha between 1 and 2, meanwhile, have average values, but they don’t have a well-defined average variability — what statisticians call volatility or variance — which means it can be very hard to calculate an average value from empirical data, even when the average exists.*  

- Page 81 (location ~ 1242-1250)    

*Cotton markets were the first place that Mandelbrot found evidence of Lévy-stable distributions. But if cotton prices varied wildly, he wondered, why should other markets be different? Mandelbrot quickly began collecting data on markets of all sorts: other commodities (like gold or oil), stocks, bonds. In every case he found the same thing: the alphas associated with these markets were less than 2, often substantially so. This meant that Bachelier’s and Osborne’s theories of random walks and normal distributions faced a big problem. Mandelbrot made the connection between Pareto distributions and Lévy-stable distributions in 1960, the year after Osborne’s first paper; he published the extension of this work to cotton prices in 1963, early enough that Paul Cootner, the MIT economist who edited the collection of essays that included Bachelier’s and Osborne’s work, was able to include a paper by Mandelbrot outlining his alternative theory. This meant that the volume that brought Bachelier’s and Osborne’s work to the wider community of economists and financial theorists already included hints that simple random walk models were not the whole story. Around 1965, financial theorists had a choice, though it surely didn’t feel that way to them at the time: they could follow Osborne and others who showed how traditional statistical methods, developed largely in the context of physics, could be used to analyze and model stock market returns; or they could follow Mandelbrot, who showed that despite this remarkable power, there was reason to think the traditional methods had shortcomings. Weighing in on the traditionalists’ side was the fact that the older methods were better understood and simpler. Mandelbrot, meanwhile, had some highly suggestive data on his side.*  

- Page 83 (location ~ 1261-1274)    

*Mandelbrot, like Prime Minister Churchill before him, promises us not utopia but blood, sweat, toil, and tears. If he is right, almost all of our statistical tools are obsolete. . . . Almost without exception, past econometric work is meaningless. Surely, before consigning centuries of work to the ash pile, we should like to have some assurance that all our work is truly useless. Much of the field took a similar view. At this point, the (mild) random walk hypothesis was still young, but a growing number of researchers, Cootner included, had already staked their careers on it. It is easy to see Cootner’s remarks as a reactionary attempt to fend off a young researcher who had caught out the errors of the (recent) past. Surely Mandelbrot saw it this way, and perhaps we all should now that many practitioners and theorists alike have recognized the importance of fat-tailed distributions. For instance, some people — most notably, Nassim Taleb, a hedge fund manager and professor at Polytechnic Institute of New York University who wrote an influential book called The Black Swan, as well as Mandelbrot himself — have recently argued that finance took a wrong turn in 1965 by continuing to assume mild randomness when really financial markets are wild. But that argument misses an important point about the way the science of finance has developed. In the 1960s, traditional statistics was a mature field with an enormous toolbox. Mandelbrot was coming forward with little more than a suggestion and a few pictures. It would have been essentially impossible to do the kind of work that Osborne, Samuelson, and many others working in finance and econometrics did during this period without the tools of traditional statistics. Mandelbrot’s project simply wasn’t well enough understood. It would be like telling a carpenter that screws are much stronger than nails, when the carpenter has a hammer and no one has yet invented the screwdriver. Even if the house would be stronger if built with screws, you’d still get much farther working with a hammer and nails, at least for a while.*  

- Page 84 (location ~ 1276-1291)    

*What the field implicitly understood is that you need to start with the simplest theory that works, get as far as you can, and then ask where the theory you’ve built has gone wrong. In this case, once you have established that stock market prices are random (at least in some sense), the next step is to assume that they are random in the simplest possible way: that they just follow a random walk. This is what Bachelier did. Osborne then pointed out that this couldn’t be right, since it would mean that stock prices could become negative, and so he complicated the model ever so slightly by suggesting that market rates of return follow a random walk. He then showed that this suggestion explained the data much better than Bachelier’s model.*  

- Page 85 (location ~ 1293-1298)    

*The differences between Osborne’s model and Mandelbrot’s can hardly be dismissed, but they become important only in the context of extreme events. On a typical day, there aren’t going to be any extreme events (according to either theory), and so you usually won’t notice much of a difference between the two models. For this reason — as we will see in the next several chapters — when it came time for economists interested in financial markets to try to extend the ideas presented in Cootner’s book, to put the randomness of stock market prices to work by using statistics to predict derivatives prices or to calculate the amount of risk in a portfolio, they had to pick between the simple theory that gave good results the vast majority of the time and the more cumbersome one that better accounted for certain extreme events. It made perfect sense to start with the simpler one and see what happened. If you make good assumptions, if you idealize effectively, you can often solve a problem that otherwise couldn’t be solved — and get a solution that is quite close to correct, even if some of the details are wrong. Of course, all along, you know you’ve made assumptions that aren’t quite right (markets are not perfectly efficient; returns and not prices follow a simple random walk). But they’re a start.*  

- Page 85 (location ~ 1301-1310)    

*a dedicated core of mathematicians, statisticians, and economists put Mandelbrot’s proposals to the test with ever more detailed data, and ever more sophisticated mathematical methods — most of which were developed specifically for the purpose of better understanding what it would mean if the world were really as wildly random as Mandelbrot said. This work confirmed Mandelbrot’s basic thesis, that normal and log-normal distributions are insufficient to capture the statistical properties of markets. Rates of return have fat tails. That said, there’s a wrinkle in the story. Mandelbrot made a very specific claim in his 1963 papers: he said that markets were Lévy-stable distributed. And except for the normal distribution, the volatility of Lévy-stable distributions is infinite, which means that most standard statistical tools don’t apply for analyzing such distributions. (This is what Cootner was alluding to when he said that if Mandelbrot was correct, the standard statistical tools were obsolete.) Today, the best evidence indicates that this specific claim, regarding infinite variability and the inapplicability of standard statistical tools, is false. After almost fifty years of research, the consensus is that rates of return are fat-tailed, but they aren’t Lévy-stable. If this is correct, as most economists and physicists working on these topics believe it is, then the standard statistical tools do apply, even though the simplest assumptions of normal and log-normal distributions do not. But evaluating Mandelbrot’s claims is an extremely tricky business — mostly because the important differences between his proposal and its nearest alternatives apply only in extreme cases, data for which are very hard to come by. And even today, there is disagreement about how to interpret the data we do have. The fact that Mandelbrot’s claims were likely too aggressive makes his legacy a little more difficult to evaluate. Some writers today insist that Mandelbrot was never given his due, and that a proper appreciation of his ideas would solve all the world’s problems. While this is not entirely true, a few things are certain. Extreme events occur far more often than Bachelier and Osborne believed they would, and markets are wilder places than normal distributions can describe. To fully understand markets, and to model them as safely as possible, these facts must be accounted for. And Mandelbrot is singularly responsible for discovering the shortcomings of the Bachelier-Osborne approach, and for developing the mathematics necessary to study them. Getting the details right may be an ongoing project — indeed, we should never expect to finish the iterative process of improving our mathematical models — but there is no doubt that Mandelbrot took a crucially important step forward.*  

- Page 86 (location ~ 1312-1331)    

*He accomplished what Bachelier and Osborne never could: he showed that physics and mathematics could be used to profit from financial markets. Building on the work of Bachelier and Osborne, and on his own experience with gambling systems, Thorp invented the modern hedge fund — by applying ideas from a new field that combined mathematical physics and electrical engineering. Information theory, as it’s known, was as much a part of the 1960s as the Vegas Strip. And in Thorp’s hands, it proved to be the missing link between the statistics of market prices and a winning strategy on Wall Street.*  

- Page 91 (location ~ 1382-1386)    

*When he told his chemistry teacher of his plan, the teacher was dubious. Thorp was over a year younger than the other competitors, who were preparing for college. But after the teacher gave Thorp a practice exam, he was convinced. Thorp didn’t know everything, but he had clear aptitude. Thorp’s teacher recommended three books for Thorp to read and gave him a stack of practice tests to work on over the summer. When the test results came back, Thorp learned that he had come in fourth overall. The results were remarkable, but he knew he could do better. The version of the test he took included a new section that hadn’t been on the previous year’s test, and it had called for a slide rule. Thorp had a ten-cent slide rule, small and poorly machined. The numbers didn’t always line up correctly, introducing errors in Thorp’s calculations. Thorp was convinced that if he’d had a proper slide rule, he would have won the competition. The problem was that he couldn’t take the chemistry test again. So the following year he signed up for the corresponding test in physics. This time he came in first and won the scholarship, which paid his way through UCLA. He’d successfully parlayed backyard explosives into college tuition. Since it was physics rather than chemistry that had gotten Thorp to UCLA, he decided to make it his major. Four years later, he stayed on for graduate school. Thorp loved his studies, but graduate school wasn’t a natural choice for him, given his lack of means. If not for the scholarship competition, it’s unlikely that he would have been able to afford college. And now, when he was twenty-one, money was as big an issue as ever. Thorp mustered a budget of $100 a month — about $850 in 2012 dollars — half of which went immediately to rent. Strapped for cash, Thorp began scheming about ways to make a little extra money on the side, à la his childhood exploits.*  

- Page 92 (location ~ 1399-1413)    

*Most of Thorp’s colleagues argued that roulette was a terrible choice for a get-rich-quick scheme. Maybe if the wheel had something wrong with it, certain numbers would come up more often than others. But the wheels at big casinos, like the ones in Las Vegas or Reno, were made so precisely that you could never find an imperfection to exploit. Roulette wheels were as close to random as you could get, and without some special trick, the odds were against you. Thorp didn’t disagree with the premise. But he thought the conclusion was wrong. After all, he reasoned, physicists are good at predicting how things like wheels behave. If a roulette wheel really is perfect, well, then shouldn’t normal high school physics be enough to predict where a ball starting at such and such a place, rolling around a wheel spinning with such and such velocity, would land? You don’t need quantum physics or rocket science to figure out how balls roll around wheels. The fact that roulette wheels are so perfectly manufactured could only help: there aren’t going to be small imperfections in the wheel that might throw off your calculations, and each wheel should be pretty similar to every other. To test his hypothesis, Thorp started doing experiments. He did a few calculations and then bought a cheap, half-size wheel and filmed a ball going around it so he could watch, frame by frame, how it behaved. Meanwhile, he thought about how to put his idea to use. Major casinos accept bets even after the ball is moving, so in principle it’s possible to know the initial speed and position of the wheel and ball, which ought to be all you need to calculate where the ball will land, before you make your bet. He fantasized about building a machine that could quickly make the necessary calculations. But he didn’t get very far. Vegas roulette wheels might be flawless, but the toy wheel he bought was a piece of junk. Watching the films convinced him that the wheel was useless for his experiments; professional wheels, meanwhile, cost well over $1,000 — an impossible investment for an impoverished grad student.*  

- Page 93 (location ~ 1418-1433)    

*Information theory grew out of a project Shannon worked on during World War II, as a staff scientist at Bell Labs, AT&T’s research division in Murray Hill, New Jersey. The goal of the project was to build an encrypted telephone system so that generals at the front could safely communicate with central command. Unfortunately, this was hard to do. There is only one code system that can be mathematically proven to be unbreakable. It’s called a one-time pad. Suppose you start with a letter that you want to send to your friend but that you don’t want anyone else to read. Say the letter has 100 characters in it, including spaces. To protect the letter with an unbreakable code, you need to come up with a random list of 100 numbers (corresponding to the number of characters in the letter) called a key, and then “add” these numbers to the characters in the letter. So if the first character in the letter is D (for “Dear John,” say), and the first number in your random list is 5, you want to add 5 to D by moving down the alphabet by five letters. So you write down I as the first letter of the coded message. And so on. In order to decrypt the letter, your friend needs to have a copy of the key, too, which can then be used to subtract the right number from each letter and recover the original message. If the key is really random, there’s no way to decrypt the encoded message without access to the key, since the randomness of the key will wash out any patterns in the original message. A one-time pad such as I just described can be tricky in practice because the sender and the receiver have to have the same random keys. But in principle, the idea is simple. It gets more complicated when you try to implement the idea of a one-time pad for a telephone conversation. Now there are no letters to add a number to or subtract a number from.*  

- Page 95 (location ~ 1448-1461)    

*Shannon concluded that the amount of information carried by a signal has something to do with how easy it is for the receiver to decode, or in other words, on how unpredictable the signal is. Your rant on traffic doesn’t contain much information — it’s easy to predict; your film synopsis contains more. This is the essence of Shannon’s information theory. Perhaps the easiest way to see why this way of looking at information makes sense is to turn Shannon’s picture around. Information is the kind of thing that takes you from feeling not so sure about something to feeling more sure about it. If you gain information, you learn something about the world. Now imagine two cases. Suppose you begin by thinking that the Yankees have a great chance of winning half their games in any given year, but that there’s very little chance that there are aliens living on the moon. Shannon’s essential insight could be put as follows: if you were to learn, as in become absolutely certain, that there are aliens living on the moon, you would have gained a lot more information than if you were to learn that the Yankees have won more than half their games this year. The reason? In Shannon’s terms, it’s that the probability of there being aliens on the moon is much, much lower than that of the Yankees (or any other team) winning half their games. This connection between the probability of a message and the information contained in the message provides the crucial link needed to quantify information. In other words, by connecting information with probability, Shannon discovered a way to assign a number to a message that measures the amount of information it contains, which in turn was the first major step in building a mathematical theory of information. The invention of information theory turned Shannon into an overnight sensation, at least in the worlds of electrical engineering, mathematics, and physics. The applications proved to be endless. He stayed at Bell Labs for another decade after the war, before he moved to MIT in 1956.*  

- Page 97 (location ~ 1483-1497)    

*Casinos always employ the same strategy. The dealer has to take a new card as long as his total number of points is less than seventeen. If it’s seventeen or more, the dealer stops. And if the dealer busts, everyone wins. The twist, at least in a casino, is that although the players’ cards are all dealt face up, one of the dealer’s cards is dealt face-down, so the players do not get to see it until the end of the game. Not knowing what you’re up against makes it more difficult to know when to stop asking for new cards. Casinos have run blackjack tables for a long time. And they’ve made money doing it. This suggests, but doesn’t quite prove, that the odds are with the house. The reason it doesn’t quite prove it is that blackjack, unlike roulette, is a strategy game. The player has a choice to make: When do you ask for additional cards? Even by the early 1950s, as gambling took hold in Vegas, no one knew if there was a strategy that a player could adopt that would give him an advantage over the house. All anyone knew for sure was that whatever most people were doing, it was good for the house. Figuring out more than that would prove incredibly difficult. It involved calculating the probabilities of all of the possible hands, under all sorts of different circumstances. Millions of calculations.*  

- Page 99 (location ~ 1517-1526)    

*The problem with the army strategy, as Thorp saw it, was that it treated each round of blackjack as independent: it was as though each time around, a brand-new deck was being used. But in real life, especially in 1958 (casinos have since changed the rules slightly), this wasn’t the case. A dealer would shuffle a deck and then keep playing as long as there were enough cards to go around. This changes everything. Consider that the probability of receiving, say, an ace from a new deck is 4/52, since there are 4 aces in a deck of 52 cards. But suppose you’re on your second hand, and on the first hand 10 cards came up, two of which were aces. Now the odds of getting an ace are 2/42, which is much less than 4/52. The point is that if your strategy depends on the probabilities of getting different card combinations, and if you’re being careful, you need to take into account what cards have already been played. Adopting such a strategy, where you keep track of what cards have already been played and vary your strategy accordingly, is called card counting. Card counting, Thorp believed, could make the odds in blackjack even better than what the army researchers found. Using MIT’s IBM 704, one of the first mass-produced electronic computers, Thorp managed to prove that the player would have an advantage if he combined a modified version of the army’s strategy with a simple card-counting technique. This was Thorp’s in with Shannon. He wrote a paper describing what he had found, with the hope that Shannon would help him publish it. When the day of the meeting arrived, Thorp knew the pressure was on. He had his thirty-second elevator pitch ready: what he wanted; why Shannon should care. As it turned out, Thorp had little to worry about. Shannon immediately saw what was interesting about Thorp’s results. And after a few piercing questions, Shannon was convinced that Thorp was the real deal. He made some editorial suggestions and suggested that Thorp tone down the title (from “A Winning Strategy for Blackjack” to “A Favorable Strategy for Twenty-One”) and then offered to submit Thorp’s paper to the Proceedings of the National Academy of Sciences, the most prestigious academic journal that would consider publishing such work (only members of the Academy could submit papers). Then, as Thorp prepared to leave, Shannon casually asked if Thorp had any other gambling-related projects. This kind of math, with clear and fun applications, was right up Shannon’s alley. After a pause, Thorp leaned forward. “There is one other thing,” he began. “It’s about roulette*  

- Page 101 (location ~ 1538-1556)    

*One strategy would be to try to make bets in a way that maximizes the amount of money you could stand to make. The best way to do this would be to bet everything in your pocket each time. Then, if you win, you double your money on each flip. But this strategy has a big problem: the coin being weighted means that you will usually win, not that you’ll always win. And if you bet everything on each flip, you’ll lose everything the first time it comes up tails. So even though you were trying to make as much money as possible, the chances that you’ll end up broke are quite high (in fact, you’re essentially guaranteed to go broke in the long run), with no chance to make your money back. This scenario — where your available funds run out, and you’re forced to accept your losses — is known as “gambler’s ruin.” There’s another possibility — one that minimizes the chances of going broke. This is also a straightforward strategy: don’t bet in the first place. But this option is (almost) as bad as the last one, because now you guarantee that you won’t make any money, even though the coin is weighted in your favor. The answer, then, has to be somewhere in the middle. Whenever you find yourself in a gambling situation where you have an advantage, you want to figure out a way to keep the chances of going broke to a minimum, while still capitalizing on the fact that in the long run, you’re going to win most of the bets. You need to manage your money in a way that keeps you in the game long enough for the long-term benefits to kick in. But actually doing this is tricky.*  

- Page 105 (location ~ 1608-1619)    

*Shannon’s theory tells you how much credence to give a message when there’s a chance that the message is being distorted by noise, or when the level of noise makes it difficult to interpret the message in the first place. So if it’s difficult to decipher your racing tips, Shannon’s theory provides a way of deciding how to place your bets based on the partial information you do receive. Kelly worked out the solution to this problem, provided you want to maximize the long-term growth of the money you start with. As in the example above, where you could make out a t sound but nothing else, partial information can be sufficient to give you an advantage over a bookie who is setting odds without any information about how the race turned out. The advantage can be calculated by multiplying the payout — the number b when someone gives you b-to-1 odds — by what you believe is the true probability of winning (based on your partial information), and then subtracting the probability of losing (again, based on your partial information). To figure out how much of your starting money to bet, as a fraction of what you have, you divide your advantage by the payout. This gives the equation now called the Kelly criterion or Kelly bet size. The percentage of your money to bet on any given outcome is advantage ————— payout If your advantage is zero (or negative!), Kelly says not to bet at all; otherwise, bet the fraction of your wealth given by the Kelly criterion. If you always follow this rule, you will be guaranteed to outperform anyone adopting another betting strategy (such as betting it all or betting nothing). One of the most surprising things in Kelly’s paper, something that feels almost mystical, is a proof of what will happen if you follow his rule in a scenario like the horse-betting story, where you have a stream of (partial) information coming in: if you always use the Kelly criterion, under certain ideal circumstances your wealth will increase at exactly the rate that information comes in along the line. Information is money. When Shannon showed Kelly’s paper to Thorp, the last piece of the blackjack puzzle fell into place. Card counting is a process by which you gain information about the deck of cards — you learn how the composition of the deck has changed with each hand. This is just what you need to calculate your advantage, as Kelly proposed. Information flows and your money grows.*  

- Page 108 (location ~ 1651-1670)    

*As Thorp and Kimmel made their preparations for Reno, Shannon and Thorp were collaborating on Thorp’s roulette plan. When he heard Thorp’s ideas, Shannon was mesmerized, in large part because Thorp’s roulette idea combined game theory with Shannon’s real passion: machines. At the heart of the idea was a wearable computer that would perform the necessary calculations for the player. They began testing ideas for how the actual gambling would work, assuming they could make sufficient progress on the prediction algorithm. They agreed that it would take more than one person for it to go smoothly, because one person couldn’t focus sufficiently on the wheel to input the necessary data and still be prepared to bet before the ball slowed down and the croupier (roulette’s equivalent of a dealer) announced that betting was closed. So they decided on a two-person scheme. One person would stand near the roulette wheel and watch carefully — ideally while doing something else, so as not to attract attention. This person would be wearing the computer, which would be a small device, about the size of a cigarette pack. The input device would be a series of switches hidden in one of the wearer’s shoes. The idea was that the person watching the wheel would tap his foot when the wheel started spinning, and then again when the ball made one full rotation. This would initialize the device and synchronize it to the wheel. Meanwhile, a second person would be sitting at the table, with an earpiece connected to the computer. Once the computer had a chance to take the initial speeds of the ball and the rotor into account, it would send a signal to the person at the table indicating how to bet. It was too difficult to predict just what number the ball would fall into, as the calculations for that level of precision were far too complicated. But roulette wheels are separated into eight regions, called octants. Each octant has four or five numbers in it, arranged in an order that would seem random to someone who didn’t have the roulette wheel memorized. Thorp and Shannon discovered that in many cases, they could accurately predict which octant the ball would fall into, narrowing the possible outcomes from thirty-eight to four or five. The computer was designed to indicate whether there was a higher-than-normal chance that the ball would fall into a particular octant. Once the person at the table received the signal, he would quickly place bets on the appropriate numbers — using a betting system based on the Kelly criterion to decide how much to bet on each.*  

- Page 109 (location ~ 1671-1689)    

*In 1962, flush with blackjack winnings and the proceeds from his card-counting book, he decided to try again. This time he bought silver. In the early 1960s, demand for silver was sky-high — so high that many people expected the open-market value of the silver in U.S. coins to exceed the coins’ denominations, which would make quarters and silver dollars more valuable as scrap metal than as money. It seemed like a safe bet. To maximize his profits, Thorp borrowed some money from his broker, with the silver investment as collateral. Silver went up for most of the sixties, but it was very volatile; not long after Thorp bought in, the price fell temporarily, but sharply, and the broker decided he wanted his money back. When Thorp couldn’t come up with the cash, the broker sold Thorp’s silver, at a loss of about $6,000 to Thorp. It was devastating — over half the annual salary for an assistant professor in 1962. After this second setback, Thorp decided to get serious. After all, he was a world-renowned expert in the mathematics of gambling. And the stock market wasn’t so different from a casino game or a horserace: you make bets, based on some partial information about the future, and if things go your way, you get a payout. You can even think of market prices as reflections of the “house” odds, meaning that if you can get access to even partial relevant information, you can compare market odds and true odds to determine whether you have an advantage, just as in blackjack.*  

- Page 111 (location ~ 1699-1710)    

*As the spring semester came to an end in New Mexico, Thorp found himself with a few weeks to spare before his move to California. He began to riffle through the RHM documents. The writers at RHM apparently thought of warrants as a kind of lottery ticket. They were cheap to buy, usually worthless, but occasionally you could strike it rich if a stock started trading well above the warrant’s exercise price. Where RHM, and most other investors, saw a lottery ticket, Thorp saw a bet. A warrant is a bet on how a stock will perform over a fixed period. The price of the warrant, meanwhile, is a reflection of the market’s determination of how likely the buyer is to win the bet. It also reflects the payout, since your net profit if the warrant does become valuable is determined by how much you had to pay for the warrant in the first place. But Thorp had just spent an entire summer reading about how stock prices are random. He pulled out a piece of paper and began to calculate. His reasoning followed Bachelier’s thesis closely, except that he assumed prices were log-normally distributed, à la Osborne. He quickly arrived at an equation that told him how much a warrant should really be worth.*  

- Page 113 (location ~ 1727-1736)    

*Thorp was energized by this work on warrants. It seemed to him that he had finally found the perfect way to use his gambling experience to profit from the world’s biggest casino. But there was a problem. When he finished his calculations and plugged some numbers into a computer (Thorp wasn’t able to solve the equations he set up explicitly, but he was able to come up with a way to use a computer to do the final calculations for him), he discovered that there was no advantage to buying warrants. In other words, you couldn’t go out and buy warrants and expect to make a profit — according to the Kelly betting system, you should invest nothing! The reason for this wasn’t that warrants were all trading at exactly what they were worth; rather, they were trading at much too high a price. The dirt-cheap lottery tickets that RHM Warrant Survey was advertising were actually much, much too expensive. If you think of investing as a kind of gamble, buying a stock represents a bet that the stock price will go up. Selling a stock, meanwhile, is a bet that the stock will go down. Thorp, like Bachelier before him, realized that the “true” price of a stock (or option) corresponds to the price at which the odds of the buyer winning are the same as the odds of the seller winning. But with traditional trades, there’s an asymmetry. You can virtually always buy a stock; but you can sell a stock only if you already own it. So you can bet against a stock only if you’ve already chosen to bet for it. This is similar to a casino: it would be highly desirable, in roulette, say, to bet against a number. This, after all, is what the house does, and the house ultimately has the long-term advantage. But it isn’t possible. No casino will let you bet that your blackjack hand will lose.*  

- Page 114 (location ~ 1741-1753)    

*Today, short selling is perfectly standard. But in the 1960s — indeed, for much of the practice’s history — it was viewed as dangerous at best, and perhaps even depraved or unpatriotic. The short seller was perceived as a blatant speculator, gambling on market moves rather than investing capital to spur growth. Worse, he had the nerve to take a financial interest in bad news. This struck many investors as déclassé. Views on short selling changed in the 1970s and 1980s, in part because of Thorp’s and others’ work, and in part because of the rise of the Chicago School of economics. As those economists argued at the time, short selling may seem crude, but it serves a crucial social good: it helps keep markets efficient. If the only people who can sell a stock are the ones who already own it, people who have information that could be bad for the company often don’t have any way of affecting market prices. This would mean that information could be available that isn’t reflected in the stock price, because the people who have access to the information aren’t able to participate in the market. Short selling prevents this situation.*  

- Page 115 (location ~ 1760-1767)    

*Still, Thorp was able to find a broker who was willing to execute the required trades. This solved one problem, of figuring out how to apply Kelly’s results in the first place. But even if Thorp could ignore the social stigma of short selling — and he could — the real dangers of unlimited losses remained. Here, though, Thorp had one of his most creative insights. His analysis of warrant pricing gave him a way of relating warrant prices to stock prices. Using this relationship, he realized that if you sell warrants short, but at the same time you buy some shares of the underlying stock, you can protect yourself against the warrant increasing in value — because if the warrant increases in value, according to Thorp’s calculations the stock price should also increase, limiting your losses on the warrant. Thorp discovered that if you pick the right mix of warrants and stocks, you can guarantee a profit unless the stock price moves dramatically. This strategy is now called delta hedging, and it has spawned other strategies involving other “convertible” securities (securities that, like options, can be exchanged for another security, such as certain bonds or preferred shares of stock that can be converted to shares of common stock). Using such strategies, Thorp was able to consistently make 20% per year . . . for about forty-five years. He’s still doing it — indeed, 2008 was one of his worst years ever, and he made 18%. In 1967, he wrote a book, called Beat the Market, with a colleague at UC Irvine who had worked on similar ideas. Beat the Market was too unusual, too different from then-current practices, to change Wall Street overnight. Many traders simply ignored it; most who read it didn’t understand it, or missed its importance. But one reader, a stockbroker named Jay Regan, saw Thorp’s genius. He wrote to Thorp and proposed that they enter a partnership to create a “hedge fund.” (The term hedge fund, originally “hedged” fund, was already twenty years old when Thorp and Regan first met, but nowadays so many hedge funds are based on ideas related to Thorp’s delta hedging strategy that the name might as well have originated with Thorp and Regan.) Regan would take care of the tasks that Thorp hated: he would promote the fund, find and manage clients, interface with brokers, execute the trades.*  

- Page 116 (location ~ 1773-1790)    

*Thorp learned that his host was leaving the money management business to focus on a new venture — an old manufacturing and textiles company that he was hoping to rebuild. He’d made his first million managing other people’s money, and now it was time to put his own money to work. But mostly, Thorp and his host discussed probability theory. While they were playing, the host mentioned a kind of trick dice, called nontransitive dice. Nontransitive dice are a set of three dice with different numbers on each side. They have the unusual property that if you roll dice 1 and 2 at the same time, die 2 is favored; if you roll dice 2 and 3 at the same time, die 3 is favored; but if you roll dice 1 and 3 at the same time, die 1 is favored. Thorp, always a fan of games and the probabilities associated with them, had long been interested in nontransitive dice. From that point on, the two were fast friends. On the ride back to Newport Beach, Thorp told Vivian that he expected their host to someday be the richest man in the world. In 2008, his prediction came true. The old money manager’s name was Warren Buffett. And at his recommendation, Gerard invested with Thorp’s company.*  

- Page 118 (location ~ 1801-1808)    

*He was trained as a physicist but was never successful as one — in large part because he was too wide-ranging and unfocused. Though he was more successful as a financial economist, his career was fleeting, as he quickly became bored with the projects that made him famous and turned to new ideas that were met with much more skepticism. Yet these very qualities — the qualities that Oettinger worried would lead Black to dilettantism — were what allowed Black to bring about a marriage long in the waiting. He was enough of a physicist to understand and develop the insights of people like Bachelier and Osborne, and yet he was enough of an economist to express his discoveries in a language economists could understand. In these ways he was like Samuelson, though he was never as intellectually distinguished. But unlike Samuelson, Black was able to communicate to investors and Wall Street bankers how the new ideas coming out of physics could be used in practice. Thorp was the first person to figure out how to use Bachelier’s and Osborne’s random walk hypothesis to make a profit, but he did so outside of the establishment, through Princeton-Newport Partners. Black, on the other hand, was the person who made quantitative finance, with its deep roots in physics, an essential part of investment banking. Black took physics to the Street.*  

- Page 121 (location ~ 1844-1853)    

*Black worked at ADL for about five years. The experience changed his life. When he arrived, he was an operations research and computer science guy. He had unusually broad interests, but there’s no evidence to suggest that finance was among them. When he left in 1969, he had already laid the foundation for the Black-Scholes model. He was recognized, at least in some circles, as an exciting, if radical, up-and-coming financial economist. Wells Fargo immediately hired him to develop a trading strategy. This transformation began shortly after Black arrived at ADL, where he encountered a slightly older member of the operations research section named Jack Treynor. Treynor had gone to Haverford College intending to major in physics but decided that the department wasn’t very good, and so he switched to mathematics. After college he went to Harvard Business School and then joined ADL in 1956, a decade before Black would arrive. Treynor and Black didn’t overlap at ADL for long: in 1966, Treynor was wooed away by Merrill Lynch. But the two practically minded mathematicians made fast friends. Black liked Treynor’s way of thinking and quickly became interested in his work, primarily on risk management, hedge fund performance, and asset pricing. Although Treynor didn’t have a formal background in financial theory either, his business school background had exposed him to a set of problems that he was well suited to work on, and so much of his work at ADL involved financial institutions. Meanwhile, he worked on more theoretical research projects on the side, often motivated by the kinds of problems ADL clients encountered.*  

- Page 124 (location ~ 1900-1911)    

*The basic idea underlying CAPM was that it should be possible to assign a price to risk. Risk, in this context, means uncertainty, or volatility. Certain kinds of assets — U.S. Treasury bonds, for instance — are essentially risk-free. Nonetheless, they yield a certain rate of return, so that if you invest in Treasury bonds, you are guaranteed to make money at a fixed rate. Most investments, however, are inherently risky. Treynor realized that it would be crazy to put your money into one of these risky investments, unless you could expect the risky investments to have a higher rate of return, at least on average, than the risk-free rate. Treynor called this additional return a risk premium because it represented the additional income an investor would demand before buying a risky asset. CAPM was a model that allowed you to link risk and return, via a cost-benefit analysis of risk premiums. When Black learned about CAPM, he was immediately hooked. He found the simple relationship between uncertainty and profit deeply compelling. CAPM was a big-picture theory. It described the role of risk in making rational choices in a very abstract way. Later in his career, Black would point to one feature of CAPM in particular that he was drawn to: it was (in his words) an equilibrium theory. “Equilibrium was the concept that attracted me to finance and economics,” Black wrote in 1987. CAPM was an equilibrium theory because it described economic value as the natural balance between risk and reward. The idea that the world was in a constantly evolving equilibrium would have appealed to Black’s sensibilities as a physicist: in physics, one often finds that complicated systems tend toward states that are stable under small changes. These states are called equilibrium states because they, too, represent a kind of balance between different influences. Black set out to learn everything that Treynor knew about finance, so that when Treynor left ADL, just a year after he and Black first met, Black was the natural person to take Treynor’s place on ADL’s financial consulting team — and further perfect Treynor’s model. CAPM would form the foundation for virtually all of the work Black would go on to do.*  

- Page 125 (location ~ 1913-1928)    

*Wells Fargo approached Scholes with an offer for a consulting arrangement, to help the bank implement some of the new ideas in finance, like CAPM, that were just bubbling to the surface in academia. Scholes felt that he didn’t have enough time to do the work himself, but he knew someone who would be perfect for the job. Black quickly agreed, and in March 1969, some six months after that first meeting in the ADL cantina, Black quit his job at ADL and went off on his own. He started a new consulting firm, called Associates in Finance, with Wells Fargo as his principal client. He and Scholes were tapped to help Wells Fargo create a new, state-of-the-art investment strategy. It was around this time that Black began thinking about ways to extend CAPM to different kinds of assets and different kinds of portfolios. For instance, he tried to apply CAPM to the question of how to apportion one’s investments over time. Should you change your risk exposure as you get older, as some people were suggesting? Black decided the answer was no: just as you want to diversify over different stocks at a given time, you also want to diversify over different times, to minimize the impact that any particular stretch of bad luck might have. The question of how to value options using CAPM was just one of the many such problems that Black was working on at this time. And as early as the summer of 1969, Black had already made progress, by deriving the fundamental relationship that would ultimately give rise to the Black-Scholes equation. The essential insight was that at any given instant, it is always possible to create a portfolio consisting of a stock and an option on that stock that would be perfectly risk-free. If this sounds familiar, it’s because the idea is very similar to the one at the heart of Thorp’s delta hedging strategy: he, too, realized that if the prices of options and their underlying assets are related, you could combine options and stocks to control risk. The difference was that Thorp’s delta hedge strategy aimed to guarantee a profit, provided that the underlying stock’s price didn’t change too dramatically. This approach controlled risk, but it didn’t eliminate it altogether. (Indeed, if CAPM-style reasoning is correct, you shouldn’t be able to both eliminate risk and still make a substantial profit.) Black’s approach was to find a portfolio consisting of stocks and options that was risk-free, and then argue by CAPM reasoning that this portfolio should be expected to earn the risk-free rate of return. Black’s strategy of building a risk-free asset from stocks and options is now called dynamic hedging.*  

- Page 127 (location ~ 1941-1959)    

*Chicago wasn’t working on a hunch that Black’s work would become important. The faculty there had some inside information: options were about to become a really big deal — and a formula that allowed investors to price them would prove essential. Two major changes to U.S. and international policy were in the works, both centered in Chicago, that would soon revolutionize the derivatives industry. Having someone like Black on one’s team could only help. The first major change took place on October 14, 1971, just a few weeks after Black arrived in Chicago. The Securities and Exchange Commission (SEC) gave the go-ahead to the Chicago Board Options Exchange (CBOE), the first open, dedicated options market in United States history. Options had been around for hundreds of years, and they had been traded in the United States, often in the guise of warrants, since at least the middle of the nineteenth century. But they had never been traded on an open market before. Economists in Chicago had been agitating for the SEC to remove barriers to an open options exchange for years, until finally they convinced the Chicago Board of Trade (CBOT) to convene a committee to consider the possibility, in 1969. The head of that committee was James Lorie, a faculty member at the University of Chicago business school; later, Lorie and Merton Miller were essential in writing the report on the public impact of an options exchange that would become a major part of the CBOT’s proposal to the SEC in March 1971.*  

- Page 130 (location ~ 1989-2000)    

*What does the IMM have to do with Black and Scholes’s options pricing formula? At first glance nothing — but within a few years, futures trading at the IMM had expanded to include new derivatives based on currencies, including options. Because currency risk is an important part of any international transaction, currency derivatives very rapidly became essential to the international economy. And once again, as at the CBOE, the Black-Scholes model became an integral part of everyday trading life. Even more importantly, Black and Scholes pointed a way forward for modeling other derivatives contracts, too, which rapidly grew at the IMM as businesses sought new ways of protecting themselves against currency risk. Between the IMM and the CBOE, Black and Scholes found a world that was perfectly poised to take advantage of their new ideas. The options pricing formula that Black, Scholes, and Merton discovered was equivalent to the method that Thorp had worked out in 1965 for pricing warrants — though Thorp used a computer program to calculate options prices, rather than derive the explicit equation that bears Black’s, Scholes’s, and Merton’s names. But the underlying arguments were different. Thorp’s reasoning followed Bachelier’s: he argued that a fair price for an option should be the price at which the option could be interpreted as a fair bet. From here, Thorp worked out what the price of an option should be, assuming that stock prices satisfy the log-normal distribution Osborne described. Once he had a way of calculating the “true” price of an option, Thorp went on to work out the proportions of stocks and options necessary to execute the delta hedging strategy. Black and Scholes, meanwhile, worked in the opposite direction. They started with a hedging strategy, by observing that it should always be possible to construct a risk-free portfolio from a combination of stocks and options. They then applied CAPM to say what the rate of return on this portfolio should be — that is, the risk-free rate — and worked backward to figure out how options prices would have to depend on stock prices in order to realize this risk-free return.*  

- Page 134 (location ~ 2040-2055)    

*The distinction may seem inconsequential — after all, the two arguments are different paths to the same model of options prices. But in practice, it was crucial. The reason is that dynamic hedging, the basic idea behind the Black-Scholes approach, gave investment banks the tool they needed to manufacture options. Suppose you are a bank and you would like to start selling options to your clients. This amounts to selling your clients the right to buy or sell a given stock at a predetermined price. Ideally, you don’t want to make a risky bet yourself — your profits are going to come from the commissions you will earn on the sales, not on the proceeds of speculation. In effect this means that when a bank sells an option, it wants to find a way to counterbalance the possibility that the underlying stock will become valuable, without losing money if the option doesn’t become valuable. Black and Scholes’s dynamic hedging strategy gave banks a way to do exactly this: using the Black-Scholes approach, banks could sell options and buy other assets in such a way that (at least theoretically) they didn’t carry any risk. This turned options into a kind of product, something that banks could construct and sell. Black stayed in Chicago until 1975, when MIT wooed him back to Cambridge. For a few years, academia seemed like the perfect fit for Black. He could work on whatever he liked, and at least in the early heyday of exchange-based options trading, it seemed he could do no wrong. He was an academic celebrity of the highest order, which brought both respect and freedom. His personal life, however, was a growing disaster: his (second) wife, Mimi, hated their Chicago life, which was an important part of the decision to move back to Cambridge, nearer to her family. But the move east didn’t help much. Increasingly alienated at home, Black devoted more and more time to his work, branching off now in new directions. He began to work on generalizing CAPM to try to explain cycles in the economy: why, in a rational world, would there be periods of growth, followed by periods of contraction? This led him to a new theory of macroeconomics, which he called “general equilibrium.”*  

- Page 135 (location ~ 2056-2071)    

*In December 1983, Robert Merton, Black’s old collaborator from the Black-Scholes days, was doing consulting work for the investment bank Goldman Sachs. Merton was doing at Goldman what Black and Scholes had been doing at Wells Fargo back in 1970: bringing in the new ideas from academia and trying to implement them in a practical setting. In this capacity, he argued to Robert Rubin, then head of the Equities Division, that Goldman Sachs should hire a theorist, an academic of its own, at a high enough level of the company that the new ideas would have a chance to seep through the culture. Rubin was convinced, and so Merton went back to MIT, brainstorming who among their current crop of graduate students he would recommend for this important position. Merton asked Black for his advice and received a surprising answer: Black wanted the job himself. Three months later, Black left academia for a new job at Goldman Sachs, to organize a Quantitative Strategies Group in the Equities Division. Thus he became one of the first quants, a new kind of investment bank employee with an intensely quantitative and scientific focus, as interested in intellectual innovation as in making a big trade. Wall Street would never be the same.*  

- Page 136 (location ~ 2078-2086)    

*Physics had been on the rise in the United States since World War II. But after Sputnik was launched, physics interest skyrocketed. About five hundred physics PhDs were awarded in 1958. By 1965, that number was closer to a thousand, and by 1969 it was over fifteen hundred. This rapid growth was in part a matter of nationalism: becoming a rocket scientist was a fine way to serve your country. But even more, it was a matter of funding. NASA’s annual budget increased by a factor of seventy from 1958 to its peak in the mid-sixties. In 1966, NASA was given almost $6 billion — 4.5% of the total federal budget — to devote to basic science. Other government funding agencies, like the Department of Energy and the National Science Foundation, were also flush (though none could compete with NASA). Even mediocre graduates of mid-tier doctoral programs were guaranteed jobs in science, as either professors or government researchers. Physicists were in high demand. On July 20, 1969, Neil Armstrong and Buzz Aldrin became the first men to set foot on the surface of the moon. America and its allies rejoiced — finally, an American victory in the space race. And almost immediately, the physics job market collapsed. As the space race accelerated, so too did America’s commitment to the war in Vietnam. The success of the Apollo 11 mission gave Nixon an excuse to divert funds from NASA and other research groups to the military effort. By 1971, NASA’s budget was less than half of what it had been in 1966 (in real terms). Meanwhile, college enrollment began to drop, largely because the Baby Boom years were over. Once the “Boomers” had graduated, universities stopped hiring new faculty members.*  

- Page 137 (location ~ 2094-2105)    

*Both Thorp and Black based their options models on Osborne’s random walk hypothesis, which amounted to assuming that rates of return are normally distributed. This might give you pause. After all, Mandelbrot argued throughout the 1960s that normal and log-normal distributions do not effectively account for extreme events, that markets are wildly random. Even if Mandelbrot’s claim that rates of return are Lévy-stable distributed and thus do not have well-defined volatility is false — and most economists now believe it is — the weaker claim that market data exhibit fat tails still holds. Options models assign prices based on the probability that a stock will rise above (or drop below) a certain threshold — namely, the strike price for the option. If extreme market changes are more likely than Osborne’s model predicts, neither Thorp’s model nor the Black-Scholes model will get options prices right. In particular, they should undervalue options that would be exercised only if the market makes a dramatic move, so-called far-out-of-the-money options. A more realistic options model, meanwhile, should account for fat tails.*  

- Page 140 (location ~ 2143-2151)    

*When the market crashed in 1987, though, everyone with portfolio insurance tried to sell their stocks at the same time. The trouble with this was that there were no buyers — everyone was selling! This meant that the computers trying to execute the trades ended up selling at much lower prices than the people who had designed the portfolio insurance had expected, and the carefully calculated short positions in market futures did little to protect investors. (In fact, investors holding portfolio insurance tended to do better than those who didn’t hold it; however, many people think the automated sell orders associated with portfolio insurance exacerbated the sell-off, and so everyone suffered because portfolio insurance was so prevalent.) The Black-Scholes-based calculations underlying portfolio insurance didn’t anticipate the possibility of a crash, because the random walk model indicates that a major one-day drop like this wouldn’t happen in a million years. Several things happened in light of the crash. For*  

- Page 141 (location ~ 2159-2166)    

*When the market crashed in 1987, though, everyone with portfolio insurance tried to sell their stocks at the same time. The trouble with this was that there were no buyers — everyone was selling! This meant that the computers trying to execute the trades ended up selling at much lower prices than the people who had designed the portfolio insurance had expected, and the carefully calculated short positions in market futures did little to protect investors. (In fact, investors holding portfolio insurance tended to do better than those who didn’t hold it; however, many people think the automated sell orders associated with portfolio insurance exacerbated the sell-off, and so everyone suffered because portfolio insurance was so prevalent.) The Black-Scholes-based calculations underlying portfolio insurance didn’t anticipate the possibility of a crash, because the random walk model indicates that a major one-day drop like this wouldn’t happen in a million years. Several things happened in light of the crash. For one, many practitioners began to question the statistical predictions of the random walk model. This makes perfect sense — if your model says something is impossible, or virtually impossible, and then it happens, you need to start asking questions. But something else happened, too. Markets themselves seemed to change in the wake of the crash. Whereas in the years leading up to the crash the Black-Scholes model seemed to get options prices exactly right, in virtually all contexts and all markets, after the crash certain discrepancies began to appear. These discrepancies are often called the volatility smile because of their distinctive shape in certain graphs. The smile appeared suddenly and presented a major mystery for financial engineers in the early 1990s, when its prevalence was first recognized. Notably, Emanuel Derman came up with a way of modifying the Black-Scholes model to account for the volatility smile, though he never came up with a principled reason why the Black-Scholes model had stopped working. Mandelbrot’s work, however, offers a compelling explanation for the volatility smile. One way of interpreting the smile is as an indication that the market believes large shifts in prices are more likely than the Black-Scholes model assumes. This is just what Mandelbrot had been claiming all along: that probability distributions describing market returns have fat tails, which means that extreme events are more likely than one would predict based on a normal distribution.*  

- Page 141 (location ~ 2159-2177)    

*But given the timing, many people assume that O’Connor was simply an early adopter of the Black-Scholes model. Not so. Greenbaum realized from the start that the assumptions underlying Black-Scholes weren’t perfect, and that it was failing to properly account for extreme events. And so Greenbaum built a team of risk managers and mathematicians to figure out how to improve on the Black-Scholes model. One of O’Connor’s first employees was an eighteen-year-old whiz kid named Clay Struve, who had worked for Greenbaum at First Options in a summer job, and who worked for Fischer Black as an undergraduate at MIT during the school year. During 1977 and 1978, Greenbaum, Struve, and a small team of proto-quants worked out a modified Black-Scholes model that took into account things like sudden jumps in prices, which can lead to fat tails. O’Connor was famously successful, first in options and then in other derivatives — in part because the modified Black-Scholes model tended to outperform the standard one. Remarkably, according to Struve, O’Connor was aware of the volatility smile from very early on. That is, even before the crash of 1987, there were small, potentially exploitable discrepancies between the Black-Scholes model and market prices. Later, when the 1987 crash did occur, O’Connor survived.*  

- Page 143 (location ~ 2185-2194)    

*During the financial meltdown, even sophisticated investors, such as the banks that produced securitized loans in the first place, appear to have been mistaken about how risky these products were. In other words, the models that were supposed to make these products risk-free for their manufacturers failed, utterly. Models have failed in other market disasters as well — perhaps most notably when Long-Term Capital Management (LTCM), a small private investment firm whose strategy team included Myron Scholes among others, imploded. LTCM had a successful run from its founding in 1994 until the early summer of 1998, when Russia defaulted on its state debts. Then, in just under four months, LTCM lost $4.6 billion. By September, its assets had disappeared. The firm was heavily invested in derivatives markets, with obligations to every major bank in the world, totaling about $1 trillion. Yet at the close of trading on September 22, its market positions were worth about $500 million — a tiny fraction of what they had been worth a few months before, and far too little to cover the company’s loans. A feather’s weight would have led to a default on hundreds of billions of dollars of debt, leading to an immediate international panic, had the government not stepped in to resolve the crisis. The mathematical models underlying dynamic hedging strategies specifically, and derivatives trading more generally, are not perfect. Bachelier’s, Osborne’s, and Mandelbrot’s stories go a long way toward making clear just why this is. Their models, and the models that have come since, are based on rigorous reasoning that, in a very real sense, cannot be wrong. But even the best mathematical models can be misapplied, often in subtle and difficult-to-detect ways. In order to make complicated financial markets tractable, Bachelier, Osborne, Thorp, Black, and even Mandelbrot introduced idealizations and often strong assumptions about how markets work.*  

- Page 144 (location ~ 2196-2210)    

*the O’Connor story has an important moral. Many histories suggest that the 1987 crash rocked the financial world because it was so entirely unexpected — impossible to anticipate, in fact, given the prevailing market models. The sudden appearance of the volatility smile is taken as evidence that models can work for a while and then suddenly stop working, which in turn is supposed to undermine the reliability of the whole market-modeling enterprise. If models that work today can break tomorrow, with no warning and no explanation, why should anyone ever trust physicists on Wall Street? But this just isn’t right. By carefully thinking through the simplest model and complicating it as appropriate — in essence, by accounting for fat tails — O’Connor was able to anticipate the conditions under which Black-Scholes would break down, and to adopt a strategy that allowed the firm to weather an event like the 1987 crash. The story that I have told so far, from Bachelier to Black, goes a long way toward showing that financial modeling is an evolving process, one that proceeds in iterative fashion as mathematicians, statisticians, economists, and quite often physicists attempt to figure out the shortcomings of the best models and identify ways of improving them. In this, financial modeling is much like mathematical modeling in engineering and science more generally. Models fail. Sometimes we can anticipate when they will fail, as Greenbaum and Struve did; in other cases, we figure out what went wrong only as we are trying to put the pieces back together. This simple fact should urge caution as we develop and implement new modeling techniques, and as we continue to apply older ones. Still, if we have learned anything in the last three hundred years, it’s that the basic methodological principles of scientific progress are the best ones we’ve got — and it would be foolish to abandon them just because they aren’t always perfect.*  

- Page 145 (location ~ 2212-2225)    

*The new venture was a company, soon to be called the Prediction Company (though as they sat that evening on the Santa Fe market square, the company was still nameless). Their goal was to do the impossible: to predict the behavior of financial markets. If anyone could do it, it was this group. Between them, Farmer and Packard had three decades of experience in a subject known as nonlinear forecasting, an area of physics and applied mathematics (and increasingly other fields as well) that sought to identify predictive patterns in apparently random phenomena. In Packard’s words, it involved identifying the order at “the edge of chaos,” the small windows of time in which there was enough structure in a chaotic process to predict where a system would go next. The tools they used had been developed to predict things like how a turbulent fluid would behave in a narrow pipe. But Farmer and Packard, and the half-dozen acolytes who had followed them to Santa Fe, believed they could predict far more than that.*  

- Page 147 (location ~ 2251-2258)    

*In 1947, J. Robert Oppenheimer was appointed director of both the Institute for Advanced Study in Princeton — possibly the most prestigious scientific research institute in the world — and the newly formed Atomic Energy Commission. The same year, the Washington Times-Herald reported that Frank Oppenheimer had been a member of the American Communist Party from 1937 to 1939. Eager as he was to continue in his brother’s footsteps, 1947 was not a good year for a would-be nuclear physicist to be outed as a Communist. Frank initially denied the charges and appeared to have escaped with his reputation intact. But two years later, amid mass fear about Soviet nuclear research and the mishandling of the “atomic secret,” Frank was called before the infamous House Un-American Activities Committee. Under oath and before Congress, he admitted that he and his wife had been members of the party for about three and a half years, pushed to political extremes during the Great Depression. The confession was a newspaperman’s dream. Frank Oppenheimer, brother of the American scientist-savior, was an admitted Communist. He was never convicted of a crime, nor was there any reason to think that he had compromised classified information. But during the heady and paranoid days of McCarthyism, the mere suggestion of Communist affiliation was enough to blacklist someone, no matter whose brother he was. Frank was forced to resign from his position at the University of Minnesota, and for more than a decade he was effectively strong-armed out of physics. Living on a substantial inheritance (sadly, he was forced to sell one of the van Goghs he’d inherited from his father), he and his wife bought a ranch in Colorado and made a new start as cattle farmers and homesteaders.*  

- Page 148 (location ~ 2265-2278)    

*The ideas at the heart of Farmer’s and Packard’s work were first developed by a man named Edward Lorenz. As a young boy, Lorenz thought he wanted to be a mathematician. He had a clear talent for mathematics, and when it came time to select a major at Dartmouth, he had few doubts about what he would choose. He graduated in 1938 and went on to Harvard, planning to pursue a PhD. But World War II interfered with his plans: in 1942, he joined the U.S. Army Air Corps. His job was to predict the weather for Allied pilots. He was given this task because of his mathematical background, but at that point, at least, mathematics was of little use in weather forecasting, which was done more on the basis of gut feelings, rules of thumb, and brute luck. Lorenz was sure there was a better way — one that used sophisticated mathematics to make predictions. When he left the service in 1946, Lorenz decided to stick with meteorology. It was a place where he could put his training to productive use. He went to MIT for a PhD in meteorology and stayed for the rest of his career — first as a graduate student, then as a staff meteorologist, and finally as a professor. He worked on many of the mainstream problems that meteorologists worked on, especially early in his career. But he had some unusual tastes. For one, based on his experience in the army, he maintained an interest in forecasting. This was considered quixotic at best by his colleagues; the poor state of forecasting technology had convinced many that forecasting technology was a fool’s errand. Another oddity was that Lorenz thought computers — which, in the 1950s and 1960s, were little more than souped-up adding machines — could be useful in science, and especially in the study of complicated systems like the atmosphere. In particular, he thought that with a big enough computer and careful enough research, it would be possible to come up with a set of equations governing how things like storms and winds developed and changed. You could then use the computer to solve the equations in real time, keeping one step ahead of the actual weather to make accurate predictions long into the future.*  

- Page 152 (location ~ 2325-2340)    

*The world is an ordered place. Or at least that’s what everyone thought before Lorenz accidentally discovered chaos. Lorenz didn’t call it chaos. That word came later, with the work of two physicists named James Yorke and Tien-Yien Li who wrote a paper called “Period Three Implies Chaos.” Lorenz called his discovery “sensitive dependence on initial conditions,” which, though much less sexy, is extremely descriptive, capturing the essence of chaotic behavior. Despite the fact that Lorenz’s system was entirely deterministic, wholly governed by the laws of Lorenzian weather, extremely small differences in the state of the system at a given time would quickly explode into large differences later on. This observation, a result of one of the very first computer simulations in service of a scientific problem, contradicted every classical expectation regarding how things like weather worked. (Lorenz quickly showed that much simpler systems, such as pendulums and water wheels, things that you could build in your basement, also exhibited a sensitivity to initial conditions.) The basic idea of chaos is summed up by another accidental contribution of Lorenz’s: the so-called butterfly effect, which takes its name from a paper that Lorenz gave at the 1972 meeting of the American Association for the Advancement of Science called “Predictability: Does the Flap of a Butterfly’s Wings in Brazil Set Off a Tornado in Texas?” (Lorenz never took credit for the title. He claimed one of the conference organizers came up with it when Lorenz forgot to submit one.) Lorenz never answered*  

- Page 155 (location ~ 2366-2378)    

*The world is an ordered place. Or at least that’s what everyone thought before Lorenz accidentally discovered chaos. Lorenz didn’t call it chaos. That word came later, with the work of two physicists named James Yorke and Tien-Yien Li who wrote a paper called “Period Three Implies Chaos.” Lorenz called his discovery “sensitive dependence on initial conditions,” which, though much less sexy, is extremely descriptive, capturing the essence of chaotic behavior. Despite the fact that Lorenz’s system was entirely deterministic, wholly governed by the laws of Lorenzian weather, extremely small differences in the state of the system at a given time would quickly explode into large differences later on. This observation, a result of one of the very first computer simulations in service of a scientific problem, contradicted every classical expectation regarding how things like weather worked. (Lorenz quickly showed that much simpler systems, such as pendulums and water wheels, things that you could build in your basement, also exhibited a sensitivity to initial conditions.) The basic idea of chaos is summed up by another accidental contribution of Lorenz’s: the so-called butterfly effect, which takes its name from a paper that Lorenz gave at the 1972 meeting of the American Association for the Advancement of Science called “Predictability: Does the Flap of a Butterfly’s Wings in Brazil Set Off a Tornado in Texas?” (Lorenz never took credit for the title.*  

- Page 155 (location ~ 2366-2377)    

*The world is an ordered place. Or at least that’s what everyone thought before Lorenz accidentally discovered chaos. Lorenz didn’t call it chaos. That word came later, with the work of two physicists named James Yorke and Tien-Yien Li who wrote a paper called “Period Three Implies Chaos.” Lorenz called his discovery “sensitive dependence on initial conditions,” which, though much less sexy, is extremely descriptive, capturing the essence of chaotic behavior. Despite the fact that Lorenz’s system was entirely deterministic, wholly governed by the laws of Lorenzian weather, extremely small differences in the state of the system at a given time would quickly explode into large differences later on. This observation, a result of one of the very first computer simulations in service of a scientific problem, contradicted every classical expectation regarding how things like weather worked. (Lorenz quickly showed that much simpler systems, such as pendulums and water wheels, things that you could build in your basement, also exhibited a sensitivity to initial conditions.) The basic idea of chaos is summed up by another accidental contribution of Lorenz’s: the so-called butterfly effect, which takes its name from a paper that Lorenz gave at the 1972 meeting of the American Association for the Advancement of Science called “Predictability: Does the Flap of a Butterfly’s Wings in Brazil Set Off a Tornado in Texas?” (Lorenz never took credit for the title. He claimed one of the conference organizers came up with it when Lorenz forgot to submit one.)*  

- Page 155 (location ~ 2366-2378)    

*Lorenz never answered the question asked in the title of his talk, but the implication was clear: a small change in initial conditions can have a huge impact on events down the road. But the real moral is that, even though chaotic systems are deterministic — in the sense that an infinitely precise description at any given instant can in principle lead to an accurate prediction — it is simply impossible to capture the state of the world with such precision. You can never account for all the flaps of all the butterflies across the globe. And even the tiniest errors will quickly explode into enormous differences. The result is that, even though weather is deterministic, it seems random because we can never know enough about butterflies.*  

- Page 156 (location ~ 2378-2383)    

*During the summer of 1975, the year after Packard’s junior year at Reed and Farmer’s second year of graduate school, Packard and Farmer decided to try their hands at gambling. They had explored the idea independently, Farmer through reading A. H. Morehead’s Complete Guide to Winning Poker, and Packard by reading Ed Thorp’s Beat the Dealer. With their analytic minds and disdain for authority, both men found gambling systems had a certain appeal. They could make money without doing work — and at least in the blackjack case, they could do it by being smarter than everyone else. It was a romantic idea. The trouble was in the execution. Packard studied Thorp’s system carefully and then, along with a friend from Reed named Jack Biles, he took it to Vegas. They kept careful track of their winnings and losses — and observed an awful lot of wins. Day after day, they would record profits. They would switch to higher-stakes tables as their accumulated capital increased, and the profits would soar even higher. But then something happened. No matter how much success they had, there would always be a losing streak that would bring them back to zero. In the end, they barely broke even. It was only at the very end of a summer of gambling that they realized they were being cheated. In the years since Thorp’s card-counting system had first been introduced, casinos had become very good at identifying — and foiling — card counters, often by simple methods like crooked dealing.*  

- Page 156 (location ~ 2389-2399)    

*At the end of the summer, Farmer and Packard decided to meet up to compare notes on their gambling adventures. Farmer had good news to report: you could make a killing in poker, if you just played by the book. Packard’s experience was less auspicious. But in place of blackjack winnings, he brought something even better: a new idea for a gambling system. Prompted in part by some cryptic remarks that Thorp had made at the end of his book, Packard convinced himself that another game could be beaten more effectively than blackjack (and with less likelihood for casino shenanigans). Packard, like Thorp before him, had an idea about roulette. Farmer was skeptical, but Packard was persistent and finally convinced Farmer to think about it. Soon enough, Farmer was on board. He, Packard, and Biles spent three days thinking about the problem, working out some initial calculations and getting excited about their newest project. By the time Farmer had to go back to Santa Cruz, the three men had decided to pursue the project. They would build a computer to beat roulette. In the fall of 1975, Farmer was starting his third year of graduate school. He was supposed to be settling on a dissertation topic and beginning research in astrophysics. Instead, he and Browne began running experiments on a roulette wheel they had bought in Reno, at Paul’s Gaming Devices, the manufacturer rumored to provide the regulation wheels used in Reno and Las Vegas. (Farmer’s thesis advisor, a man named George Blumenthal, had enjoyed his own run as a would-be card counter in Las Vegas. He was tickled enough by Farmer’s project to look the other way as Farmer’s academic research stalled — in fact, after reviewing Farmer’s calculations, he even suggested that there might be a physics dissertation lurking in the roulette project.)*  

- Page 157 (location ~ 2405-2418)    

*At the end of that academic year, in the spring of 1976, the four gambling men met up in Santa Cruz to put their work together and make a plan for the summer. One of their first pieces of business was to settle on a name for the group. Farmer had recently stumbled on a new word, eudaemonia, while flipping through the dictionary. Central to the ethics of the ancient Greek philosopher Aristotle, eudaemonia was a state of ideal human flourishing. The roulette group took the name Eudaemonic Enterprises, and the members referred to themselves as Eudaemons (Greek for “good spirits”). They rented a professor’s house for the summer and built a tinkerer’s lab, assembling electronics and running experiments on roulette wheels. The Eudaemons independently arrived at the same basic strategy that Thorp and Shannon had used, with two people working the game, one timing the wheel and the other making bets. Ingerson’s legacy was manifest in Farmer and Packard’s conviction that they could build anything. The Eudaemons were an only slightly more grown-up version of the Explorer Post 114 (indeed, Ingerson later helped the group in Vegas when they tried to put the scheme into action). The original four were soon joined by another physicist named John Boyd and a friend of Farmer’s from his undergraduate days, Steve Lawton. Lawton was a humanist, a specialist in utopian literature. His role was to organize a reading group on political fiction. From the start, the group was devoted to a revolutionary mindset. Over the years, as they continued to work on roulette, more and more people joined — gamblers, physicists, computer programmers, utopians. The group thought of themselves as Yippies, members of the countercultural movement founded by Abbie Hoffman and others in 1967 and devoted to undermining the status quo through anarchic pranks they called “Groucho Marxism.” For the Eudaemons, the roulette project was a way to beat the Man and take his money — money they planned to use to build a commune on the Washington coast.*  

- Page 158 (location ~ 2422-2436)    

*In 1977, some of the physicists working on Eudaemonic Enterprises (Farmer and Packard, along with an undergraduate named James Crutchfield and an older graduate student named Robert Shaw) started an informal research group called by turns the Dynamical Systems Collective and the Chaos Cabal. Shaw threw out a nearly finished dissertation to start working on chaos theory full-time; Farmer officially switched away from astrophysics. By the late 1970s, a great deal had been done on chaos theory. Lorenz had discovered many of the basic principles and had then come up with simple examples of chaotic systems and described how they behaved. He was the first person to recognize that there is a kind of order in chaotic systems: if you draw pictures of the paths traced by objects obeying differential equations, they tend to settle down into regular patterns. These patterns are called attractors, because they tend to attract the paths of the objects. In roulette, for instance, the attractors correspond to the pockets of the wheel: whatever trajectory the ball takes, in the long run it will settle down into one of these states. But for other systems, the attractors can be much more complicated. A major contribution to the study of chaos theory was the realization that if a system is chaotic, these attractors have a highly intricate fractal structure.*  

- Page 160 (location ~ 2450-2459)    

*From the very start, prompted perhaps by the roulette experience, the Dynamical Systems Collective was interested in prediction. It was a novel way of thinking about chaotic systems, which most people were interested in precisely because they seemed so unpredictable. The collective’s most important paper, published in 1980, showed how you could use a stream of data from, say, a sensor placed in the middle of a pipe with water flowing through it to reconstruct what the attractor for the system would have to be. And once you had the attractor, an essential part of trying to understand how a chaotic system would behave over time, you could begin to make some predictions. Previously, attractors were understood as a theoretical tool, something you could get only by solving equations. Packard, Farmer, Shaw, and Crutchfield showed that, in fact, you could figure out this important feature empirically, by looking at how the system actually behaved.*  

- Page 161 (location ~ 2465-2471)    

*One theme that characterized much of the research in complexity and chaos during the early 1980s was the idea that simple large-scale structures can emerge from underlying processes that don’t seem to have that structure. To take an example from atmospheric physics, consider that the atmosphere, at the smallest scale, consists of a bunch of gas particles bumping around in the sky. And yet, when one steps back, these mindless particles somehow organize themselves into hurricanes. Similar phenomena occur in biology. Individual ants seem to behave in pretty simple ways, foraging for food, following pheromone trails, building nests. And yet, when one takes these simple actions and interactions in aggregate, they form a colony, something that appears to be more than the sum of its parts. As a whole, an ant colony even appears to be able to adapt to changes in its environment, or the deaths of individual ants. Once these ideas were in the air at Santa Fe, it was a natural leap to ask if the economies of nations and the behavior of markets could also be understood as the collective action of individual people.*  

- Page 162 (location ~ 2484-2492)    

*Building a company is different from building a radio or a motorcycle engine, or even a computer to beat roulette. But many of the same skills prove useful: the vision to see how to pull the pieces together in a new way; a tolerance for tinkering with something until you can make it work; unflagging persistence. Making something new is addictive, which might be why so many entrepreneurs are engineers and scientists. Farmer and Packard were also motivated by a strong antiestablishmentarian bent stretching back to their days as Eudaemons. The new company wasn’t designed as a first step into the financial world — it was part of a plan to upend it, to take Wall Street for all it was worth by being a little smarter, a little more conniving, than the suits. It was a company founded in much the same spirit as the roulette project, a Yippie adventure and a return to a culture of pure research and no rules. Farmer wore an EAT THE RICH T-shirt to the new company’s first formal meeting, in March 1991.*  

- Page 164 (location ~ 2509-2516)    

*the fifteen years that Farmer and Packard spent working on chaos theory gave them an unprecedented (by 1991 standards) understanding of how complex systems work, and the ability to use computers and mathematics in ways that someone trained in economics (or even in most areas of physics) would never have imagined possible. Their experience with chaos theory helped them appreciate how regular patterns — patterns with real predictive power — could be masked by the appearance of randomness. Their experience also showed them how to apply the right statistical measures to identify truly predictive patterns, how to test data against their models of market behavior, and finally how to figure out when those models were no longer doing their job. They were at ease with the statistical properties of fat-tailed distributions and wild randomness, which are characteristic of complex systems in physics as well as financial markets. This meant that they could easily apply some of Mandelbrot’s ideas for risk management in ways that people with more traditional economics training could not. As far as the Prediction Company was*  

- Page 166 (location ~ 2543-2551)    

*the fifteen years that Farmer and Packard spent working on chaos theory gave them an unprecedented (by 1991 standards) understanding of how complex systems work, and the ability to use computers and mathematics in ways that someone trained in economics (or even in most areas of physics) would never have imagined possible. Their experience with chaos theory helped them appreciate how regular patterns — patterns with real predictive power — could be masked by the appearance of randomness. Their experience also showed them how to apply the right statistical measures to identify truly predictive patterns, how to test data against their models of market behavior, and finally how to figure out when those models were no longer doing their job. They were at ease with the statistical properties of fat-tailed distributions and wild randomness, which are characteristic of complex systems in physics as well as financial markets. This meant that they could easily apply some of Mandelbrot’s ideas for risk management in ways that people with more traditional economics training could not.*  

- Page 166 (location ~ 2543-2551)    

*One strategy they used was something called statistical arbitrage, which works by betting that certain statistical properties of stocks will tend to return even if they disappear briefly. The classic example is pairs trading. Pairs trading works by observing that some companies’ stock prices are usually closely correlated. Consider Pepsi and Coca-Cola. Virtually any news that isn’t company-specific is likely to affect Pepsi’s products in just the same way as Coca-Cola’s, which means that the two stock prices usually track one another. But changes in the two companies’ prices don’t always occur simultaneously, so sometimes the prices get out of whack compared to their long-term behavior. If Pepsi goes up a little bit but Coca-Cola doesn’t, upsetting the usual relationship, you buy Coca-Cola and sell Pepsi because you have good reason to think that the two prices will soon revert to normal. Farmer and Packard didn’t come up with pairs trading — it was largely pioneered in the 1980s at Morgan Stanley, by an astrophysicist named Nunzio Tartaglia and a computer scientist named Gerry Bamberger — but they did bring a new level of rigor and sophistication to the identification and testing of the statistical relationships underlying the strategy. This sophistication was purely a function of the tools that Farmer*  

- Page 167 (location ~ 2556-2565)    

*One strategy they used was something called statistical arbitrage, which works by betting that certain statistical properties of stocks will tend to return even if they disappear briefly. The classic example is pairs trading. Pairs trading works by observing that some companies’ stock prices are usually closely correlated. Consider Pepsi and Coca-Cola. Virtually any news that isn’t company-specific is likely to affect Pepsi’s products in just the same way as Coca-Cola’s, which means that the two stock prices usually track one another. But changes in the two companies’ prices don’t always occur simultaneously, so sometimes the prices get out of whack compared to their long-term behavior. If Pepsi goes up a little bit but Coca-Cola doesn’t, upsetting the usual relationship, you buy Coca-Cola and sell Pepsi because you have good reason to think that the two prices will soon revert to normal. Farmer and Packard didn’t come up with pairs trading — it was largely pioneered in the 1980s at Morgan Stanley, by an astrophysicist named Nunzio Tartaglia and a computer scientist named Gerry Bamberger — but they did bring a new level of rigor and sophistication to the identification and testing of the statistical relationships underlying the strategy.*  

- Page 167 (location ~ 2556-2565)    

*Another one of the Prediction Company’s ideas was to use many different models at once, each based on different simplified assumptions about the statistical properties of different assets. Farmer and Packard developed algorithms that allowed the different models to “vote” on trades — and then they adopted a strategy only if their models were able to form a consensus that it would likely be successful. Voting may not sound as if it has anything to do with physics, but the underlying idea comes right from Farmer’s and Packard’s days studying complex systems. Allowing many different models to vote identifies which trading strategies are robust, in the sense that they aren’t sensitive to the special details of a particular model. There is a close connection between searching for robust strategies and searching for attractors in a complex system, since attractors are independent of initial conditions. This kind of modeling, where one uses algorithmic methods to identify optimal strategies, is often called “black box” modeling in the financial industry. Black box models are very different from models like Black-Scholes and its predecessors, whose inner workings are not only transparent but often provide deep insights into why the models (should) work. Black box models are much more opaque, and as a result they are often scarier, especially to people who don’t understand where they come from or why they should be trusted. Black box models were occasionally used before the Prediction Company came along, but the Prediction Company was one of the very first companies to build an entire business model based on them. It was a whole new way of thinking about trading.*  

- Page 169 (location ~ 2589-2601)    

*Shortly after Farmer and Heimark met, Farmer received a phone call from another O’Connor partner, named David Weinberger. Weinberger had been one of the very first quants, leaving a teaching job in operations research (essentially, a branch of applied mathematics) at Yale to work for Goldman Sachs in 1976, even before Black arrived. He’d moved to O’Connor in 1983, to help that company come up with new strategies as more and more companies got on the Black-Scholes bandwagon. He was one of the few people in the industry, even in 1991, who both was high powered enough to make a deal and also spoke the language of the scientists running the Prediction Company. He called on a Friday afternoon, from Chicago. On Saturday morning, he was sitting in the Griffin Street office. O’Connor turned out to be just the kind of firm that the Prediction Company wanted to work with — in large part because the people working at O’Connor were able to understand what Farmer and Packard were doing well enough to evaluate it themselves. Under the deal they ultimately negotiated, the Prediction Company maintained its independence. O’Connor put up the investment capital, in exchange for the majority of the proceeds; it also fronted the Prediction Company the funds it so desperately needed in order to pay salaries and buy equipment in the meantime.*  

- Page 171 (location ~ 2616-2625)    

*The Prediction Company, following the O’Connor tradition as a secretive high-tech firm, never released any metrics of its success publicly — and none of the former principals or board members with whom I spoke were authorized to share any concrete information. This might seem suspicious. After all, if you’re successful, why hide it? Here, though, the opposite is the case: on Wall Street, success breeds imitation, and the more firms there are implementing a strategy, the less profitable it is for anyone. There are some indications, however, that the Prediction Company has been wildly successful. As one former board member I spoke with pointed out, it is still an active subsidiary of UBS, after more than a decade. Another knowledgeable source told me that, over the firm’s first fifteen years, its risk-adjusted return was almost one hundred times larger than the S&P 500 return over the same period. Farmer stayed with the firm for about a decade before his passion for research lured him back to academia. He took a position at the Santa Fe Institute as a full-time researcher in 1999. Packard stayed with the company for a few more years, serving as CEO until 2003, when he left to start a new company, called ProtoLife. By the time they left, they had made their point: a firm grasp of statistics and a little creative reappropriation of tools from physics were enough to beat the Man. It was time to tackle a new set of problems.*  

- Page 172 (location ~ 2634-2644)    

*In the end, though, data outclass theory. This means that no matter how good the theoretical backing for your (non–black box) model, you ultimately need to evaluate it on the basis of how well it performs. Even the most transparent models need to be constantly tested by just the same kinds of statistical methods that are used to evaluate black box models. The clearest example of why this is so can be found by looking at the failure of the Black-Scholes model to account for the volatility smile in the aftermath of the 1987 crash. Theoretical backing for a model can be a double-edged sword: on the one hand, it can help guide practitioners who are trying to understand the limits of the model; conversely, it can lull you into a sense of false confidence that, because you have some theoretical justification for a model, the model must be right. Unfortunately science doesn’t work this way. And from this latter point of view, black box models have an advantage over other, more theoretically transparent models, because one is effectively forced to evaluate their effectiveness on the basis of their actual success, not on one’s beliefs about what ought to be successful. There’s another worry about black box models, above and beyond their opaqueness. All of the physicists whose work I have discussed thus far, from Bachelier to Black, have argued that markets are unpredictable. Purely random. The only disputes concern the nature of the randomness, and whether they are well enough behaved to be treated by normal distributions. In the years since it was first observed by Bachelier and Osborne, the idea that markets are unpredictable has been elevated to a central tenet of mainstream financial theory, under the umbrella of the efficient market hypothesis.*  

- Page 173 (location ~ 2651-2663)    

*It’s reasonable to be skeptical about the company’s success. Investing can often come down to luck. That markets are random is not just conventional wisdom in economics departments. There’s an enormous amount of statistical evidence to support it. Then again, perhaps the idea that markets are random because they are efficient — in the sense that market prices quickly change to account for all available information concerning the expected future performance of a stock — is not necessarily in conflict with the Prediction Company’s success. It sounds like a paradox. But think about the basis for the efficient market hypothesis. The standard argument goes something like this: Suppose that there was some way to game the markets; that is, suppose that there was some reliable way to predict how prices are going to change over time. Then investors would quickly try to capitalize on that information. If markets are always at a local high in the last week of May, or if they always drop on the Monday following a Giants victory, then as soon as the pattern gets noticed, sophisticated investors will start selling stocks at the end of May and buying them as soon as the Giants win — with the result that prices will drop at the end of May and rise on Mondays after Giants victories, essentially washing out the pattern. Sure enough, every time an economist appears to find an anomalous pattern in market behavior, it seems to correct itself before the next study can be done to confirm it.*  

- Page 174 (location ~ 2667-2677)    

*Sornette had been working his way into finance for several years, but even so he was still a physicist. Ledoit knew the financial industry and could help him figure out the next steps. The two settled on a plan. First, they would file their warning with the authorities. Sornette and his postdoctoral researcher at UCLA, another geophysicist-cum-economist named Anders Johansen, wrote a notice and sent it to the French patent office. No one would believe them now, of course — none of the traditional methods of analyzing markets pointed to instability. And if they waited until after the crash, no one would believe them either, though for a different reason: their voices would be lost among the thousands of economists and investors who would insist they had seen this coming. The patent filing would be their insurance policy, their proof that they really had made the prediction, over a month before the crash. The notice was filed on September 17, 1997. It predicted a market crash in late October of that same year. The second step? Profit. It’s easy to make money when markets are rising. But in many ways, a market crash is an even more dramatic profit opportunity, if you can see it coming. There are several ways to make money off a crash, but the simplest way is buying put options. The options I discussed earlier are known as call options. You buy the right to purchase a stock at some fixed price, called the strike price, at some time in the future. If the market value of the stock goes above the strike price, you profit, because you have the right to buy the stock at the strike price, and then sell it at the higher market price, pocketing the difference. Of course, if the price doesn’t go up, that’s OK too. You’re only out the money spent on the option, and not the higher price of the stock itself. Put options work in essentially the opposite way. You buy the right to sell a stock at a specific price. In this case, you profit if the price of the stock falls below the strike price, because you can buy the stock at the market price and sell it at the higher strike price, again pocketing the difference.*  

- Page 177 (location ~ 2713-2727)    

*Imagine inflating a balloon. You start with a limp piece of rubber. In this uninflated state, the balloon is stretchy and very difficult to tear. You could poke it and prod it any way you like, even with a very sharp knife, and unless you stretch the balloon out first, the knife is unlikely to puncture it. A pin would do no damage at all. Now begin to blow air into it. After a few puffs, the balloon starts to expand. The pressure from the air inside is pushing the walls of the balloon out, just enough to give the surface a roughly spherical shape. The material still has considerable give. Depending on how much air has been pumped in, a very sharp knife might now slice the rubber, but the balloon certainly won’t pop, even if you manage to puncture it. A puncture would allow the air inside to leak, but it wouldn’t be very dramatic. As you blow more air into the balloon, however, it becomes increasingly sensitive to outside effects. A fully inflated balloon is liable to pop from the slightest brush with a tree branch or a bit of concrete — a tap from a pin is certain to make it explode. Indeed, if you keep blowing air into a balloon, you can make it burst by touching it with your fingertips, or by simply blowing in another mouthful of air. Once the balloon is primed, it doesn’t take much to produce a very dramatic effect: the balloon shreds into tiny pieces faster than the speed of sound. What makes a balloon pop? In some sense, it’s an external cause: a tree branch or a pin, or perhaps the pressure from your fingers as you hold it. But these very same influences, under most circumstances, have little or no effect on the balloon. The balloon needs to be inflated, or even overinflated, for the external cause to take hold. Moreover, the particular external cause doesn’t much matter — it’s far more important that the balloon be highly inflated when it is pricked. In fact, the external cause of a popped balloon isn’t what makes the balloon pop at all. It’s the internal instability in the balloon’s state that makes it susceptible to an explosive pop. The bursting of a balloon is one of a variety of phenomena known as ruptures. Ruptures occur in all sorts of materials when they are put under stress. A rupture can often be thought of as a straw-that-broke-the-camel’s-back effect: the stress on a substance, such as high internal pressure (caused, for instance, by the air in a balloon, or the gas in a soda can that has been shaken up — or the accumulated weight on a camel’s back), leads to instabilities that in turn make the material vulnerable to explosive events. These explosions, sometimes called critical events, are the ruptures. Just as when a balloon bursts, a rupturing material changes its state very rapidly, releasing a substantial amount of energy in the process. Events that might otherwise have little effect, like a pin breaking the surface of an only partially inflated balloon, tend to cascade, building into something larger.*  

- Page 179 (location ~ 2732-2753)    

*But Sornette has made contributions to more than a dozen fields, ranging from material science to geophysics, to decision theory (a branch of economics and psychology), to financial markets, even to neuroscience (he has done considerable work on the origin and prediction of epileptic seizures). He thinks of himself as a scientist in the broadest sense, as someone conversant in the sciences at large. He studied physics as a young man, not because he believed he wanted to devote his life to the field, but because he thought of physics as a kind of mother science. He likes to quote the philosopher Descartes, who in his magnum opus Discourse on Method wrote that the sciences are like a tree: metaphysics is the roots, physics is the trunk, and everything else is the branches. (Nowadays, Sornette is more modest about his training. He thinks of his background in physics as an excellent preparation for approaching many problems but says that the intellectual challenges of fields like economics and biology are at least an order of magnitude more difficult than those posed by physics.) Despite the variety of topics, however, much of Sornette’s work involves identifying patterns endemic to the structures of complex systems and using these patterns to predict critical phenomena: ruptures, quakes, crashes.*  

- Page 180 (location ~ 2758-2767)    

*We know that if a balloon is inflated sufficiently, it will nearly always pop when pricked with a sharp pin. Other substances, though, can be trickier to figure out. Materials like Kevlar will eventually rupture from the strain of high-pressure contents, but determining precisely when, or why, is a surprisingly difficult problem. When substances like Kevlar are put under significant stress, tiny fractures begin to appear. Sometimes these fractures combine and grow into slightly larger fractures. Sometimes these slightly larger fractures grow into still-larger fractures, and so on, until you get a very large fracture. These fractures follow a pattern we have already seen: they are fractals, where the tiniest fractures look just like the larger ones. The difficulty is that tiny fractures don’t affect the behavior of the pressure tanks, whereas the largest fractures can be disastrous. But it’s hard to say what makes a large fracture different from a small one, at least in terms of the fractures’ causes. A large fracture is just a small one that never stopped growing; very large, disruptive fractures are no different in kind from the very small benign ones. This relationship between large and small fractures posed a major problem for the rocket scientists. It meant that even under ordinary working conditions, when the Kevlar was usually stable, there was always a chance that a normal tiny fracture would spontaneously grow into a major one and destroy the rocket. Any given fracture, even the very smallest ones, had the capacity to become explosive. When Sornette joined the team, the other scientists were at a loss. To put these pressure tanks to good use, they needed to figure out how to use them safely — that is, they needed to figure out the conditions under which ruptures would occur.*  

- Page 182 (location ~ 2788-2801)    

*Normally, the parts of a pressure tank are more or less independent, like workers in the nineteenth century, before collective bargaining. If you kick a pressure tank, for instance, there might be some vibrations, but these will die off pretty quickly, and even if you manage to put a dent in the part of the tank where your foot made contact (unlikely), you won’t do any damage to the rest of the tank. Likewise, if a small fracture appears under these circumstances, it won’t produce a rupture. This is a bit like when you try to pop an only partially inflated balloon: a pin doesn’t have much of an effect. Sometimes, though, the various parts of the material begin to conspire with one another. They display a kind of herding effect. This can happen for various reasons: heat, say, or pressure, or other external effects. When this occurs, it’s almost as if the various parts of the material have unionized. A kick in one place can ripple through a whole tank, with small localized influences leading to dramatic effects, much as a pinprick in one place can make an inflated balloon tear itself apart. This kind of conspiracy is sometimes called self-organization, because no matter how random and uncorrelated the materials are to begin with, if they are placed under stress, they will begin to coordinate their activity. It’s as though the bits and pieces of material begin to stir under pressure, gradually deciding to join together in common cause. Sornette didn’t come up with the notion of self-organization, though he has done as much work on the theory as anyone. Instead, he realized something slightly different. He finally understood how a small labor strike differs from a catastrophic one. All strikes are caused by the same sorts of sparks: an egregious injury; an unfair termination; cut wages. You might think that there’s no way of telling which such events will lead to a nationwide walkout. A large strike looks like a small strike that, for whatever reason, simply didn’t stop. So, too, with the microfractures that, under some circumstances, seem to explode into ruptures that tear a material apart. But the biggest strikes require something more than just a spark: they require a labor movement, with a high degree of structure and a capacity for coordinated action. They require a mechanism for system-wide feedback and amplification, something to transform an otherwise small event into a large one. In other words, if you want to predict a major strike, don’t look for the grievances. Those are always there. Look for the unions. Look for telltale patterns of self-organization. Coordination, rather than the pinpricks, is what really leads to critical events. And Sornette would take that insight straight to the bank.*  

- Page 183 (location ~ 2802-2821)    

*Tectonic plates were originally proposed to explain the strange evidence that the continents were once connected — for example, certain varieties of plant are found only in western South America and eastern Australia — but they are now believed to be responsible for things like earthquakes (which occur when two plates collide or shift past one another), mountain ranges (which form when the plates collide, buckling at the collision site), volcanoes (which erupt at the interface between plates, where magma from below the crust can escape), and ocean trenches (the opposite of mountain ranges). The Sornettes’ work was an attempt to understand how the current geology and topography of the divide between Asia and India — a stretch of land as long across as the continental United States, spanning the Himalayas and a handful of smaller mountain ranges — could arise as a result of many small earthquakes over millions of years, as the two continents collided with one another. Geophysicists study a broad swath of topics concerning the internal structure of planets. But their bread and butter, the research that gets funding agencies most excited, is predicting natural disasters like earthquakes and volcanoes. Earthquake prediction is a matter of particular importance, for both scientific and humanitarian reasons. It is also famously difficult, though this hasn’t stopped scientists, and before that philosophers and astrologers, from trying their hand. The ancient Roman historian Aelian, for instance, hinted that animals could accurately predict earthquakes, claiming that snakes and weasels evacuated the Greek city of Helice a few days in advance of an earthquake that devastated the region. An ancient Indian astrologer and mathematician named Varahamihira believed that earthquakes could be predicted by looking for particular cloud patterns.*  

- Page 186 (location ~ 2839-2851)    

*The moment of inspiration came two years later, in 1991. By this time, he and others had developed a detailed model for how fractures and cracks percolate through a material. This model accounted for how degrees of organization and coordination could serve to amplify fractures, to turn small causes into large effects. It was while thinking about this model that Sornette realized that if all of the pieces were in place for a critical event, an explosive rupture, the way in which the fractures leading up to the rupture would multiply would be affected. The idea was that a rupture would be preceded by smaller events, following a very specific, accelerating pattern. This pattern is called log-periodic because the time between the smaller events decreases in a particular way, related to the logarithm of the time. Since this pattern would occur only if the system were primed for a rupture, it counted as a signal that a critical event was about to occur. And because the pattern was one that accelerated over time, if you looked at a few of the smaller events in a row, you could determine whether they were showing the log-periodic behavior (because the time between the events would be shrinking), and you could extrapolate forward in time to figure out when the peaks would collapse into one another, thus predicting the critical event.*  

- Page 187 (location ~ 2862-2871)    

*Historians now explain the worldwide crash as a reverberation effect. Earlier that year, the Thai baht collapsed after the Thai government decided to stop pegging it to the U.S. dollar. Thailand carried significant foreign debt before the collapse of the currency, and afterward the country was essentially bankrupt. Thailand’s difficulties quickly spread to its neighbors, earning the nickname “Asian flu” for the crisis because of the way it moved through Southeast Asian economies, devaluing currencies and depressing equity markets throughout the region. These conditions increased uncertainty in all parts of the world’s economy, leading to unusually high variations in the prices of securities. When Asian markets fell overnight on the twenty-sixth, investors in the United States reacted strongly and amplified the crash. One of the most striking things about the October 27 crash, and the reason it is now referred to as a “mini crash,” is that New York markets rebounded the next day. By the close of trading on the twenty-eighth, the Dow had regained 60% of the previous day’s losses. And in a striking counterpoint to closing its doors early for the first time the day before, October 28 was the first day that over a billion shares were traded on the NYSE. This kind of dramatic seesawing is telling: since the cumulative effect of the crash and rebound was a relatively modest change in prices, standard reasoning about pricing in an efficient market does not seem to apply. That is, any theory of the stock market that accounts for price changes in terms of the actual values of the companies whose stocks are being traded would predict that a crash would correspond to some dramatic change in the real-world values. But this didn’t happen. Stocks were worth more or less the same amount on October 29 as they had been on October 26, indicating that most investors didn’t think the values of the companies had changed all that much. Instead, it seems that the crash resulted from some sort of internal instability in the markets themselves.*  

- Page 189 (location ~ 2898-2912)    

*According to Sornette and his collaborators, this is a feature that shows up in many market crashes. As he is fond of pointing out, the standard economic reasoning suggests that if bubbles are possible at all, they can end only with some dramatic news that materially changes the value of firms whose stocks are being traded. And yet, many economists agree that if you look at particular crashes, it is often very hard to identify what that piece of news could have been. Sure, there’s always some piece of bad news to associate with a market crash. But one is often stuck blaming extreme events on run-of-the-mill external causes that do not seem to change the value of the things being traded. This alone should be highly suggestive, at least to someone who is accustomed to thinking about critical phenomena in physics, because it implies that even if a piece of news is the immediate cause of a crash, there is something about the state of the market that determines whether the market actually crashes, or just closes a few points lower. And as with ruptures and earthquakes, Sornette argues, even if you cannot predict the news, you can try to identify when the market is in a precarious state. Just look for the log-periodic tremors.*  

- Page 190 (location ~ 2912-2920)    

*Sornette’s first foray into economics was in 1994. He coauthored a paper with another physicist in France, named Jean-Philippe Bouchaud. That same year, Sornette and Bouchaud went on to found a research company called Science & Finance, which in 2000 merged with a Parisian hedge fund management company, Capital Fund Management (CFM). Today Bouchaud is chairman and chief scientist of CFM, which has grown to be the largest hedge fund management company in France. (He is still officially a physics professor, at École Polytechnique, the grande école near Paris where Mandelbrot studied; Sornette, meanwhile, left Science & Finance in 1997.) Their joint paper showed how to price options even if the underlying stock does not follow the kind of random walk assumed by Black and Scholes. This effectively extended the theory of options pricing to more sophisticated models of price changes, including those with fat-tailed distributions. (O’Connor and Associates had already done work along these lines — but this wasn’t widely known.) After that paper, Sornette was hooked. Over the next several years, he read more and more about traditional economics, adding what he could to problems like options pricing and risk. (Sornette prides himself on having learned to think like an economist.) Much of this early work was done in collaboration with Bouchaud, who by this time was working on finance nearly full-time.*  

- Page 191 (location ~ 2929-2938)    

*As with his theories of material rupture and earthquakes, the central idea behind Sornette’s market-crash-as-critical-event hypothesis involves collective action, or herding behavior. By itself, this is hardly surprising, as the suggestion that market crashes have something to do with mob psychology is old: in 1841, Charles Mackay wrote a book on, among other things, economic bubbles that he called Extraordinary Popular Delusions and the Madness of Crowds. There, he pointed to several historical cases in which entire countries had been taken by some sort of frenzy, leading to speculative bubbles — market conditions under which prices become entirely divorced from the value of the things being traded. Perhaps the most striking example occurred in the Netherlands in the early seventeenth century. The subject of speculation was tulip bulbs. Tulips originated in Turkey but made their way into western Europe, via Austria, in the middle of the sixteenth century. The flowers were considered very beautiful and were highly prized by the European aristocracy, but the real money was in tulip bulbs, which could be used both to produce the flowers and to produce new bulbs. Tulips came to represent Dutch imperial power. The country’s new merchant class, made wealthy by trade in the Dutch East and West Indies, would broadcast its power and prestige with ornate flower gardens, with tulips as the centerpiece.*  

- Page 193 (location ~ 2945-2955)    

*By 1635, trades worth 2,500 Dutch guilders (worth roughly $30,000 in 2010 dollars) for a single bulb were recorded. Trades of 1,500 guilders were common. In contrast, a skilled laborer could expect to make about 150 guilders in a year. Around this time, foreign money began to pour into the market as outsiders tried to make a quick buck in the tulip game. The Dutch were thrilled. They took the foreign investment to mean that all of Europe was catching on to their tulip craze, and so they doubled down: ordinary people sold their belongings, mortgaged their houses, and exhausted their savings to participate in the tulip market. Tulips bulbs are typically planted in the fall and then harvested in the late spring. But winter was the prime time for speculation because this was when would-be investors had the least information about the supply for the coming year: the old bulbs had been planted but the new bulbs and cut flowers were not yet available. It was during the winter of 1636–37 that tulip mania (as it is now called) reached its height. That winter, a single bulb sold for as much as 5,200 guilders (more than $60,000 for one tulip bulb!). And then one day in February 1637, at an otherwise ordinary tulip auction in Haarlem, the bidding stopped too soon. Apparently no one had invited the next batch of tulip fools. That day, prized tulips sold for just a fraction of what they had even one day before. Panic spread quickly, and within days prices had fallen to less than 1% of their height. Fortunes that had been made overnight vanished by morning. The Dutch economy teetered, until ultimately the government needed to intervene.*  

- Page 193 (location ~ 2956-2967)    

*Herding and similar phenomena — the kinds of behavior that lead to bubbles — seem to be an ever-present aspect of human psychology. No one wants to be left out, and so we tend to copy one another. Ordinarily, though, we do not act like lemmings. Even if we look to one another for guidance, we do not usually follow blindly. The question, then, is why under some circumstances herding seems to take over. How does something like tulip mania strike? When do the normal mental brakes that would keep someone from spending his entire life savings on a tulip bulb give out? Sornette doesn’t have an answer to this question, though he has developed some models that predict which circumstances will lead herding effects to become particularly strong. What Sornette can do is identify when herding effects have taken over. This amounts to identifying when a speculative bubble has taken hold in a particular market and to predicting the probability that the bubble will pop before a certain fixed time (the critical point).*  

- Page 194 (location ~ 2967-2974)    

*Still, he does think there is something special about finance and economics. Many people go into science because of some urge to understand how the world works. But, Sornette believes, the physical world is only part of the story. He is just as interested, perhaps more interested, in how the social world works. Gravity may keep the planet in orbit, but, as the emcee in the musical Cabaret sings, money makes the world go round. And financial markets determine how money flows. As Sornette puts it, finance is the “queen, and not the maid.” It controls everything. And whatever your political position on the role of financial markets in global geopolitics, Sornette believes that the very fact that financial markets and the people who run them do have so much social power is a sufficient reason to look closely at how they work.*  

- Page 195 (location ~ 2980-2986)    

*Since first predicting the October 1997 crash, Sornette has had a remarkable track record of identifying when market crashes will occur. He saw the log-periodic pattern in advance of the September 2008 crash, for instance, and was able to predict the timing. Similarly, the 1998 collapse in the Russian ruble that brought Long-Term Capital Management to its knees showed the signs of an impending crash — indeed, Sornette has claimed that even though the largely unanticipated Russian debt default may have triggered the market turmoil that summer, the crash showed the log-periodic precursors characteristic of herding behavior. This means that a market crash would likely have occurred during that period whether the ruble had collapsed or not. The balloon was already in a primed state; Russia’s default was just the pinprick.*  

- Page 195 (location ~ 2986-2992)    

*Sornette started seeing the log-periodic oscillations in NASDAQ data beginning in late 1999. By March 10, 2000 — the day the NASDAQ peaked — he had enough data to say the crash was imminent, and to predict when it would occur. He put the date somewhere between March 31 and May 2. Sure enough, during the week beginning April 10, the NASDAQ fell by 25%. Tech stocks had gone the way of the tulip bulb. The methods Sornette has used to identify bubbles and predict when crashes will occur can also be used to identify a situation that Sornette has called an anti-bubble. These are cases in which stock prices are artificially low. On January 25, 1999, for instance, Sornette posted a paper on an online physics archive claiming that, based on his observation of log-periodic patterns in the market data, the Japanese Nikkei stock index was in the midst of an anti-bubble. The paper included quite precise predictions: Sornette indicated that by the end of that year, the Nikkei would increase by 50%. This prediction was all the more remarkable because the Japanese market was near its fourteen-year low, which it reached on January 5, 1999. All indications were that the market would continue to fall — an opinion held by most economists at the time. Nobel Prize laureate and New York Times opinion columnist Paul Krugman, for instance, wrote on January 20 that the Japanese economy was beginning to look like a tragedy, and that there simply wasn’t enough demand for a recovery. But time proved Sornette right. By the end of the year, the Nikkei had recovered, by precisely the 50% Sornette predicted.*  

- Page 196 (location ~ 2999-3011)    

*In his book The Black Swan, Taleb explains that some events — he calls them “black swans” — are so far from standard, normal distribution expectations that you cannot even make sense of questions about their likelihood. They are essentially unpredictable, and yet when they occur, they change everything. Taleb takes it to be a consequence of Mandelbrot’s arguments that these kinds of extreme events, the events with the most dramatic consequences, occur much more frequently than any model can account for. To trust a mathematical model in a wildly random system like a financial market is foolish, then, because the models exclude the most important phenomena: the catastrophic crashes. Recently, Sornette introduced a new term for extreme events. Instead of black swans, he calls them “dragon kings.” He used the word king because, if you try to match plots like Pareto’s law — the fat-tailed distribution governing income disparity that Mandelbrot studied at IBM — to countries that have a monarchy, you find that kings don’t fit with the 80–20 rule. Kings control far more wealth than they ought to, even by the standards of fat tails. They are true outliers. And they, not the extremely wealthy just below them, are the ones who really exert control. The word dragon, meanwhile, is supposed to capture the fact that these kinds of events don’t have a natural place in the normal bestiary. They’re unlike anything else. Many large earthquakes are little ones that, for whatever reason, didn’t stop. These are not predictable using Sornette’s methods. But dragon-king earthquakes, the critical events, seem to require more. Like ruptures, they happen only if all sorts of things fall into place in just the right way. A good example of a dragon king is the city of Paris. France’s cities follow Zipf’s law remarkably well. The distribution of cities in France is fat-tailed, in that the very biggest cities are much bigger than the next biggest cities. But if you plot the size of French cities by their population size, as Zipf’s law would have you do, Paris is still much too big. It breaks the mold.*  

- Page 197 (location ~ 3021-3035)    

*Together, Malaney and Weinstein developed an entirely novel way of solving the index number problem by adapting a tool from mathematical physics known as gauge theory. (The early mathematical development of modern gauge theory — the topic on which Weinstein wrote his dissertation — was largely the work of Jim Simons, the mathematical physicist turned hedge fund manager who founded Renaissance Technologies in the 1980s.) Gauge theories use geometry to compare apparently incomparable physical quantities. This, Malaney and Weinstein argued, was precisely what was at issue in the index number problem — although there, instead of incomparable physical quantities, one was trying to compare different economic variables. It was an unusual, highly technical way of thinking about economics. This made Malaney a little nervous, since she didn’t know how economists unaccustomed to such high-level mathematical analysis would react. But she decided to pursue the project for her dissertation after she showed it to her advisor, a superstar in the Harvard economics department named Eric Maskin. (He would go on to win the 2007 Nobel Prize in economics, for work he had already done before meeting Malaney.) Maskin told her the idea was great. He believed she’d made real progress on an important topic, one with long-term political and economic implications. She finished the dissertation during the summer of 1996 and began to think about applying for tenure-track jobs at top research universities. With such a groundbreaking thesis topic and the support of her advisor, she had every reason to think she’d be a competitive candidate for these highly desirable positions. She was living the academic dream.*  

- Page 202 (location ~ 3084-3096)    

*doesn’t have intrinsic value. The value of money comes from what you can do with it. Perhaps*  

- Page 202 (location ~ 3097-3097)    

*How much is money worth? This might seem like an odd question. For most people, money doesn’t have intrinsic value. The value of money comes from what you can do with it. Perhaps money can’t buy you love, but it sure can buy you orange juice, or a pair of pants, or a new car. And over time, the amount of money it takes to buy that same orange juice, pair of pants, or new car changes. Usually, goods become more expensive over time (at least if you look at the price tags alone); grandparents the world over will tell you how little a chocolate bar used to cost, or a movie ticket. A nickel, we’re told, went a lot farther in 1950 than it does now. This decrease in the value of money over time is what we usually call inflation. But how do you measure inflation? It’s not as though all prices go up evenly across the board. Even as some goods have become more expensive with time, others have become cheaper. Consider that the price tag for an Apple II, one of the first mass-produced personal computers, with a breakneck processor speed of 1MHz and a whopping 48KB of memory, was $2,638 when it first went on sale in 1977. Nowadays, almost thirty-five years later, you can get a desktop computer with a processor over three thousand times as fast, and with a hundred thousand times more memory, for a fraction of that — just a few hundred dollars. So what if chocolate is more expensive: computing power is now dirt cheap by 1970s standards. One way in which economists deal with this problem is by looking at how prices change across a broad range of products. They do this by tracking the price of what is called a standard market basket: an imaginary shopping cart filled with groceries and household commodities like gasoline and heating oil, as well as services like education, medical care, and housing. This is what’s used to calculate the CPI, which is effectively the average price of the various goods and services in the cart. By looking at price changes for many different items in this way, you can get a rough estimate of how far a dollar (or a euro, or a yen) goes today, as compared to sometime in the past. Gasoline prices might spike over the course of a few months, while computer prices might drop gradually over a few years, but the change in the standard market basket is supposed to be a relatively stable indication of how much spending power changes with time.*  

- Page 202 (location ~ 3096-3113)    

*The CPI is a blunt tool. Virtually everyone in economics agrees that we need to find some way to hone it. Still, it is incredibly important for policymaking because of its central role in determining inflation, which in turn affects virtually every aspect of the budget. In the United States, for instance, the thresholds for tax brackets are tied to the stated rate of inflation. So are wage increases for government employees. Social Security outlays are also determined by inflation. Every year, these quantities are recalculated based on the inflation rate of the previous year, to adjust for changes in the cost of living. In June 1995 the U.S. Senate appointed the Advisory Commission to Study the Consumer Price Index, usually called the Boskin Commission after Michael Boskin, the Stanford economics professor who chaired it. The brainchild of soon-to-be-disgraced Senator Bob Packwood, then chairman of the Senate Finance Committee, the Boskin Commission was charged with coming up with a better way to compute the CPI, and by extension inflation. For Malaney and Weinstein, the Boskin Commission seemed like a godsend. A Senate-appointed committee tasked with solving just the problem that they had chosen to tackle made Malaney and Weinstein’s work immediately relevant. It was the perfect opportunity for them to make a contribution — not just to economic theory, but potentially to public policy, since Packwood planned to implement the Boskin Commission’s findings immediately. Even better, one of the economists appointed to the commission, Dale Jorgenson, was a member of the Harvard economics department.*  

- Page 204 (location ~ 3128-3139)    

*Weyl wasn’t ETH’s only recent hire, however. As part of the restructuring, the school had made a number of appointments to the physics department. One of these was a prominent young physicist, an undergraduate alumnus of ETH named Albert Einstein. Einstein had gone on to do a PhD in physics at the University of Zürich, graduating in 1905 — the same year that he published a mathematical treatment of Brownian motion (anticipated, of course, by Bachelier), came up with a theory of the photoelectric effect (for which he would win the Nobel Prize in 1921), and discovered the special theory of relativity, including his famous equation e = mc  2. And yet, none of this led to much success for Einstein. After finishing graduate school, he moved about 150km away to Bern, where the only job he could find was as a patent clerk. Occasionally, he was permitted to teach at the local university. Gradually, however, as more physicists came to understand the importance of the 1905 papers, Einstein’s reputation grew. In 1911, he was offered a professorship at the German university in Prague; the next year, his alma mater offered him a job. By the time Einstein returned to Zürich, he was already a shining star of the physics community. His reputation had exploded in just a few years. He didn’t stay at Zürich for long — in 1914, he was appointed director of the Kaiser Wilhelm Institute in Berlin — but the year that Einstein and Weyl spent together was enough to change the course of Weyl’s research. Though initially a mathematician in the purest sense, Weyl found Einstein’s relativity theory captivating, particularly because when they met, Einstein was just beginning to realize the importance of high-powered modern geometry to the theory. The basic idea underlying general relativity is that matter — ordinary stuff like cars and people and stars — affects the geometrical properties of space and time. This geometry, meanwhile, determines how bodies move. It is this movement of massive objects through deformed space and time that we ordinarily think of as gravitation, the physical phenomenon that keeps us firmly planted on the surface of the Earth, and that keeps the Earth in its elliptical orbit around the sun. The general relativistic picture is as different as can be from the older, Newtonian theory of gravity. In Newtonian gravitation, space and time are static. Their properties are unrelated to the matter that’s distributed through space. Bodies gravitate toward one another via an unexplained force that acts instantaneously at a distance. Matter affects space and time in Einstein’s theory by inducing curvature. When physicists and mathematicians say something is “curved,” they mean just what we would ordinarily mean. A tabletop or an unfolded piece of paper is flat; a basketball or a paper towel roll is curved. But from a mathematical point of view, the thing that distinguishes a tabletop from a basketball isn’t that a basketball rolls and a table doesn’t, or that it’s easier to stand on a table than on a basketball. Instead, the feature that characterizes curvature for a mathematician is how hard it is to keep an arrow pointing in the same direction as you move it around the surface. If an object is flat, it turns out to be very easy. Not so if the object is curved.*  

- Page 206 (location ~ 3146-3170)    

*Einstein’s theory of general relativity makes essential use of the fact that space and time are curved in the sense that parallel transport is path dependent. But Weyl thought that Einstein hadn’t gone far enough. In general relativity, if you begin with an arrow at one place and then move it around a path that brings it back to the starting point, it might face a different direction. But it will always have the same length. Weyl thought this was an arbitrary distinction that couldn’t have physical meaning, and so he came up with an alternative theory in which length, too, was path dependent, so that if you moved a ruler around two different closed paths, it would have different lengths when it returned to the starting point, depending on the path it took. Weyl called his new theory a gauge theory. It was the first time the term had been used, and it was based on the idea that there was no universal, once-and-for-all way to “gauge,” or measure, the length of a ruler. Suppose you and your neighbor are both about to leave your driveway in the morning on the way to work. Imagine you drive identical cars, and you both work at the same location. What would you say if someone stopped you and asked which car would have more gasoline in the tank when you both got to work, yours or your neighbor’s? You might glance at your gas gauge and see that you have a full tank, and then ask your neighbor how much gas he has. But this isn’t enough information to answer the question. The answer will depend on the paths you and your neighbor take to work: you might take a direct route, while the neighbor takes the scenic route. Your neighbor might take a highway, while you stick to city streets. Whatever the case may be, how much gasoline each of you has left at the end of your journeys will depend on the paths you take to work.*  

- Page 210 (location ~ 3214-3227)    

*Weyl’s theory wasn’t a success. Einstein quickly pointed out that it was inconsistent with some well-known experimental results, and it was soon relegated to the dustbins of scientific history. But Weyl’s basic idea about gauge — that to determine if two quantities are equal in a physical theory, you need a standard of comparison that accounts for possible path dependence — was destined to be far more important than the theory that led to it. Gauge theory was resurrected in the 1950s by a pair of young researchers at Brookhaven National Laboratory named C. N. Yang and Robert Mills. Yang and Mills took Weyl’s theory one step further: If it was possible to construct a theory in which length was path dependent, was it possible to construct theories in which still other quantities were path dependent? The answer, they realized, was yes. They went on to develop a general framework for much more complicated gauge theories than the one Weyl had imagined. These theories, now known as Yang-Mills theories, spawned what is sometimes called the gauge revolution. Beginning in 1961, fundamental physics was rewritten in terms of gauge theory — a process that only accelerated when Yang, in collaboration with Jim Simons of Renaissance, realized a deep connection between Yang-Mills gauge theories and modern geometry later that decade. Gauge theories proved particularly important in physics because they proved to be a natural setting to look for “unified” theories, where what was being unified was the standard by which different quantities were compared in the theories. By 1973, it appeared that the three fundamental forces of particle physics — electromagnetism, the weak force, and the strong force — had been unified into a single gauge-theoretic framework. This framework was called the Standard Model of particle physics. Today, it is the single best-confirmed theory ever discovered, in any field. It is the very heart of modern physics.*  

- Page 211 (location ~ 3236-3249)    

*Ronald Coase was a British economist who spent most of his career in the United States, at the University of Chicago. He was interested in something he called “social cost.” Imagine you are the local sheriff in an agricultural community. Two of your constituents come to you, asking you to help them settle an ongoing dispute. One of them is a rancher, raising cattle. The other, the rancher’s neighbor, farms soybeans. The dispute concerns the rancher’s cattle, which have a habit of wandering over to the farmer’s land and destroying his crop. Matters have recently become especially difficult because the farmer has learned that the rancher wants to add more cattle to his herd, and the farmer is concerned that the problem will get worse. What should you do? When Coase tried to formalize an answer to social cost problems like this one, he came to a striking conclusion. It doesn’t matter what the sheriff does, at least from a long-term perspective, as long as three conditions are met: the damages involved must be adequately quantified, some well-defined notion of property must be instituted, and bargaining must be free. To see why this would be, consider what would happen if the sheriff told the rancher he could have as many cattle as he liked, but that he had to pay for all of the damage his herd inflicted. In essence, the rancher has incurred an additional cost to raising cows. Depending on how much damage gets done, and how much soybeans are worth, it may well make sense for the rancher to keep adding head to his herd even while paying the farmer for the soybeans that keep getting destroyed. If the rancher really is paying for the value of the soybeans, the farmer shouldn’t care whether the revenue comes from selling the soybeans himself or from the rancher’s compensation — in fact, he might as well think of the rancher as a customer buying whatever soybeans the cattle destroy. Ultimately, the rancher and farmer will reach an agreement about how many cattle the rancher will own based on what is maximally profitable for both parties. But what if the sheriff makes some other choice? If the farmer has to pay the rancher to keep his cattle from destroying the farmer’s crops, one would expect the exact same bargaining to occur. Coase’s theorem says that the endpoint will always be the same: both parties will agree on an arrangement that is maximally profitable for everyone.*  

- Page 214 (location ~ 3282-3298)    

*When Malaney gave Weinstein this problem, Weinstein took it seriously. Making some simple mathematical assumptions, similar to the ones Coase made, Weinstein soon saw his way to a solution — just the solution, in fact, that Coase had arrived at. But this, Weinstein thought, was a surprise. At least in this case, it seemed as though the mathematics was working in the right sort of way, and indeed, it led to what seemed to be a deeply counterintuitive result that nonetheless bore weight. The process felt surprisingly similar to using mathematics in physics: one makes some simplifying assumptions and then uses mathematics to gain insights into a problem that would have otherwise remained intractable. Most importantly, if someone had told Weinstein about Coase’s theorem before he had worked on it himself, he would likely have thought that the solution was politically driven, a thinly veiled case for less government intervention, shrouded in mathematics to give the appearance of rigor. But now he saw that matters were not so simple. His interest piqued, Weinstein began looking for other cases where mathematics was used to reach counterintuitive results in economics. He uncovered several examples. The Black-Scholes equation was one, since it makes use of fairly sophisticated mathematics to get at the heart of what it means to produce and trade an option. Another was Arrow’s theorem, a famous result in social choice theory that essentially proves that if you have a group of people trying to choose between three or more options, there is no voting system that can turn the ranked preferences of all of the individuals in the community into a fair community-wide ranking. Weinstein realized that his criticisms of economics had been misplaced. Mathematics, he now believed, could be used productively to understand economic problems. It was an exhilarating realization, because it meant that someone with some mathematical acumen and a background in physics stood a chance at making progress on problems in economics.*  

- Page 216 (location ~ 3299-3313)    

*Weyl’s essential innovation, conceptually speaking, was to find a mathematical theory for comparing otherwise incomparable quantities. In his theory, the incomparable quantities were the lengths of rulers at different locations. His solution was to find a way to bring the rulers to the same location, and then just hold them up next to one another to determine their relationship. But now think of the index value problem, which, at its core, involves comparing different, apparently incomparable quantities. How can you make sense of the value of money to two different people, especially if they have radically different lifestyles? And how do you compare what might seem like a reasonable market basket in 1950 to what would seem like a reasonable market basket in 1970, or in 2010? These problems seemed insurmountable at first to Weinstein and Malaney. But in the context of the mathematical framework that Weyl and his successors had developed, at least one possible solution emerged. All they needed to do was figure out a way to take any two people — say, a lumberjack in 1950 and a computer programmer in 1995 — and put them in the same circumstances so that they could directly compare their preferences and values. It was a strange thing to propose — after all, the conversation between the lumberjack and the programmer might be a little awkward — but from the point of view of Weyl’s mathematics, it was the most natural thing in the world. To solve the index number problem, Weinstein and Malaney argued, you need a gauge theory of economics.*  

- Page 217 (location ~ 3316-3327)    

*A few months earlier, Smolin had published an article in the magazine Physics Today, a semi-popular publication whose goal was to explain new developments in physics to physicists who weren’t necessarily experts in the given area. Smolin’s article was an attempt to explain why quantum gravity had not produced a researcher like Albert Einstein, who successfully revolutionized physics by thinking far out of the box. The article was a preview of a book Smolin was just finishing, called The Trouble with Physics. In both the article and the book, Smolin argued that physics, or rather, quantum gravity research, faced a sociological problem. A group of physicists working on something called string theory, one approach to solving the basic problem of how to combine gravitational physics with quantum physics, had come to dominate the field. When it came time to hire new faculty members into their physics departments, or to dole out research funding, these string theorists tended to give the resources to other string theorists rather than to people working on alternative approaches to quantum gravity. It was this Physics Today article that had prompted the unexpected e-mail. The man who had written the message was Eric Weinstein, now a hedge fund manager and financial consultant in Manhattan. Weinstein agreed with Smolin’s assessment of the physics community, based on his years working as a mathematical physicist at Harvard and then at MIT. But he had a bigger point to make, about how sociology could distort progress in academic research more broadly. As far as Weinstein was concerned, the sociology problem in physics was nothing. Economics was ten times worse.*  

- Page 218 (location ~ 3333-3344)    

*In September 2008, Weinstein visited Perimeter a second time, for a conference on science in the twenty-first century. The talks focused on ways in which scientific research was changing with new funding sources, with new means of disseminating ideas, such as blogs and online conferences, and with new ideas about where research should and could happen, with places like Perimeter and the Santa Fe Institute becoming centers of study outside of the traditional university. But the future of science was not at the forefront of Weinstein’s mind that September. Just a week after Weinstein’s talk at Perimeter, the fourth-largest investment bank in the United States, Lehman Brothers, closed its doors after a century and a half of business. At virtually the same time, AIG, one of the twenty largest publicly traded companies in the world, had its debt downgraded, leading to a liquidity crisis that would have toppled the company had the U.S. government not intervened. In early September, the world economy was already on the ropes. As a hedge fund manager and consultant, Weinstein was tuned in to the surprise and panic in the financial industry, and in economics more generally. As far as Weinstein knew, no one had seen this coming. (Sornette had, but he didn’t publicize this prediction widely.) For Weinstein, the unexpectedly dramatic failure of the U.S. banking system was only further evidence that it was time to take the next step in the development of modern economics. It was time to reflect on what had gone wrong with the now-toxic securities and recognize that economics needed a new set of tools. As physicists had done a generation before, economists needed to broaden their theoretical framework to account for a wider variety of phenomena. Economics needed a new generation of theories and models, suited for the complexity of the modern world. Weinstein thought that the crisis should be an opportunity to set aside past differences between the various approaches to finance and economics. He called for a new large-scale collaboration between economists and researchers from physics and other fields. It would be, he said, an economic Manhattan Project.*  

- Page 219 (location ~ 3358-3373)    

*Social Security, technically the U.S. federal Old-Age, Survivors, and Disability Insurance program, was first signed into law in 1935 as part of the New Deal, Franklin Roosevelt’s program to end the Great Depression through stimulus spending and a broad expansion of the U.S. welfare system. It was a way for the federal government to provide support to the elderly, to children whose parents had died before they were of employable age, and to people who became disabled and unable to work. It was designed to pay for itself, as a real insurance program would. Workers would contribute to the program through a mandatory tax, and the funds collected would be used to pay for the program’s costs. The program was highly controversial. Early on, it was challenged several times in the Supreme Court (unsuccessfully). But over time, as successive generations contributed during the course of their working lives, most Americans came to count on the program as a retirement and disability benefit. By the 1960s, it had become a part of American life, something that workers nearing retirement took as an entitlement. This made matters politically difficult when, during the period of high rates of inflation and low economic growth in the 1970s, it became clear that Social Security was in trouble. Projecting forward, politicians and economists realized that over the coming decades, ever-larger numbers of aging Baby Boomers (then just coming into their own) would retire, and the costs of providing them with benefits would rapidly outstrip the program’s ability to fund itself. And yet, there was little to be done. For a politician to draw attention to Social Security’s woes was suicidal. The two obvious solutions to the funding problem — reducing benefits and raising taxes — were equally unappealing. Social Security presented a kind of political catch-22 — that is, until Daniel Patrick Moynihan and Bob Packwood, the two leading members of the Senate Finance Committee in the mid-nineties, shared a moment of inspiration. If you wanted to come up with $1 trillion without anyone noticing the difference, all you needed to do was change the value of money. Here’s how the plan worked. Projections for the future costs of Social Security were based on the expected rate of inflation, which in turn was based on the CPI. Moynihan and Packwood realized that if the official rate of inflation could be lowered, the income from the Social Security tax would rise, and the costs of administering the program would fall. The effect would be to raise taxes and reduce entitlements, relative to the real buying power of money, without acknowledging that you were doing so. The challenge was to find an argument for why inflation calculations should be modified. This is where the Boskin Commission came in. It was a masterful sleight of hand. Working backward from the figure of $1 trillion, which Moynihan believed would be necessary to keep Social Security solvent, he and Packwood determined that inflation would need to be reduced by 1.1%. According to notes written by Robert Gordon, an economist at Northwestern University and one of the five members of the commission, Dale Jorgenson — the Harvard economist who had thrown Malaney out of his office — reported to the commission early on that they were aiming for $1 trillion in Social Security savings over ten years, and that this meant they needed to come up with the requisite reduction in inflation. Then the committee broke up into two teams to work on different ways in which the problems of changing preferences and changing quality could affect CPI. Gordon and the other person on his team, working together, arrived at one number. The other team, which included Jorgenson and Boskin, arrived at another. And then, “somehow” (Gordon’s word), when the two teams combined their results, the commission’s final recommendation “corrected” inflation by precisely 1.1%. The Boskin Commission’s findings were criticized from all corners. As Gordon later reported, the project was rushed and careless. He and his collaborator finished their contribution days before the commission was due to present to the Senate. The calculations were what physicists and economists both call “back of the envelope,” little more than informal estimates. The commission’s report was never peer-reviewed before it was presented to the Senate.*  

- Page 220 (location ~ 3373-3405)    

*Exporting gauge theories, or other ideas from physics, to economics remains a hard sell. Weinstein was right that late 2008 presented a unique opportunity for someone inclined to change the way economists thought about the world — and the world, economics. Many people in finance, in economics, and in ordinary homes around the world were scared. Things that many people thought they understood turned out to be changing and unreliable. Meanwhile, people working in other fields, such as physics and mathematics, saw an opportunity to contribute to a field that seemed besieged. The suggestion that it was time to reevaluate some of the principal theories and methods of modern economics struck a chord with many, including Smolin and a handful of other physicists working at Perimeter.*  

- Page 223 (location ~ 3412-3418)  
