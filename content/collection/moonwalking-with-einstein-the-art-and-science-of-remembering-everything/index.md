---
title: Moonwalking With Einstein-  The Art and Science of Remembering Everything (Joshua Foer)
author: E
date: '2017-04-05'
summaryOn: true
summary: 'Hola, this is el summary'
categories: []
tags:
  - books
  - review
showDate: no
draft: yes
---


*Ben Pridmore, on the other hand, could memorize the order of a shuffled deck of playing cards in thirty-two seconds. In five minutes he could permanently commit to memory what happened on ninety-six different historical dates. The man knew fifty thousand digits of pi. What was not to envy? I had once read that the average person squanders about forty days a year compensating for things he or she has forgotten. Putting aside for a moment the fact that he was temporarily unemployed, how much more productive must Ben Pridmore be? Every day there seems to be more to remember: more names, more passwords, more appointments. With a memory like Ben Pridmore’s, I imagined, life would be qualitatively different—and better. Our culture constantly inundates us with new information, and yet our brains capture so little of it. Most just goes in one ear and out the other. If the point of reading were simply to retain knowledge, it would probably be the single least efficient activity I engage in. I can spend a half dozen hours reading a book and then have only a foggy notion of what it was about. All those facts and anecdotes, even the stuff interesting enough to be worth underlining, have a habit of briefly making an impression on me and then disappearing into who knows where. There are books on my shelf that I can’t even remember whether I’ve read or not.*  

- Page 8 (location ~ 119-129)    

*“What you have to understand is that even average memories are remarkably powerful if used properly,” he said. Ed had a blocky face and a shoulder-length mop of curly brown hair, and could be counted among the competitors who were least concerned with habits of personal grooming. He was wearing a suit with a loosened tie and, incongruously, a pair of flip-flops emblazoned with the Union Jack. He was twenty-four years old but carried his body like someone three times that age. He hobbled about with a cane at his side—“a winning prop,” he called it—which was necessitated by a recent painful relapse of chronic juvenile arthritis. He and all the other mental athletes I met kept insisting, as Ben Pridmore had in his interview, that anyone could do what they do. It was simply a matter of learning to “think in more memorable ways” using the “extraordinarily simple” 2,500-year-old mnemonic technique known as the “memory palace” that Simonides of Ceos had supposedly invented in the rubble of the great banquet hall collapse. The techniques of the memory palace—also known as the journey method or the method of loci, and more broadly as the ars memorativa, or “art of memory”—were refined and codified in an extensive set of rules and instruction manuals by Romans like Cicero and Quintilian, and flowered in the Middle Ages as a way for the pious to memorize everything from sermons and prayers to the punishments awaiting the wicked in hell. These were the same tricks that Roman senators had used to memorize their speeches, that the Athenian statesman Themistocles had supposedly used to memorize the names of twenty thousand Athenians, and that medieval scholars had used to memorize entire books.*  

- Page 11 (location ~ 158-170)    

*What’s more, memory training was considered a form of character building, a way of developing the cardinal virtue of prudence and, by extension, ethics. Only through memorizing, the thinking went, could ideas truly be incorporated into one’s psyche and their values absorbed. The techniques existed not just to memorize useless information like decks of playing cards, but also to etch into the brain foundational texts and ideas. But then, in the fifteenth century, Gutenberg came along and turned books into mass-produced commodities, and eventually it was no longer all that important to remember what the printed page could remember for you. Memory techniques that had once been a staple of classical and medieval culture got wrapped up with the occult and esoteric Hermetic traditions of the Renaissance, and by the nineteenth century they had been relegated to carnival sideshows and tacky self-help books—only to be resurrected in the last decades of the twentieth century for this bizarre and singular competition.*  

- Page 12 (location ~ 173-180)    

*Buzan believes schools go about teaching all wrong. They pour vast amounts of information into students’ heads, but don’t teach them how to retain it. Memorizing has gotten a bad rap as a mindless way of holding onto facts just long enough to pass the next exam. But it’s not memorization that’s evil, he says; it’s the tradition of boring rote learning that he believes has corrupted Western education. “What we have been doing over the last century is defining memory incorrectly, understanding it incompletely, applying it inappropriately, and condemning it because it doesn’t work and isn’t enjoyable,” Buzan argues. If rote memorization is a way of scratching impressions onto our brains through the brute force of repetition—the old “drill and kill” method—then the art of memory is a more elegant way of remembering through technique. It is faster, less painful, and produces longerlasting memories, Buzan told me.*  

- Page 13 (location ~ 195-201)    

*“I figure that there are two ways of figuring out how the brain works,” he said. “The first is the way that empirical psychology does it, which is that you look from the outside and take a load of measurements on a load of different people. The other way follows from the logic that a system’s optimal performance can tell you something about its design. Perhaps the best way to understand human memory is to try very hard to optimize it—ideally with a load of bright people in conditions where they get rigorous and objective feedback. That’s what the memory circuit is.”*  

- Page 16 (location ~ 243-247)    

*A troubling thought percolated to the front of my brain as I stood in the back of the Con Edison auditorium watching these supposedly normal human beings perform their almost unfathomable mental acrobatics: I didn’t have a clue how my own memory worked. Was there even such a place as the front of my brain? A slow wave of questions swept over me—things I’d never bothered to wonder about, but which all of a sudden seemed profoundly pressing. What exactly is a memory? How is one created? And how does it get stored? I’d spent the first two and a half decades of my life with a memory that operated so seamlessly that I’d never had cause to stop and inquire about its mechanics. And yet, now that I was stopping to think about it, I realized that it actually didn’t work all that seamlessly. It completely failed in certain areas, and worked far too well in others. And it had so many inexplicable quirks.*  

- Page 17 (location ~ 252-259)    

*Was it really true that anyone could learn to quickly memorize huge quantities of information? Anyone? I was willing to believe Buzan when he said there were techniques that one could learn to marginally improve one’s memory around the edges, but I didn’t fully believe him (or Ed) when he said that any schmo off the street could learn to memorize entire decks of playing cards or thousands of binary digits. The alternate explanation just seemed a whole lot more plausible: that Ed and his colleagues had some freakish innate talent that was the mental equivalent of André the Giant’s height or Usain Bolt’s legs. Indeed, much of what’s been written about memory improvement by self-help gurus is tainted by hucksterism. When I checked out the self-help aisle at my local Barnes & Noble, I found stacks of books making fevered claims that they could teach me how to “never forget a telephone number or date” or “develop instant recall.” One book even pronounced that it could show me how to use the “other 90 percent” of my brain, which is one of those pseudoscientific clichés that makes about as much sense as saying I could be taught to use the other 90 percent of my hand. But memory improvement has also long been investigated by people whose relationships to the subject are less obviously profitable and whose claims are inspected by peer review. Academic psychologists have been interested in expanding our native memory capacities ever since Hermann Ebbinghaus first brought the study of memory into the laboratory in the 1870s.*  

- Page 18 (location ~ 271-282)    

*If memory is our means of preserving that which we consider most valuable, it is also painfully linked to our own transience. When we die, our memories die with us. In a sense, the elaborate system of externalized memory we’ve created is a way of fending off mortality. It allows ideas to be efficiently passed across time and space, and for one idea to build on another to a degree not possible when a thought has to be passed from brain to brain in order to be sustained. The externalization of memory not only changed how people think; it also led to a profound shift in the very notion of what it means to be intelligent. Internal memory became devalued. Erudition evolved from possessing information internally to knowing how and where to find it in the labyrinthine world of external memory. It’s a telling statement that pretty much the only place where you’ll find people still training their memories is at the World Memory Championship and the dozen national memory contests held around the globe. What was once a cornerstone of Western culture is now at best a curiosity. But as our culture has transformed from one that was fundamentally based on internal memories to one that is fundamentally based on memories stored outside the brain, what are the implications for ourselves and for our society? What we’ve gained is indisputable. But what have we traded away? What does it mean that we’ve lost our memory?*  

- Page 20 (location ~ 302-311)    

*Loftus goes on to say that this conviction has its modern origins in a set of experiments carried out from 1934 to 1954 by a Canadian neurosurgeon named Wilder Penfield. Penfield used electrical probes to stimulate the brains of epileptic patients while they were lying conscious on the operating table with their skulls exposed. He was trying to pinpoint the source of their epilepsy, and hopefully cure it, but he found that when his probe touched certain parts of his patients’ temporal lobes, something very unexpected happened. The patients started describing vivid, long-forgotten memories. When he touched the same spot again, he often elicited the same memory. Based on those experiments, Penfield came to believe that the brain records everything to which it pays any degree of conscious attention, and that this recording is permanent. The Dutch psychologist Willem Wagenaar came to believe the same thing. For six years, between 1978 and 1984, he kept a diary of the one or two most notable events that happened to him each day. For each event, he wrote down what occurred, who was involved, where it occurred, and when—each on a separate card. In 1984, he began testing himself to see just how much of those six years he’d be able to recall. He would pull out a random card and see if he had any memories of the events described that day. He found that he could recall almost everything that happened—especially the more recent events—with just a few retrieval clues. But nearly 20 percent of the oldest memories seemed to have totally disappeared. These events, described in his own diary, felt totally foreign, as if they had happened to a stranger. But were those memories really gone? Wagenaar wasn’t convinced they were. He decided to take another look at ten events that he believed he’d completely forgotten, in which his diary suggested that another person had been present. He went back to those people and asked them for details that might help him recall his lost memories. In every single case, with enough prodding, someone was able to supply a detail that led Wagenaar to retrieve other parts of the memory. Not one of his memories had actually disappeared. He concluded that “in light of this one cannot say that any event was completely forgotten.”*  

- Page 27 (location ~ 408-424)    

*Nevertheless, the sudden reappearance of long-lost episodes from one’s past is a familiar enough experience, and the notion that with just the right cue, we might somehow be able to pull out every single bit of information that once went into our brains persists. In fact, probably the single most common misperception about human memory—the one that Ed had so casually laughed off—is that some people have photographic memories. When I followed up with him about that, he confided that he used to wake up in cold sweats worrying that someday someone with a photographic memory would read about the World Memory Championship in the newspaper, show up, and blow him and his colleagues out of the water. He was reassured to learn that most scientists now agree that this is unlikely to happen. Even though many people claim to have a photographic memory, there’s no evidence that anyone can actually store mental snapshots and recall them with perfect fidelity. Indeed, only one case of photographic memory has ever been described in the scientific literature.*  

- Page 28 (location ~ 429-436)    

*In 1979, another researcher named John Merritt decided to investigate Stromeyer’s claims. He placed a photographic memory test in magazines and newspapers around the country. It consisted of two random dot drawings. Merritt hoped someone might come forward with abilities similar to Elizabeth’s and prove that her case was not unique. He figures that roughly one million people tried their hand at the test. Of that number, thirty wrote in with the right answer, and fifteen agreed to be studied by Merritt. But with scientists looking over their shoulders, none of them could pull off Elizabeth’s nifty trick. There are so many unlikely circumstances surrounding the Elizabeth case—the marriage between subject and scientist, the lack of further testing, the inability to find anyone else with her abilities—that some psychologists have concluded that there’s something fishy about Stromeyer’s findings. He denies it. “We don’t have any doubt about our data,” he told me over the phone. Still, his one-woman study, he admits, “is not strong evidence for other people having photographic memory.”*  

- Page 29 (location ~ 442-450)    

*  S's exceptional memory wasn’t the only strange feature of his brain. He also suffered from a rare perceptual disorder known as synesthesia, which caused his senses to be bizarrely intertwined. Every sound S heard had its own color, texture, and sometimes even taste, and evoked “a whole complex of feelings.” Some words were “smooth and white,” others “as orange and sharp as arrows.” The voice of Luria’s colleague, the famous psychologist Lev Vygotsky, was “crumbly yellow.” The cinematographer Sergei Eisenstein’s voice resembled a “flame with fibres protruding from it.” Words set S’s mind ablaze with mental imagery. When you or I hear someone mention the word “elephant” or read the word on this page, we understand immediately that the referent is a large, gray pachyderm with thick legs and an oversize proboscis. But under most circumstances we don’t actually conjure up an image of an elephant in our mind’s eye. We might, if we choose to, but it takes a little extra effort, and in the course of normal conversation or reading, there’s usually no point to it. But that’s exactly what S did, automatically and instantaneously, with every word he heard. He couldn’t help it. “When I hear the word green, a green flowerpot appears; with the word red I see a man in a red shirt coming toward me; as for blue, this means an image of someone waving a small blue flag from a window,” he told Luria. Because every word summoned up an accompanying synesthetic image—sometimes also a taste or smell—S lived in a kind of waking dream, once removed from reality. While one universe unfolded around him, another universe of images blossomed in his mind’s eye.*  

- Page 31 (location ~ 461-473)    

*Even numbers had their own personalities for S: “Take the number 1. This is a proud, well-built man; 2 is a high-spirited woman; 3 a gloomy person (why, I don’t know); 6 a man with a swollen foot; 7 a man with a mustache; 8 a very stout woman—a sack within a sack. As for the number 87, what I see is a fat woman and a man twirling his mustache.” But while numbers were brought to life by S’s synesthesia, he had trouble understanding abstract concepts and metaphors. “I can only understand what I can visualize,” he explained. Words like “infinity” and “nothing” were beyond his grasp. “Take the word something for example. For me this is a dense cloud of steam that has the color of smoke. When I hear the word nothing, I also see a cloud, but that one is thinner, completely transparent. And when I try to seize a particle of this nothing, I get the most minute particles of nothing.” S was simply unable to think figuratively. An expression like “weigh one’s words” evoked images of scales, not prudence. Poetry was virtually impossible to read, unless it was completely literal. Even simple stories proved difficult to understand because his irrepressible image-making would bog him down as he tried to visualize every word, or else send his brain hurtling off to some other associated image, and some other memory.*  

- Page 32 (location ~ 479-488)    

*For all the advances that have been made in recent decades, it’s still the case that no one has ever actually seen a memory in the human brain. Though advances in imaging technology have allowed neuroscientists to grasp much of the basic topography of the brain, and studies of neurons have given us a clear picture of what happens inside and between individual brain cells, science is still relatively clueless about what transpires in the circuitry of the cortex, the wrinkled outer layer of the brain that allows us to plan into the future, do long division, and write poetry, and which holds most of our memories. In our knowledge of the brain, we’re like someone looking down on a city from a high-flying airplane. We can tell where the industrial and residential neighborhoods are, where the airport is, the locations of the main traffic arteries, where the suburbs begin. We also know, in great detail, what the individual units of the city (citizens, and in this metaphor, neurons) look like. But, for the most part, we can’t say where people go when they get hungry, how people make a living, or what any given person’s commute looks like. The brain makes sense up close and from far away. It’s the in-between—the stuff of thought and memory, the language of the brain—that remains a profound mystery. One thing is clear, however: The nonlinear associative nature of our brains makes it impossible for us to consciously search our memories in an orderly way. A memory only pops directly into consciousness if it is cued by some other thought or perception—some other node in the nearly limitless interconnected web. So when a memory goes missing or a name gets caught on the tip of the tongue, hunting it down can be frustrating and often futile.*  

- Page 33 (location ~ 498-510)    

*S kept his memories rigidly organized by mapping them onto structures and places he already knew well. “When S read through a long series of words, each word would elicit a graphic image. And since the series was fairly long, he had to find some way of distributing these images of his in a mental row or sequence,” wrote Luria. “Most often ... he would ‘distribute’ them along some roadway or street he visualized in his mind.” When he wanted to commit something to memory, S would simply take a mental stroll down Gorky Street in Moscow, or his home in Torzhok, or some other place he’d once visited, and install each of his images at a different point along the walk. One image might be placed at the doorway of a house, another near a streetlamp, another on top of a picket fence, another in a garden, another on the ledge of a store window. All this happened in his mind’s eye as effortlessly as if he were placing real objects along a real street. If asked to memorize those same seven words—“bear,” “truck,” “college,” “shoe,” “drama,” “garbage,” and “watermelon”—he would conjure up an image associated with each of them, and scatter them along one of his many mental paths.*  

- Page 34 (location ~ 519-528)    

*S’s memory was a beast that indiscriminately gobbled up everything it was fed, and had trouble disgorging those pieces of information that were too trivial to be worth keeping. The greatest challenge S faced was learning what Luria called “the art of forgetting.” The rich images that every sensation created proved frustratingly indelible. He experimented with different techniques to wipe them from his mind. He tried writing things down, with the hope that he would then no longer feel a need to remember them. When that didn’t work, he tried burning the pieces of paper, but he could still see numbers hovering among the embers. Eventually he had an epiphany. One evening, while feeling particularly pestered by a chart of numbers he had earlier memorized, he figured out the secret of forgetting. All he had to do was convince himself that the information he wanted to forget was meaningless. “If I don’t want the chart to show up it won’t,” he exclaimed. “And all it took was for me to realize this!” One might assume that S’s vacuum-cleaner memory would have made him a formidable journalist. I imagined if I could only take notes without taking notes and have at my fingertips every fact I’d ever digested, I’d be immensely better at my job. I’d be better at everything. But professionally S was a failure. His newspaper gig didn’t last long, and he was never able to hold down a steady job. He was, in Luria’s estimation, “a somewhat anchorless person, living with the expectation that at any moment something particularly fine was to come his way.” Ultimately, his condition made him unemployable as anything but a stage performer, a theatrical curio like the mnemonist of Alfred Hitchcock’s The 39 Steps. The man with the best memory in the world simply remembered too much.*  

- Page 35 (location ~ 535-548)    

*In 2000, a neuroscientist at University College London named Eleanor Maguire wanted to find out what effect, if any, all that driving around the labyrinthine streets of London might have on the cabbies’ brains. When she brought sixteen taxi drivers into her lab and examined their brains in an MRI scanner, she found one surprising and important difference. The right posterior hippocampus, a part of the brain known to be involved in spatial navigation, was 7 percent larger than normal in the cabbies—a small but very significant difference. Maguire concluded that all of that way-finding around London had physically altered the gross structure of their brains. The more years a cabbie had been on the road, the more pronounced the effect. The brain is a mutable organ, capable—within limits—of reorganizing itself and readapting to new kinds of sensory input, a phenomenon known as neuroplasticity. It had long been thought that the adult brain was incapable of spawning new neurons—that while learning caused synapses to rearrange themselves and new links between brain cells to form, the brain’s basic anatomical structure was more or less static. Maguire’s study suggested the old inherited wisdom was simply not true.*  

- Page 37 (location ~ 561-569)    

*After her groundbreaking study of London cabbies, Maguire decided to turn her attention to mental athletes. She teamed up with Elizabeth Valentine and John Wilding, authors of the academic monograph Superior Memory, to study ten individuals who had finished near the top of the World Memory Championship. They wanted to find out if the memorizers’ brains were—like the London cabbies’—structurally different from the rest of ours, or if they were somehow just making better use of memory abilities that we all possess. The researchers put both the mental athletes and a group of matched control subjects into MRI scanners and asked them to memorize three-digit numbers, black-and-white photographs of people’s faces, and magnified images of snowflakes, while their brains were being scanned. Maguire and her team thought it was possible that they might discover anatomical differences in the brains of the memory champs, evidence that their brains had somehow reorganized themselves in the process of doing all that intensive remembering. But when the researchers reviewed the imaging data, not a single significant structural difference turned up. The brains of the mental athletes appeared to be indistinguishable from those of the control subjects. What’s more, on every single test of general cognitive ability, the mental athletes’ scores came back well within the normal range. The memory champs weren’t smarter, and they didn’t have special brains. When Ed and Lukas told me they were average guys with average memories, they weren’t just being modest. But there was one telling difference between the brains of the mental athletes and the control subjects: When the researchers looked at which parts of the brain were lighting up when the mental athletes were memorizing, they found that they were activating entirely different circuitry. According to the functional MRIs, regions of the brain that were less active in the control subjects seemed to be working in overdrive for the mental athletes. Surprisingly, when the mental athletes were learning new information, they were engaging several regions of the brain known to be involved in two specific tasks: visual memory and spatial navigation, including the same right posterior hippocampal region that the London cabbies had enlarged with all their daily way-finding. At first glance, this wouldn’t seem to make any sense. Why would mental athletes be conjuring images in their mind’s eye when they were trying to learn three-digit numbers? Why should they be navigating like London cabbies when they’re supposed to be remembering the shapes of snowflakes? Maguire and her team asked the mental athletes to describe exactly what was going through their minds as they memorized. The mental athletes recounted a strategy that sounded almost exactly like what S claimed had been happening in his brain. Even though they were not innate synesthetes like S, the mental athletes said they were consciously converting the information they were being asked to memorize into images, and distributing those images along familiar spatial journeys. Unlike S, they weren’t doing this automatically, or because it was an inborn talent they’d nurtured since childhood. Rather, the unexpected patterns of neural activity that Maguire’s fMRIs turned up were the result of training and practice. The mental athletes had taught themselves to remember like S.  *  

- Page 38 (location ~ 569-594)    

*Ed then explained to me his procedure for making a name memorable, which he had used in the competition to memorize the first and last names associated with ninety-nine different photographic head shots in the names-and-faces event. It was a technique he promised I could use to remember people’s names at parties and meetings. “The trick is actually deceptively simple,” he said. “It is always to associate the sound of a person’s name with something you can clearly imagine. It’s all about creating a vivid image in your mind that anchors your visual memory of the person’s face to a visual memory connected to the person’s name. When you need to reach back and remember the person’s name at some later date, the image you created will simply pop back into your mind ... So, hmm, you said your name was Josh Foer, eh?” He raised an eyebrow and gave his chin a melodramatic stroke. “Well, I’d imagine you joshing me where we first met, outside the competition hall, and I’d imagine myself breaking into four pieces in response. Four/Foer, get it? That little image is more entertaining—to me, at least—than your mere name, and should stick nicely in the mind.” It occurred to me that this was a kind of manufactured synesthesia.*  

- Page 43 (location ~ 646-654)    

*To understand why this sort of mnemonic trick works, you need to know something about a strange kind of forgetfulness that psychologists have dubbed the “Baker/baker paradox.” The paradox goes like this: A researcher shows two people the same photograph of a face and tells one of them that the guy is a baker and the other that his last name is Baker. A couple days later, the researcher shows the same two guys the same photograph and asks for the accompanying word. The person who was told the man’s profession is much more likely to remember it than the person who was given his surname. Why should that be? Same photograph. Same word. Different amount of remembering. When you hear that the man in the photo is a baker, that fact gets embedded in a whole network of ideas about what it means to be a baker: He cooks bread, he wears a big white hat, he smells good when he comes home from work. The name Baker, on the other hand, is tethered only to a memory of the person’s face. That link is tenuous, and should it dissolve, the name will float off irretrievably into the netherworld of lost memories. (When a word feels like it’s stuck on the tip of the tongue, it’s likely because we’re accessing only part of the neural network that “contains” the idea, but not all of it.) But when it comes to the man’s profession, there are multiple strings to reel the memory back in. Even if you don’t at first remember that the man is a baker, perhaps you get some vague sense of breadiness about him, or see some association between his face and a big white hat, or maybe you conjure up a memory of your own neighborhood bakery. There are any number of knots in that tangle of associations that can be traced back to his profession. The secret to success in the names-and-faces event—and to remembering people’s names in the real world—is simply to turn Bakers into bakers—or Foers into fours. Or Reagans into ray guns. It’s a simple trick, but highly effective.*  

- Page 43 (location ~ 655-668)    

*Though it’s best not to be born a chicken at all, it is especially bad luck to be born a cockerel. From the perspective of the poultry farmer, male chickens are useless. They can’t lay eggs, their meat is stringy, and they’re ornery to the hens that do all the hard work of putting food on our tables. Commercial hatcheries tend to treat male chicks like fabric cutoffs or scrap metal: the wasteful but necessary by-product of an industrial process. The sooner they can be disposed of—often they’re ground into animal feed—the better. But a costly problem has vexed egg farmers for millennia: It’s virtually impossible to tell the difference between male and female chickens until they’re four to six weeks old, when they begin to grow distinctive feathers and secondary sex characteristics like the rooster’s comb. Until then, they’re all just indistinguishable fluff balls that have to be housed and fed—at considerable expense.*  

- Page 46 (location ~ 693-699)    

*Somehow it took until the 1920s before anyone figured out a solution to this costly dilemma. The momentous discovery was made by a group of Japanese veterinary scientists, who realized that just inside the chick’s rear end there is a constellation of folds, marks, spots, and bumps that to the untrained eye appear arbitrary, but when properly read, can divulge the sex of a day-old bird. When this discovery was unveiled at the 1927 World Poultry Congress in Ottawa, it revolutionized the global hatchery industry and eventually lowered the price of eggs worldwide. The professional chicken sexer, equipped with a skill that took years to master, became one of the most valuable workers in agriculture. The best of the best were graduates of the two-year Zen-Nippon Chick Sexing School, whose standards were so rigorous that only 5 to 10 percent of students received accreditation. But those who did graduate earned as much as five hundred dollars a day and were shuttled around the world from hatchery to hatchery like top-flight business consultants. A diaspora of Japanese chicken sexers spilled across the globe.*  

- Page 46 (location ~ 700-707)    

*By some estimates there are as many as a thousand different vent configurations that a sexer has to learn to become competent. The job is made even more difficult by the fact that the sexer has to diagnose the bird with just a glance. There is no time for conscious reasoning. If he hesitates for even a couple seconds, his grip on the bird can cause a pullet’s vent to swell to look unquestionably like a cockerel’s. Mistakes are costly. In the 1960s, one hatchery paid its sexers a penny for each correctly sexed chick and deducted 35 cents for each one they got wrong. The best in the business can sex 1,200 chicks an hour with 98 to 99 percent accuracy. In Japan, a few superheroes of the industry have learned how to double clutch the chicks and sex them two at a time, at the rate of 1,700 per hour.*  

- Page 47 (location ~ 716-721)    

*As I was combing the scientific literature, one name kept popping up in my research about memory improvement: K. Anders Ericsson. He was a psychology professor at Florida State University and the author of an article titled “Exceptional Memorizers: Made, Not Born.” Before Tony Buzan mass-marketed the idea of “using your perfect memory,” Ericsson was laying the scientific groundwork for what’s known as “Skilled Memory Theory,” which explains how and why our memory is improvable. In 1981, he and fellow psychologist Bill Chase conducted a now-classic experiment on a Carnegie Mellon undergraduate, who has been immortalized in the literature by his initials, SF. Chase and Ericsson paid SF to spend several hours a week in their lab taking a simple memory test over and over and over again. It was similar to the test that Luria had given to S when he first walked into his office. SF sat in a chair and tried to remember as many numbers as possible as they were read off at the rate of one per second. At the outset, he could only hold about seven digits in his head at a time. By the time the experiment wrapped up—two years and 250 mind-numbing hours later—SF had expanded his ability to remember numbers by a factor of ten. The experiment shattered the old notions that our memory capacities are fixed. How SF did it, Ericsson believes, holds a key to understanding the basic cognitive processes underlying all forms of expertise—from mental athlete memorizers to chess grand masters to chicken sexers.*  

- Page 48 (location ~ 731-741)    

*Like the professional chicken sexers, the senior SWAT officers had a skill that was difficult to put into words. Ericsson’s research program can be summarized as an attempt to isolate the thing we call expertise, so that he can dissect it and identify its cognitive basis. In order to do that, Ericsson and his colleagues asked the officers to talk aloud about what was going through their minds as the scenario unfolded. What Ericsson expected to learn from these accounts was the same thing he’s found in every other field of expertise that he’s studied: Experts see the world differently. They notice things that nonexperts don’t see. They home in on the information that matters most, and have an almost automatic sense of what to do with it. And most important, experts process the enormous amounts of information flowing through their senses in more sophisticated ways. They can overcome one of the brain’s most fundamental constraints: the magical number seven.*  

- Page 51 (location ~ 777-784)    

*Miller had discovered that our ability to process information and make decisions in the world is limited by a fundamental constraint: We can only think about roughly seven things at a time. When a new thought or perception enters our head, it doesn’t immediately get stashed away in long-term memory. Rather, it exists in a temporary limbo, in what’s known as working memory, a collection of brain systems that hold on to whatever is rattling around in our consciousness at the present moment. Without looking back and rereading it, try to repeat the first three words of this sentence to yourself. Without looking back Easy enough. Now, without looking back, try to repeat the first three words of the sentence before that. If you find that quite a bit harder, it’s because that sentence has already been dropped by your working memory.*  

- Page 52 (location ~ 793-801)    

*Our working memories serve a critical role as a filter between our perception of the world and our long-term memory of it. If every sensation or thought was immediately filed away in the enormous database that is our long-term memory, we’d be drowning, like S and Funes, in irrelevant information. Most of the things that pass through our brain don’t need to be remembered any longer than the moment or two we spend perceiving them and, if necessary, reacting to them. In fact, dividing memory between short-term and long-term stores is such a savvy way of managing information that most computers are built around the same model. They have long-term memories in the form of hard drives as well as a working memory cache in the CPU that stores whatever the processor is computing at the moment. Like a computer, our ability to operate in the world, is limited by the amount of information we can juggle at one time. Unless we repeat things over and over, they tend to slip from our grasp. Everyone knows our working memory stinks. Miller’s paper explained that it stinks within very specific parameters. Some people can hold as few as five things in their head at any given time, a few people can hold as many as nine, but the “magical number seven” seems to be the universal carrying capacity of our short-term working memory.*  

- Page 53 (location ~ 801-810)    

*Chunking is a way to decrease the number of items you have to remember by increasing the size of each item. Chunking is the reason that phone numbers are broken into two parts plus an area code and that credit card numbers are split into groups of four. And chunking is extremely relevant to the question of why experts so often have such exceptional memories. The classic explanation of chunking involves language. If you were asked to memorize the twenty-two letters HEADSHOULDERS-KNEESTOES, and you didn’t notice what they spelled, you’d almost certainly have a tough time with it. But break up those twenty-two letters into four chunks—HEAD, SHOULDERS, KNEES, and TOES—and the task becomes a whole lot easier. And if you happen to know the full nursery rhyme, the line “Head, shoulders, knees, and toes” can effectively be treated like one single chunk. The same can be done with numbers. The twelve-digit numerical string 120741091101 is pretty hard to remember. Break it into four chunks—120, 741, 091, 101—and it becomes a little easier. Turn it into two chunks, 12/07/41 and 09/11/01, and they’re almost impossible to forget. You could even turn those dates into a single chunk of information by remembering it as “the two big surprise attacks on American soil.”*  

- Page 57 (location ~ 866-875)    

*When a graduate of the Zen-Nippon Chick Sexing School looks at a chick’s bottom, finely honed perceptual skills allow the sexer to quickly and automatically gather up a stock of information embedded in the chick’s anatomy, and before a conscious thought can even enter his or her head, the sexer knows whether the chick is a boy or a girl. But as with the senior SWAT officer, that seemingly automatic knowledge is hard earned. It is said that a student of sexing must work through at least 250,000 chicks before attaining any degree of proficiency. Even if the sexer calls it “intuition,” it’s been shaped by years of experience. It is the vast memory bank of chick bottoms that allows him or her to recognize patterns in the vents glanced at so quickly. In most cases, the skill is not the result of conscious reasoning, but pattern recognition. It is a feat of perception and memory, not analysis.*  

- Page 58 (location ~ 889-895)    

*What De Groot uncovered was an even bigger surprise than what his Russian predecessors had found. For the most part, the chess experts didn’t look more moves ahead, at least not at first. They didn’t even consider more possible moves. Rather, they behaved in a manner surprisingly similar to the chicken sexers: They tended to see the right moves, and they tended to see them almost right away. It was as if the chess experts weren’t thinking so much as reacting. When De Groot listened to their verbal reports, he noticed that they described their thoughts in different language than less experienced chess players. They talked about configurations of pieces like “pawn structures” and immediately noticed things that were out of sorts, like exposed rooks. They weren’t seeing the board as thirty-two pieces. They were seeing it as chunks of pieces, and systems of tension.*  

- Page 60 (location ~ 908-914)    

*But the most striking finding of all from these early studies of chess experts was their astounding memories. The experts could memorize entire boards after just a brief glance. And they could reconstruct longago games from memory. In fact, later studies confirmed that the ability to memorize board positions is one of the best overall indicators of how good a chess player somebody is. And these chess positions are not simply encoded in transient short-term memory. Chess experts can remember positions from games for hours, weeks, even years afterward. Indeed, at a certain point in every chess master’s development, keeping mental track of the pieces on the board becomes such a trivial skill that they can take on several opponents at once, entirely in their heads.*  

- Page 60 (location ~ 918-923)    

*In the same way that a few pages ago we used our knowledge of historic dates to chunk the twelve-digit number, chess masters use the vast library of chess patterns that they’ve cached away in long-term memory to chunk the board. At the root of the chess master’s skill is that he or she simply has a richer vocabulary of chunks to recognize. Which is why it is so rare for anyone to achieve world-class status in chess—or any other field—without years of experience. Even Bobby Fischer, perhaps the greatest chess prodigy of all time, had been playing intensely for nine years before he was recognized as a grand master at age fifteen. Contrary to all the old wisdom that chess is an intellectual activity based on analysis, many of the chess master’s important decisions about which moves to make happen in the immediate act of perceiving the board. Like the chicken sexer who looks at the chick and simply sees its gender or the SWAT officer who immediately notices the bomb, the chess master looks at the board and simply sees the most promising move. The process usually happens within five seconds, and you can actually see it transpiring in the brain. Using magnetoencephalography, a technique that measures the weak magnetic fields given off by a thinking brain, researchers have found that higher-rated chess players are more likely to engage the frontal and parietal cortices of the brain when they look at the board, which suggests that they are recalling information from long-term memory.*  

- Page 61 (location ~ 930-940)    

*Lower-ranked players are more likely to engage the medial temporal lobes, which suggests that they are encoding new information. The experts are interpreting the present board in term of their massive knowledge of past ones. The lower-ranked players are seeing the board as something new. Though chess might seem like a trivial subject for a psychologist to study—it is, after all, just a game—De Groot believed that his experiments with chess masters had much larger implications. He argued that expertise in “the field of shoemaking, painting, building, [or] confectionary” is the result of the same accumulation of “experiential linkings.” According to Ericsson, what we call expertise is really just “vast amounts of knowledge, pattern-based retrieval, and planning mechanisms acquired over many years of experience in the associated domain.” In other words, a great memory isn’t just a by-product of expertise; it is the essence of expertise.*  

- Page 62 (location ~ 940-947)    

*The medial temporal lobes—there’s one on each side of the brain—include the hippocampus and several adjacent regions that together perform the magical feat of turning our perceptions into long-term memories. Memories aren’t actually stored in the hippocampus—they reside elsewhere, in the brain’s corrugated outer layers, the neocortex—but the hippocampal area makes them stick. EP’s hippocampus was destroyed, and without it he is like a camcorder without a working tape head. He sees, but he doesn’t record. EP has two types of amnesia—anterograde, which means he can’t form new memories, and retrograde, which means he can’t recall old memories either, at least not since about 1950. His childhood, his service in the merchant marine, World War II—all that is perfectly vivid. But as far as he knows, gas costs a quarter a gallon, and man never took that small step onto the moon.*  

- Page 66 (location ~ 1003-1009)    

*Without time, there would be no need for a memory. But without a memory, would there be such a thing as time? I don’t mean time in the sense that, say, physicists speak of it: the fourth dimension, the independent variable, the quantity that compresses when you approach the speed of light. I mean psychological time, the tempo at which we experience life’s passage. Time as a mental construct. Watching EP struggle to recount his own age, I recalled one of the stories Ed Cooke had told me about his research at the University of Paris when we met at the U.S. Memory Championship. “I’m working on expanding subjective time so that it feels like I live longer,” Ed had mumbled to me on the sidewalk outside the Con Ed headquarters, a cigarette dangling from his mouth. “The idea is to avoid that feeling you have when you get to the end of the year and feel like, where the hell did that go?” “And how are you going to do that?” I asked. “By remembering more. By providing my life with more chronological landmarks. By making myself more aware of time’s passage.” I told him that his plan reminded me of Dunbar, the pilot in Joseph Heller’s Catch-22 who reasons that since time flies when you’re having fun, the surest way to slow life’s passage is to make it as boring as possible. Ed shrugged. “Quite the opposite. The more we pack our lives with memories, the slower time seems to fly.” Our subjective experience of time is highly variable. We all know that days can pass like weeks and months can feel like years, and that the opposite can be just as true: A month or year can zoom by in what feels like no time at all.*  

- Page 69 (location ~ 1055-1068)    

*There is perhaps a bit of Peter Pan to Ed’s quest to make his life maximally memorable, but of all the things one could be obsessive about collecting, memories of one’s own life don’t seem like the most unreasonable. There’s something even strangely rational about it. There’s an old philosophical conundrum that often gets bandied about in introductory philosophy courses: In the nineteenth century, doctors began to wonder whether the general anesthetic they had been administering to patients might not actually put the patients to sleep so much as freeze their muscles and erase their memories of the surgery. If that were the case, could the doctors be said to have done anything wrong? Like the proverbial tree that falls without anyone hearing it, can an experience that isn’t remembered be meaningfully said to have happened at all? Socrates thought the unexamined life was not worth living. How much more so the unremembered life?*  

- Page 72 (location ~ 1093-1099)    

*This phenomenon of unconscious remembering, known as priming, is evidence of an entire shadowy underworld of memories lurking beneath the surface of our conscious reckoning. Though there is disagreement about just how many memory systems there are, scientists generally divide memories broadly into two types: declarative and nondeclarative (sometimes referred to as explicit and implicit). Declarative memories are things you know you remember, like the color of your car, or what happened yesterday afternoon. EP and HM had lost the ability to make new declarative memories. Nondeclarative memories are the things you know unconsciously, like how to ride a bike or how to draw a shape while looking at it in a mirror (or what a word flashed rapidly across a computer screen means). Those unconscious memories don’t seem to pass through the same short-term memory buffer as declarative memories, nor do they depend on the hippocampal region to be consolidated and stored. They rely primarily on different parts of the brain. Motor skill learning takes place largely in the cerebellum, perceptual learning in the neocortex, habit learning in the basal ganglia. As EP and HM have so strikingly demonstrated, you can damage one part of the brain, and the rest will keep on working. Indeed, most of who we are and how we think—the core material of our personalities—is bound up in implicit memories that are off-limits to the conscious brain. Within the category of declarative memories, psychologists make a further distinction between semantic memories, or memories for facts and concepts, and episodic memories, or memories of the experiences of our own lives. Recalling that I had eggs for breakfast this morning would be an episodic memory. Knowing that breakfast is the first meal of the day is a semantic memory. Episodic memories are located in time and space: They have a where and a when attached to them. Semantic memories are located outside of time and space, as free-floating pieces of knowledge. These two different types of remembering seem to make use of different neural pathways, and rely on different regions of the brain, though both are critically dependent on the hippocampus and other structures within the medial temporal lobes. EP has lost both types of memory in equal measure, but curiously his forgetfulness extends back only for the last sixty or so years. His memories have faded along a gradient.*  

- Page 75 (location ~ 1135-1152)    

*Until the age of three or four, almost nothing that happens to us leaves the sort of lasting impression that can be consciously recalled as an adult. The average age that people report having their earliest memory is three and a half, and those tend to be just blurry, fragmentary snapshots that are often false. How strange that during the period when a person is learning more rapidly than at any other point in his life—when one is learning to walk and talk and make sense of the world—so little of that learning is of the kind that is explicitly memorable. Freud thought that infantile amnesia was a matter of adults repressing the hypersexualized fantasies of early childhood, which only become shameful in later life. I’m not sure you could find too many psychologists who still cling to that interpretation. The more likely explanation for this strange early forgetting lies in the fact that our brains are maturing rapidly during the first couple years of life, with unused neural connections getting pruned back, and new connections constantly forming. The neocortex is not fully developed until about the third or fourth year, around the time that children start laying down permanent memories. Anatomy, however, may only tell part of the story. As infants, we also lack schema for interpreting the world and relating the present to the past. Without experience—and perhaps most important, without the essential organizing tool of language—infants lack the capacity to embed their memories in a web of meaning that will make them accessible later in life. Those structures only develop over time, through exposure to the world. The vital learning that we do during the first years of life is virtually entirely of the implicit, nondeclarative kind. In other words, everyone on earth has had some taste of EP’s condition. And like EP, we’ve all forgotten what it’s like.*  

- Page 77 (location ~ 1181-1194)    

*“Our neighbors love him because he’ll come up to them and just start talking to them,” Beverly tells me. Even though he thinks he’s meeting them for the first time, he’s learned through force of habit that these are people he should feel comfortable with, and he interprets those unconscious feelings of comfort as a good reason to stop and say hello. That EP has learned to like his neighbors without ever learning who they are points to how many of our basic day-to-day actions are guided by implicit values and judgments, independent of declarative memory. I wonder what other things EP has learned through force of habit. What other nondeclarative memories have continued to shape him over the decade and a half since he lost his declarative memory? Surely, he must still have desires and fears, emotions, and cravings—even if his conscious recollection of those feelings is so fleeting that he cannot recognize them for long enough to verbalize them.*  

- Page 79 (location ~ 1202-1209)    

*Much as our taste for sugar and fat may have served us well in a world of scarce nutrition, but is now maladaptive in a world of ubiquitous fast food joints, our memories aren’t perfectly adapted for our contemporary information age. The tasks that we often rely on our memories for today simply weren’t relevant in the environment in which the human brain evolved. Our ancestors didn’t need to recall phone numbers, or word-for-word instructions from their bosses, or the Advanced Placement U.S. history curriculum, or (because they lived in relatively small, stable groups) the names of dozens of strangers at a cocktail party. What our early human and hominid ancestors did need to remember was where to find food and resources, and the route home, and which plants were edible and which were poisonous. Those are the sorts of vital memory skills that they depended on every day, and it was—at least in part—in order to meet those demands that human memory evolved as it did. The principle underlying all memory techniques is that our brains don’t remember all types of information equally well. As exceptional as we are at remembering visual imagery (think of the two-picture recognition test), we’re terrible at remembering other kinds of information, like lists of words or numbers. The point of memory techniques is to do what the synasthete S did instinctually: to take the kinds of memories our brains aren’t good at holding on to and transform them into the kinds of memories our brains were built for.*  

- Page 82 (location ~ 1250-1261)    

*Ed told me that by learning the techniques he was about to teach, I would be installing myself in a “proud tradition of mnemonists.” That proud tradition began, at least according to legend, in the fifth century B.C. with the poet Simonides of Ceos standing in the rubble of the great banquet hall collapse in Thessaly. As the poet closed his eyes and reconstructed the crumbled building in his imagination, he had an extraordinary realization: He remembered where each of the guests at the ill-fated dinner had been sitting. Even though he had made no conscious effort to memorize the layout of the room, it had nevertheless left a durable impression upon his memory. From that simple observation, Simonides reputedly invented a technique that would form the basis of what came to be known as the art of memory. He realized that if it hadn’t been guests sitting at the banquet table, but rather something else—say, every great Greek dramatist seated in order of their dates of birth—he would have remembered that instead. Or what if, instead of banquet guests, he saw each of the words of one of his poems arrayed around the table? Or every task he needed to accomplish that day? Just about anything that could be imagined, he reckoned, could be imprinted upon one’s memory, and kept in good order, simply by engaging one’s spatial memory in the act of remembering. To use Simonides’ technique, all one has to do is convert something unmemorable, like a string of numbers or a deck of cards or a shopping list or Paradise Lost, into a series of engrossing visual images and mentally arrange them within an imagined space, and suddenly those forgettable items become unforgettable.*  

- Page 85 (location ~ 1293-1304)    

*In a world with few books, memory was sacrosanct. Just look at Pliny the Elder’s Natural History, the first-century encyclopedia that chronicled all things wondrous and useful for winning bar bets in the classical world, including the most exceptional memories then known to history. “King Cyrus could give the names of all the soldiers in his army,” Pliny reports. “Lucius Scipio knew the names of the whole Roman people. King Pyrrhus’s envoy Cineas knew those of the Senate and knighthood at Rome the day after his arrival ... A person in Greece named Charmadas recited the contents of any volumes in libraries that anyone asked him to quote, just as if he were reading them.” There are plenty of reasons not to take everything Pliny says at face value (he also reported the existence of a race of dog-headed people in India) but the sheer volume of anecdotes about extraordinary memories in the classical world is itself telling. Seneca the Elder could repeat two thousand names in the order they’d been given to him. St. Augustine tells of a friend, Simplicius, who could recite Virgil by heart—backward. (That he could recite it forward seems to have been unremarkable.) A strong memory was seen as the greatest virtue since it represented the internalization of a universe of external knowledge. “Ancient and medieval people reserved their awe for memory. Their greatest geniuses they describe as people of superior memories,” writes Mary Carruthers, the author of two books on the history of memory techniques. Indeed, the single most common theme in the lives of the saints—besides their superhuman goodness—is their often extraordinary memories.*  

- Page 86 (location ~ 1319-1330)    

*The artificial memory is that memory which is strengthened by a kind of training and system of discipline.” In other words, natural memory is the hardware you’re born with. Artificial memory is the software you run on your hardware. Artificial memory, the anonymous author continues, has two basic components: images and places. Images represent the contents of what one wishes to remember. Places—or loci, as they’re called in the original Latin—are where those images are stored. The idea is to create a space in the mind’s eye, a place that you know well and can easily visualize, and then populate that imagined place with images representing whatever you want to remember. Known as the “method of loci” by the Romans, such a building would later come to be called a “memory palace.”*  

- Page 87 (location ~ 1333-1339)    

*The principle of the memory palace, he continued, is to use one’s exquisite spatial memory to structure and store information whose order comes less naturally—in this case, Ed’s to-do list. “What you’re going to find is that in the same way as it’s impossible to get confused about the order of rooms in that house, it will be equally obvious that immediately after I locate three hula hoops, a snorkel, and a dry ice machine, my next task will be e-mailing my friend Sophia.” The crucial thing was to choose a memory palace with which I was intimately familiar. “For your first memory palace, I’d like you to use the house you grew up in, since that’s a space you’re likely to know very well,” Ed said. “We’re going to array the items of my to-do list one by one along a route that will snake around your childhood home. When it comes time to recall the list, all you will need to do is retrace the steps we’re about to take in your imagination. The hope is that all the objects you’re about to memorize will pop back into mind. Now, tell me, is your childhood home a bungalow?” “More of a two-story brick house,” I said. “Does it have a cute postbox at the end of the driveway?” “No. Why?” “Shame. That would be an excellent first locus at which to deposit an image of the first item on our to-do list. But that’s okay. We can start at the foot of the driveway. I want you to close your eyes and try to visualize in as much detail as possible a large bottle of pickled garlic standing right where the car should be parked.”*  

- Page 89 (location ~ 1357-1369)    

*“Now I want you to imagine Claudia Schiffer swimming in this tub of cottage cheese. I want you to imagine her swimming in the buff, and dripping with dairy. Are you picturing this? I don’t want you to miss any of the details here.” The Ad Herennium advises readers at length about creating the images for one’s memory palace: the funnier, lewder, and more bizarre, the better. “When we see in everyday life things that are petty, ordinary, and banal, we generally fail to remember them, because the mind is not being stirred by anything novel or marvelous. But if we see or hear something exceptionally base, dishonorable, extraordinary, great, unbelievable, or laughable, that we are likely to remember for a long time.” The more vivid the image, the more likely it is to cleave to its locus. What distinguishes a great mnemonist, I was learning, is the ability to create these sorts of lavish images on the fly, to paint in the mind a scene so unlike any that has been seen before that it cannot be forgotten. And to do it quickly. Which is why Tony Buzan tells anyone who will listen that the World Memory Championship is less a test of memory than of creativity.*  

- Page 91 (location ~ 1386-1395)    

*Consider: How many of the lunches that you ate over the last week can you recall? Do you remember what you ate today? I hope so. Yesterday? I bet it takes a moment’s effort. And what about the day before yesterday? What about a week ago? It’s not so much that your memory of last week’s lunch has disappeared; if provided with the right cue, like where you ate it, or whom you ate it with, you would likely recall what had been on your plate. Rather, it’s difficult to remember last week’s lunch because your brain has filed it away with all the other lunches you’ve ever eaten as just another lunch. When we try to recall something from a category that includes as many instances as “lunch” or “wine,” many memories compete for our attention. The memory of last Wednesday’s lunch isn’t necessarily gone; it’s that you lack the right hook to pull it out of a sea of lunchtime memories. But a wine that talks: That’s unique. It’s a memory without rivals.*  

- Page 93 (location ~ 1424-1431)    

*Ed, I had already discovered, was always memorizing something. He had long ago learned the bulk of Paradise Lost by heart (at the rate of two hundred lines per hour, he told me), and had been slowly slogging his way through Shakespeare. “My philosophy of life is that a heroic person should be able to withstand about ten years in solitary confinement without getting terribly annoyed,” he said. “Given that an hour of memorization yields about ten solid minutes of spoken poetry, and those ten minutes have enough content to keep you busy for a full day, I figure you can squeeze at least a day’s fun out of each hour of memorization—if you should ever happen to find yourself in solitary confinement.” This worldview owes a lot to the collection of ancient and medieval texts on memory that Ed had relentlessly tried to foist upon me. For those early writers, a trained memory wasn’t just about gaining easy access to information; it was about strengthening one’s personal ethics and becoming a more complete person. A trained memory was the key to cultivating “judgment, citizenship, and piety.” What one memorized helped shape one’s character. Just as the secret to becoming a chess grand master was to learn old games, the secret to becoming a grand master of life was to learn old texts. In a tight spot, where could one look for guidance about how to act, if not the depths of memory? Mere reading is not necessarily learning—a fact that I am personally confronted with every time I try to remember the contents of a book I’ve just put down. To really learn a text, one had to memorize it. As the early-eighteenth-century Dutch poet Jan Luyken put it, “One book, printed in the Heart’s own wax / Is worth a thousand in the stacks.”*  

- Page 99 (location ~ 1509-1521)    

*Even though the best American mnemonists can memorize hundreds of random digits in an hour, U.S. records still pale in comparison to those of the Europeans. Generally, nobody in North America takes memory sport seriously enough to stop drinking three months before the world championship, like the eight-time world memory champ Dominic O’Brien used to do, and from the looks of it, few competitors engage in the rigorous physical training regimen that Buzan recommends. (One of his first, unsolicited pieces of advice to me was to get in shape.) Nobody downs daily glasses of cod liver oil or takes omega-3 supplements. Only one American, the four-time national champion Scott Hagwood, has ever been inducted into the KL7. Even though America has run its national memory championship for as long as any country in the world, the best American memorizer has only finished in the top five of the world championship once, in 1999. Perhaps it says something about our national character that America has produced none of the world’s best competitive memorizers—that we’re not as detail-obsessed as the Germans, as punctilious as the Brits, or as driven as the Malaysians. Or maybe, as one European soberly suggested to me, Americans have impoverished memories because we are preoccupied with the future, while folks on the other side of the Atlantic are more concerned with the past. Whatever the reason, it became clear that if I wanted to learn more about the art of memory—if I wanted to study with the best in the world—I was going to have to go to Europe.*  

- Page 102 (location ~ 1554-1565)    

*Most of the mental athletes on the memory circuit came to the sport the same way I did: They once saw someone perform an outrageous memory stunt, thought it was cool, learned the trick behind it, and then went home and tried it themselves. But Ben missed one critical step. He’d seen someone memorizing playing cards and thought it was cool, and went home and tried it himself. But nobody ever told him how it was done. Without using any techniques at all, he just stared at the cards over and over again until they’d become imprinted on his brain. And the amazing thing is, he kept doing this in his spare time for several months, under the assumption that eventually he’d surely get good at it. He finally got his time down to fifteen minutes using pure rote memorization, a feat in many ways more impressive than his world record time of thirty-two seconds using techniques. It wasn’t until he showed up at his first World Memory Championship in 2000 that he found out about the memory palace. After the first day of events wrapped up (he finished near last place), he went to a bookstore, bought one of Tony Buzan’s books, decided this was something he had a talent for, and forgot about all of his other extracurricular interests, including his lifelong quest to watch every one of the 1,001 theatrically released Warner Bros. cartoons made between 1930 and 1968.*  

- Page 107 (location ~ 1637-1646)    

*Unlike the U.S. championship, which has just five events, none lasting longer than fifteen minutes, the World Memory Championship is frequently referred to as a “mental decathlon.” Its ten events, called “disciplines,” span three grueling days, and each tests the competitors’ memories in a slightly different way. Contestants have to memorize a previously unpublished poem spanning several pages, pages of random words (record: 280 in fifteen minutes), lists of binary digits (record: 4,140 in thirty minutes), shuffled decks of playing cards, a list of historical dates, and names and faces. Some disciplines, called “speed events,” test how much the contestants can memorize in five minutes (record: 405 digits). Two marathon disciplines test how many decks of cards and random digits they can memorize in an hour (records: 2,080 digits and 27 decks of cards).*  

- Page 109 (location ~ 1666-1672)    

*The question of how best to memorize a piece of text, or a speech, has vexed mnemonists for millennia. The earliest memory treatises described two types of recollection: memoria rerum and memoria verborum, memory for things and memory for words. When approaching a text or a speech, one could try to remember the gist, or one could try to remember verbatim. The Roman rhetoric teacher Quintilian looked down on memoria verborum on the grounds that creating such a vast number of images was not only inefficient, since it would require a gargantuan memory palace, but also unstable. If your memory for a speech hinged on knowing every word, then not only did you have a lot more to remember, but if you forgot a single word, you could end up trapped in a room of your memory palace staring at a blank wall, lost and unable to move on. Cicero agreed that the best way to memorize a speech is point by point, not word by word, by employing memoria rerum. In his De Oratore, he suggests that an orator delivering a speech should make one image for each major topic he wants to cover, and place each of those images at a locus. Indeed, the word “topic” comes from the Greek word topos, or place. (The phrase “in the first place” is a vestige from the art of memory.)*  

- Page 111 (location ~ 1699-1708)    

*The most famous of the Western tradition’s oral works, and the first to have been systematically studied, were Homer’s Odyssey and Iliad. These two poems—possibly the first to have been written down in the Greek alphabet—had long been held up as literary archetypes. However, even as they were celebrated as the models to which all literature should aspire, Homer’s masterworks had also long been the source of scholarly unease. The earliest modern critics sensed that they were somehow qualitatively different from everything that came after—even a little strange. For one thing, both poems were oddly repetitive in the way they referred to characters. Odysseus was always “clever Odysseus.” Dawn was always “rosy-fingered.” Why would someone write like that? Sometimes the epithets seemed completely off-key. Why call the murderer of Agamemnon “blameless Aegisthos”? Why refer to “swift-footed Achilles” even when he was sitting down? Or to “laughing Aphrodite” even when she was in tears? In terms of both structure and theme, the Odyssey and Iliad were also oddly formulaic, to the point of predictability. The same narrative units—gathering armies, heroic shields, challenges between rivals—pop up again and again, only with different characters and different circumstances. In the context of such finely spun, deliberate masterpieces, these quirks seemed hard to explain.*  

- Page 114 (location ~ 1744-1754)    

*In 1920, an eighteen-year-old scholar named Milman Parry took up the question of Homeric authorship as his master’s thesis at the University of California, Berkeley. He suggested that the reason Homer’s epics seemed unlike other literature was because they were unlike other literature. Parry had discovered what Wood and Wolf had missed: the evidence that the poems had been transmitted orally was right there in the text itself. All those stylistic quirks, including the formulaic and recurring plot elements and the bizarrely repetitive epithets—“clever Odysseus” and “gray-eyed Athena”—that had always perplexed readers were actually like thumbprints left by a potter: material evidence of how the poems had been crafted. They were mnemonic aids that helped the bard(s) fit the meter and pattern of the line, and remember the essence of the poems. The greatest author of antiquity was actually, Parry argued, just “one of a long tradition of oral poets that ... composed wholly without the aid of writing.”*  

- Page 116 (location ~ 1766-1773)    

*And the Odyssey and Iliad, excuse the cliché, are riddled with them. In a culture dependent on memory, it’s critical, in the words of Walter Ong, that people “think memorable thoughts.” The brain best remembers things that are repeated, rhythmic, rhyming, structured, and above all easily visualized. The principles that the oral bards discovered, as they sharpened their stories through telling and retelling, were the same basic mnemonic principles that psychologists rediscovered when they began conducting their first scientific experiments on memory around the turn of the twentieth century: Words that rhyme are much more memorable than words that don’t; concrete nouns are easier to remember than abstract nouns; dynamic images are more memorable than static images; alliteration aids memory. A striped skunk making a slam dunk is a stickier thought than a patterned mustelid engaging in athletic activity.*  

- Page 116 (location ~ 1777-1783)    

*The anonymous author of the Ad Herrenium suggests that the best method for remembering poetry ad verbum is to repeat a line two or three times before trying to see it as a series of images. This is more or less the method that Gunther Karsten uses in the poem competition. He assigns every single word to a route point. But this method has a glaring problem: There are lots of words that simply can’t be visualized. What does an “and” look like? Or a “the”? Some two thousand years ago, Metrodorus of Scepsis, a Greek contemporary of Cicero’s, offered a solution to the quandary of how to see the unseeable. Metrodorus developed a system of shorthand images that would stand in for conjunctions, articles, and other syntactical connectors. It allowed him to memorize anything he read or heard verbatim. Indeed, Metrodorus’s library of symbols seems to have been widely used in ancient Greece. The Ad Herennium mentions that “most of the Greeks who have written on memory have taken the course of listing images that correspond to a great many words, so that persons who wished to learn these images by heart would have them ready without expending effort in search of them.” Though Gunther doesn’t use Metrodorus’s symbols, which unfortunately have been lost to history, he has created his own dictionary of images for each of the two hundred most common words that can’t easily be visualized. “And” is a circle (“and” rhymes with rund, which means round in German). “The” is someone walking on his knees (die, a German word for “the,” rhymes with Knie, the German word for “knee”). When the poem reaches a period, he hammers a nail into that locus. Gunther could just as easily be memorizing a VCR repair manual as a Shakespearean sonnet. In fact, a VCR repair manual would probably be a good deal easier, since it is filled with concrete, easily visualized words like “button,” “television,” and “plug.” The challenge of memorizing poetry is its abstractness. What do you do with words like “ephemeral” or “self” that are impossible to see?*  

- Page 119 (location ~ 1817-1831)    

*Gunther’s method of creating an image for the un-imageable is a very old one: to visualize a similarly sounding, or punning, word in its place. The fourteenth-century English theologian and mathematician Thomas Bradwardine, who was later appointed archbishop of Canterbury, took this kind of verbatim memorization to its highest and most absurd level of development. He described a means of memoria sillabarum , or “memory by syllables,” which could be used to memorize words that were hard to visualize. Bradwardine’s system involved breaking the word into its constituent syllables and then creating an image for each syllable based on another word that begins with that syllable. For example, if one wanted to remember the syllable “ab-,” one would picture an abbot. For “ba-” one might visualize a crossbowman (a balistarius). When strung together, a chain of these syllables becomes a kind of rebus puzzle. (The Swedish pop group Abba could be recalled as an abbot getting shot by a crossbow.) This process of transforming words into images involves a kind of remembering by forgetting: In order to memorize a word by its sound, its meaning has to be completely dismissed. Bradwardine could translate even the most pious benediction into a preposterous scene. To remember the topic sentence of a sermon that begins “Benedictus Dominus qui per,” he’d see “the sainted Benedictine dancing to his left with a white cow with super-red teats who holds a partridge, while with his right hand he either mangles or caresses St. Dominic.”*  

- Page 120 (location ~ 1832-1842)    

*According to a survey conducted in 2007 by a neuropsychologist at Trinity College Dublin, fully a third of Brits under the age of thirty can’t remember even their own home land line number without pulling it up on their handsets. The same survey found that 30 percent of adults can’t remember the birthdays of more than three immediate family members. Our gadgets have eliminated the need to remember such things anymore. Forgotten phone numbers and birthdays represent minor erosions of our everyday memory, but they are part of a much larger story of how we’ve supplanted our own natural memory with a vast superstructure of technological crutches—from the alphabet to the BlackBerry. These technologies of storing information outside our minds have helped make our modern world possible, but they’ve also changed how we think and how we use our brains.*  

- Page 124 (location ~ 1892-1898)    

*  In Plato’s Phaedrus, Socrates describes how the Egyptian god Theuth, inventor of writing, came to Thamus, the king of Egypt, and offered to bestow his wonderful invention upon the Egyptian people. “Here is a branch of learning that will ... improve their memories,” Theuth said to the Egyptian king. “My discovery provides a recipe for both memory and wisdom.” But Thamus was reluctant to accept the gift. “If men learn this, it will implant forgetfulness in their souls,” he told the god. “They will cease to exercise their memory and become forgetful; they will rely on that which is written, calling things to remembrance no longer from within themselves, but by means of external marks. What you have discovered is a recipe not for memory, but for reminding. And it is no true wisdom that you offer your disciples, but only its semblance, for by telling them of many things without teaching them anything, you will make them seem to know much, while for the most part they will know nothing. And as men filled not with wisdom but with the conceit of wisdom, they will be a burden to their fellow-men.”*  

- Page 124 (location ~ 1899-1907)    

*Socrates lived in the fifth century B.C., at a time when writing was ascendant in Greece, and his own views were already becoming antiquated. Why was he so put off by the idea of putting pen to paper? Securing memories on the page would seem to be an immensely superior way of retaining knowledge compared to trying to hold it in the brain. The brain is always making mistakes, forgetting, misremembering. Writing is how we overcome those essential biological constraints. It allows our memories to be pulled out of the fallible wetware of the brain and secured on the less fallible page, where they can be made permanent and (one sometimes hopes) disseminated far, wide, and across time. Writing allows ideas to be passed across generations, without fear of the kind of natural mutation that is necessarily a part of oral traditions. To understand why memory was so important in the world of Socrates, we have to understand something about the evolution of writing, and how different early books were in both form and function. We have to go back to an age before printing, before indexes and tables of contents, before the codex parceled texts into pages and bound them at the edge, before punctuation marks, before lowercase letters, even before there were spaces between words. Today we write things down precisely so we don’t have to hold them in our memories. But through at least the late Middle Ages, books served not as replacements for memory, but rather as memory aids. As Thomas Aquinas put it, “Things are written down in material books to help the memory.” One read in order to remember, and books were the best available tools for impressing information into the mind. In fact, manuscripts were often copied for no reason other than to help their copier memorize them.*  

- Page 125 (location ~ 1913-1926)    

*The difficulties associated with reading such texts meant that there was a very different relationship between reading and memory than the one we know today. Since sight-reading scriptio continua was difficult, reciting a text aloud with fluency required a reader to have a degree of familiarity with it. He—and it was mostly he’s—had to prepare with it, punctuate it in his mind, memorize it—in part, if not in full—because turning a string of sounds into meaning was not something you could do easily on the fly. The text had to be learned before it could be performed. After all, the way one punctuated a text written in scriptio continua could make all the difference in the world. As the historian Jocelyn Penny Small pointed out, GODISNOWHERE comes out a lot differently when rendered as GOD IS NOW HERE versus GOD IS NOWHERE. What’s more, a scroll written in scriptio continua had to be read top to bottom if anything was to be taken from it. A scroll has just a single point of entry, the first word. Because it has to be unwound to be read, and because there are no punctuation marks or paragraphs to break up the text—to say nothing of page numbers, a table of contents, chapter divisions, and an index—it is impossible to find a specific piece of information without scanning the whole thing, head to toe. It is not a text that can be easily consulted—until it is memorized. This is a key point. Ancient texts couldn’t be readily scanned. You couldn’t pull a scroll off the shelf and quickly find a specific excerpt unless you had some baseline familiarity with the entire text. The scroll existed not to hold its contents externally, but rather to help its reader navigate its contents internally.*  

- Page 127 (location ~ 1943-1955)    

*The first concordance of the Bible, a grand index that consumed the labors of five hundred Parisian monks, was compiled in the thirteenth century, around the same time that chapter divisions were introduced. For the first time, a reader could refer to the Bible without having previously memorized it. One could find a passage without knowing it by heart or reading the text all the way through. Soon after the concordance, other books with alphabetical indexes, page numbers, and tables of contents began to appear, and as they did, they again helped change the essence of what a book was. The problem of the book before the index and table of contents is that for all the material contained in a scroll or between the covers of a book, it was impossible to navigate. What makes the brain such an incredible tool is not just the sheer volume of information it contains but the ease and efficiency with which it can find that information. It uses the greatest random-access indexing system ever invented—one that computer scientists haven’t come even close to replicating. Whereas an index in the back of a book provides a single address—a page number—for each important subject, each subject in the brain has hundreds if not thousands of addresses. Our internal memories are associational, nonlinear. You don’t need to know where a particular memory is stored in order to find it. It simply turns up—or doesn’t—when you need it. Because of the dense network that interconnects our memories, we can skip around from memory to memory and idea to idea very rapidly. From Barry White to the color white to milk to the Milky Way is a long voyage conceptually, but a short jaunt neurologically.*  

- Page 130 (location ~ 1986-1998)    

*To our memory-bound predecessors, the goal of training one’s memory was not to become a “living book,” but rather a “living concordance,” a walking index of everything one had read, and all the information one had acquired. It was about more than merely possessing an internal library of facts, quotes, and ideas; it was about building an organizational scheme for accessing them. Consider, for example, Peter of Ravenna, a leading fifteenth-century Italian jurist (also, one gets the impression, one of the fifteenth century’s leading self-promoters) who authored one of the era’s most successful books on memory training. Titled Phoenix, it was translated into several languages and reprinted all across Europe. It was just the most famous of a handful of memory treatises created from the thirteenth century onward that helped make memory techniques that had long been the exclusive purview of scholars and monks available to a wider audience of doctors, lawyers, tradesmen, and everyday folks who just wanted to remember stuff. One finds books from the period on every variety of mnemonic subject, including how to use the art of memory in gambling, how to use it to keep track of debts, how to memorize the contents of ships, how to remember the names of acquaintances, and how to memorize playing cards. Peter, for his part, bragged of having memorized twenty thousand legal points, a thousand texts by Ovid, two hundred of Cicero’s speeches and sayings, three hundred sayings of philosophers, seven thousand texts from Scripture, as well as a host of other classical works.*  

- Page 131 (location ~ 2006-2017)    

*When the point of reading is, as it was for Peter of Ravenna, remembering, you approach a text very differently than most of us do today. Now we put a premium on reading quickly and widely, and that breeds a kind of superficiality in our reading, and in what we seek to get out of books. You can’t read a page a minute, the rate at which you’re probably reading this book, and expect to remember what you’ve read for any considerable length of time. If something is going to be made memorable, it has to be dwelled upon, repeated. In his essay “The First Steps Toward a History of Reading,” Robert Darnton describes a switch from “intensive” to “extensive” reading that occurred as books began to proliferate. Until relatively recently, people read “intensively,” says Darnton. “They had only a few books—the Bible, an almanac, a devotional work or two—and they read them over and over again, usually aloud and in groups, so that a narrow range of traditional literature became deeply impressed on their consciousness.”*  

- Page 133 (location ~ 2025-2032)    

*I don’t think I’m an exceptionally bad reader. I suspect that many people, maybe even most, are like me. We read and read and read, and we forget and forget and forget. So why do we bother? Michel de Montaigne expressed the dilemma of extensive reading in the sixteenth century: “I leaf through books, I do not study them,” he wrote. “What I retain of them is something I no longer recognize as anyone else’s. It is only the material from which my judgment has profited, and the thoughts and ideas with which it has become imbued; the author, the place, the words, and other circumstances, I immediately forget.” He goes on to explain how “to compensate a little for the treachery and weakness of my memory,” he adopted the habit of writing in the back of every book a short critical judgment, so as to have at least some general idea of what the tome was about and what he thought of it.*  

- Page 134 (location ~ 2044-2050)    

*The Renaissance, with its fresh translations of ancient Greek texts, brought about a renewed fascination with Plato’s old idea that there is a transcendental ideal reality of which our own world is but a pale shadow. In Camillo’s Neoplatonic vision of the universe, images in the mind were a way of accessing that ideal realm, and the art of memory was a secret key to unlocking the occult structure of the universe. Memory was transformed from a tool of rhetoric, as it had been for the ancients, or an instrument of pious meditation, as it had been for the medieval scholastic philosophers, into a purely mystical art. Even more than Camillo, the greatest practitioner of this dark, mystical form of mnemonics was the Dominican friar Giordano Bruno. In his book On the Shadow of Ideas, published in 1582, Bruno promised that his art “will help not only the memory but also all the powers of the soul.” Memory training, for Bruno, was the key to spiritual enlightenment. Bruno had literally come up with a new twist on the old art of memory. Drawing inspiration from the palindromically named thirteenth-century Catalan philosopher and mystic Ramon Llull, Bruno invented a device that would allow him to turn any word into a unique image. Bruno imagined a series of concentric wheels, each of which had 150 two-letter pairs around its perimeter, corresponding to all of the combinations that could be formed by the thirty letters of the alphabet (the twenty-three letters of classical Latin, plus seven Greek and Hebrew letters that didn’t have an equivalent in the Latin alphabet) and the five vowels: AA, AE, AI, AO, AU, BA, BE, BO, etc. On the innermost wheel, the 150 two-letter combinations were each paired with a different mythological or occult figure. On the perimeter of the second wheel were 150 actions and predicaments—“sailing,” “on the carpet,” “broken”—corresponding to another set of letter pairs. The third wheel consisted of 150 adjectives, the fourth wheel had 150 objects, and the fifth wheel had 150 “circumstances,” such as “dressed in pearls” or “riding a sea monster.” By properly aligning the wheels, any word up to five syllables long could be translated into a unique, vivid image.*  

- Page 136 (location ~ 2082-2097)    

*The most popular of these nineteenth-century mnemonic handbooks was written by Professor Alphonse Loisette, an American “memory doctor” who, despite his prolific remembering, “had somehow forgotten that he was born Marcus Dwight Larrowe and that he had no degree,” as one article notes. The fact that I was able to find 136 used copies of Loisette’s 1886 book Physiological Memory: The Instantaneous Art of Never Forgetting selling for as little as $1.25 on the Internet is evidence of its once immense popularity. Loisette’s book is essentially a collection of mnemonic systems for remembering sundry trivia, like the order of American presidents, the counties of Ireland, the Morse telegraphic alphabet, the British territorial regiments, and the names and uses of the nine pairs of cranial nerves. Loisette claimed his system was wholly unrelated to classical mnemonics, for which he professed disdain, and that he had discovered, entirely by himself, the “laws of natural memory.” Loisette charged as much as twenty-five dollars (more than five hundred dollars in today’s money) to impart this knowledge to his pupils in seminars held all across the country, including classes at just about every prestigious university on the eastern seaboard. Inductees into the “Loisette System” were made to sign a contract binding them to secrecy, with a penalty of five hundred dollars (over ten thousand dollars in today’s money) should they divulge the professor’s methods. There was, it seems, good money to be made peddling secrets of memory improvement to a credulous American audience. According to the doctor’s own numbers, he earned today’s equivalent of almost a half million dollars over a single fourteen-week stretch in the winter of 1887.*  

- Page 138 (location ~ 2109-2122)    

*Twain himself was continually experimenting with new memory techniques to aid him on the lecture circuit. At one point early in his career, he wrote the first letter of topics he planned to drop into his speech on each of his ten fingernails, but that never really worked, since audiences began to suspect him of having some sort of vain interest in his hands. During the summer of 1883, while he was writing Huckleberry Finn, Twain procrastinated by developing a game to teach his children the English monarchs. It worked by mapping out the lengths of their reigns using pegs along a road near his home. Twain was essentially turning his backyard into a memory palace. In 1885, he patented “Mark Twain’s Memory Builder: A Game for Acquiring and Retaining All Sorts of Facts and Dates.” Twain’s notebooks are filled with pages dedicated to his spatial memory game.*  

- Page 140 (location ~ 2133-2139)    

*For the last decade, Bell has kept a digital “surrogate memory” to supplement the one in his brain. It ensures that a record is kept of anything and everything that might be forgotten. A miniature digital camera, called a SenseCam, dangles around his neck and records every sight that passes before his eyes. A digital recorder captures every sound he hears. Every phone call placed through his landline gets taped and every piece of paper Bell reads is immediately scanned into his computer. Bell, who is completely bald, often smiling, and wears rectangular glasses and a black turtleneck, calls this process of obsessive archiving “lifelogging.” All this obsessive recording may seem strange, but thanks to the plummeting price of digital storage, the increasing ubiquity of digital sensors, and better artificial intelligence to sort through the mess of data we’re constantly collecting, it’s becoming easier and easier to capture and remember ever more information from the world around us. We may never walk around with cameras dangling from our necks, but Bell’s vision of a future in which computers remember everything that happens to us is not nearly as absurd as it might at first sound. Bell made his name and fortune as an early computing pioneer at the Digital Equipment Corporation in the 1960s and ’70s. (He’s been called the “Frank Lloyd Wright of computers.”) He’s an engineer by nature, which means he sees problems and tries to build solutions. With the SenseCam, he is trying to fix an elemental human problem: that we forget our lives almost as fast as we live them. But why should any memory fade when there are technological solutions that can preserve it? In 1998, with the help of his assistant Vicki Rozyki, Bell began backfilling his lifelog by systematically scanning every document in the dozens of banker boxes he’d amassed since the 1950s. All of his old photos, engineering notebooks, and papers were digitized. Even the logos on his T-shirts couldn’t escape the scanner bed. Bell, who had always been a meticulous preservationist, figures he’s probably scanned and thrown away three quarters of all the stuff he’s ever owned. Today his lifelog takes up 170 gigabytes, and is growing at the rate of about a gigabyte each month. It includes over 100,000 e-mails, 65,000 photos, 100,000 documents, and 2,000 phone calls. It fits comfortably on a hundred-dollar hard drive. Bell can pull off some sensational stunts with his “surrogate memory.” With his custom search engine, he can, in an instant, figure out where he was and whom he was with at any moment in time, and then, in theory, check to see what that person said. And because he’s got a photographic record of everywhere he’s ever been and everything he’s ever seen, he has no excuse for ever losing anything. His digital memory never forgets.*  

- Page 141 (location ~ 2162-2182)    

*When it comes to memorizing long strings of numbers, like a hundred thousand digits of pi or the career batting averages of every New York Yankee Hall of Famer, most mental athletes use a more complex technique that is known on the Worldwide Brain Club (the online forum for memory junkies, Rubik’s cubers, and mathletes) as “person-action-object,” or, simply, PAO. It traces its lineage directly back to the loopy combinatorial mnemonics of Giordano Bruno and Ramon Llull. In the PAO system, every two-digit number from 00 to 99 is represented by a single image of a person performing an action on an object. The number 34 might be Frank Sinatra (a person) crooning (an action) into a microphone (an object). Likewise, 13 might be David Beckham kicking a soccer ball. The number 79 could be Superman flying with a cape. Any six-digit number, like say 34-13-79, can then be turned into a single image by combining the person from the first number with the action from the second and the object from the third—in this case, it would be Frank Sinatra kicking a cape. If the number were instead 79-34-13, the mental athlete might imagine the equally bizarre image of Superman crooning at a soccer ball. There’s nothing inherently Sinatraish about the number 34 or Beckhamesque about 13. Unlike the Major System, those associations are entirely arbitrary, and have to be learned in advance, which is to say it takes a lot of remembering just to be able to remember. There’s a big fixed cost in terms of time and effort to compete on the memory circuit. But what makes this system so potent is that it effectively generates a unique image for every number from 0 to 999,999. And because the algorithm necessarily generates unlikely scenes, PAO images tend, by their nature, to be memorable.*  

- Page 148 (location ~ 2255-2267)    

*Mental athletes memorize decks of playing cards in much the same way, using a PAO system in which each of the fifty-two cards is associated with its own person/action/object image. This allows any triplet of cards to be combined into a single image, and for a full deck to be condensed into just eighteen unique images (52 divided by 3 is 17, with one card left over). With Ed’s help, I laboriously created my own PAO system, which involved dreaming up fifty-two separate person/action/object images. To be maximally memorable, one’s images have to appeal to one’s own sense of what is colorful and interesting. Which means that a mental athlete’s stock of PAO images is a pretty good guide to the gremlins that live in someone’s subconscious: in my case, 1980s and early 1990s TV icons; in Ben Pridmore’s case, cartoon characters; in Ed’s case, lingerie models and Depression-era English cricketers.*  

- Page 149 (location ~ 2276-2282)    

*In the 1960s, the psychologists Paul Fitts and Michael Posner attempted to answer this question by describing the three stages that anyone goes through when acquiring a new skill. During the first phase, known as the “cognitive stage,” you’re intellectualizing the task and discovering new strategies to accomplish it more proficiently. During the second “associative stage,” you’re concentrating less, making fewer major errors, and generally becoming more efficient. Finally you reach what Fitts called the “autonomous stage,” when you figure that you’ve gotten as good as you need to get at the task and you’re basically running on autopilot. During that autonomous stage, you lose conscious control over what you’re doing. Most of the time that’s a good thing. Your mind has one less thing to worry about. In fact, the autonomous stage seems to be one of those handy features that evolution worked out for our benefit. The less you have to focus on the repetitive tasks of everyday life, the more you can concentrate on the stuff that really matters, the stuff that you haven’t seen before. And so, once we’re just good enough at typing, we move it to the back of our mind’s filing cabinet and stop paying it any attention. You can actually see this shift take place in fMRI scans of people learning new skills. As a task becomes automated, the parts of the brain involved in conscious reasoning become less active and other parts of the brain take over. You could call it the “OK plateau,” the point at which you decide you’re OK with how good you are at something, turn on autopilot, and stop improving. We all reach OK plateaus in most things we do. We learn how to drive when we’re in our teens and then once we’re good enough to avoid tickets and major accidents, we get only incrementally better. My father has been playing golf for forty years, and he’s still—though it will hurt him to read this—a duffer. In four decades his handicap hasn’t fallen even a point. How come? He reached an OK plateau. Psychologists used to think that OK plateaus marked the upper bounds of innate ability. In his 1869 book Hereditary Genius, Sir Francis Galton argued that a person could only improve at physical and mental activities up until he reached a certain wall, which “he cannot by any education or exertion overpass.” According to this view, the best we can do is simply the best we can do.*  

- Page 152 (location ~ 2327-2344)    

*What separates experts from the rest of us is that they tend to engage in a very directed, highly focused routine, which Ericsson has labeled “deliberate practice.” Having studied the best of the best in many different fields, he has found that top achievers tend to follow the same general pattern of development. They develop strategies for consciously keeping out of the autonomous stage while they practice by doing three things: focusing on their technique, staying goal-oriented, and getting constant and immediate feedback on their performance. In other words, they force themselves to stay in the “cognitive phase.”*  

- Page 154 (location ~ 2347-2351)    

*When you want to get good at something, how you spend your time practicing is far more important than the amount of time you spend. In fact, in every domain of expertise that’s been rigorously examined, from chess to violin to basketball, studies have found that the number of years one has been doing something correlates only weakly with level of performance. My dad may consider putting into a tin cup in his basement a good form of practice, but unless he’s consciously challenging himself and monitoring his performance—reviewing, responding, rethinking, rejiggering—it’s never going to make him appreciably better. Regular practice simply isn’t enough. To improve, we must watch ourselves fail, and learn from our mistakes. The best way to get out of the autonomous stage and off the OK plateau, Ericsson has found, is to actually practice failing. One way to do that is to put yourself in the mind of someone far more competent at the task you’re trying to master, and try to figure out how that person works through problems. Benjamin Franklin was apparently an early practitioner of this technique. In his autobiography, he describes how he used to read essays by the great thinkers and try to reconstruct the author’s arguments according to Franklin’s own logic. He’d then open up the essay and compare his reconstruction to the original words to see how his own chain of thinking stacked up against the master’s. The best chess players follow a similar strategy. They will often spend several hours a day replaying the games of grand masters one move at a time, trying to understand the expert’s thinking at each step.*  

- Page 154 (location ~ 2355-2366)    

*The secret to improving at a skill is to retain some degree of conscious control over it while practicing—to force oneself to stay out of autopilot. With typing, it’s relatively easy to get past the OK plateau. Psychologists have discovered that the most efficient method is to force yourself to type faster than feels comfortable, and to allow yourself to make mistakes. In one noted experiment, typists were repeatedly flashed words 10 to 15 percent faster than their fingers were able to translate them onto the keyboard. At first they weren’t able to keep up, but over a period of days they figured out the obstacles that were slowing them down, and overcame them, and then continued to type at the faster speed. By bringing typing out of the autonomous stage and back under their conscious control, they had conquered the OK plateau. Ericsson suggested I try the same thing with cards. He told me to find a metronome and to try to memorize a card every time it clicked. Once I figured out my limits, he instructed me to set the metronome 10 to 20 percent faster than that and keep trying at the quicker pace until I stopped making mistakes. Whenever I came across a card that was particularly troublesome, I was supposed to make a note of it, and see if I could figure out why it was giving me problems. It worked, and within a couple days I was off the OK plateau and my card times began falling again at a steady clip.*  

- Page 155 (location ~ 2368-2377)    

*How is it that we continue to surpass ourselves? Part of Ericsson’s answer is that the barriers we collectively set are as much psychological as innate. Once a benchmark is deemed breakable, it usually doesn’t take long before someone breaks it. For a long time, people thought that no one would ever run a mile in under four minutes. It was considered an immovable barrier, like the speed of light. When Roger Bannister, a twenty-year-old British medical student, finally broke the four-minute mile in 1954, his accomplishment was splashed across the front pages of newspapers around the world and hailed as one of the greatest athletic achievements of all time. But the barrier turned out to be more like a floodgate. It took only six weeks before an Australian named John Landy ran the mile a second and a half faster than Bannister, and within a few years four-minute miles were commonplace. Today, all professional middle-distance runners are expected to clock four-minute miles and the world record has fallen to 3 minutes and 43.13 seconds. At the World Memory Championship, at least half the existing world records fall each year. Instead of thinking of enhancing my memory as analogous to stretching my height or improving my vision or tweaking some other fundamental attribute of my body, Ericsson encouraged me to think of it more like improving a skill—more like learning to play an instrument.*  

- Page 157 (location ~ 2403-2412)    

*That has always been the rap against memory techniques: They’re impressive but ultimately useless. The seventeenth-century philosopher Francis Bacon declared, “I make no more estimation of repeating a great number of names or words upon once hearing ... than I do of the tricks of tumblers, funambuloes, baladines: the one being the same in the mind that the other is in the body, matters of strangeness without worthiness.” He thought the art of memory was fundamentally “barren.” When the sixteenth-century Jesuit missionary Matteo Ricci tried to introduce memory techniques to Chinese Mandarins studying for the imperial civil service exam, he was met with resistance. He planned to hook them first on European study skills before trying to hook them on the European god. The Chinese objected that the method of loci required so much more work than rote repetition, and claimed their way of memorizing was both simpler and faster. I could understand where they were coming from.*  

- Page 169 (location ~ 2591-2598)    

*The last century has been an especially bad one for memory. A hundred years of progressive education reform have discredited memorization as oppressive and stultifying—not only a waste of time, but positively harmful to the developing brain. Schools have deemphasized raw knowledge (most of which gets forgotten anyway), and instead stressed their role in fostering reasoning ability, creativity, and independent thinking. But is it possible we’ve been making a huge mistake? The influential critic E. D. Hirsch Jr. complained in 1987: “We cannot assume that young people today know things that were known in the past by almost every literate person in the culture.” Hirsch has argued that students are being sent out into the world without the basic level of cultural literacy that is necessary to be a good citizen (what does it say that two thirds of American seventeen-year-olds can’t even tell you within fifty years when the Civil War occurred?), and what’s needed is a kind of educational counterreformation that reemphasizes hard facts. Hirsch’s critics have pointed out that the curriculum he advocates is Dead White Males 101. But if anyone seems qualified to counter that argument it is Matthews, who maintains that for all the Eurocentrism of the curriculum, the fact is that facts still matter. If one of the goals of education is to create inquisitive, knowledgeable people, then you need to give students the most basic signposts that can guide them through a life of learning. And if, as the twelfth-century teacher Hugh of St. Victor put it, “the whole usefulness of education consists only in the memory of it,” then you might as well give them the best tools available to commit their education to memory. “I don’t use the word ‘memory’ in my class because it’s a bad word in education,” says Matthews. “You make monkeys memorize, whereas education is the ability to retrieve information at will and analyze it. But you can’t have higher-level learning—you can’t analyze—without retrieving information.” And you can’t retrieve information without putting the information in there in the first place. The dichotomy between “learning” and “memorizing” is false, Matthews contends. You can’t learn without memorizing, and if done right, you can’t memorize without learning.*  

- Page 175 (location ~ 2671-2688)    

*“In our gross misunderstanding of the function of memory, we thought that memory was operated primarily by rote. In other words, you rammed it in until your head was stuffed with facts. What was not realized is that memory is primarily an imaginative process. In fact, learning, memory, and creativity are the same fundamental process directed with a different focus,” says Buzan. “The art and science of memory is about developing the capacity to quickly create images that link disparate ideas. Creativity is the ability to form similar connections between disparate images and to create something new and hurl it into the future so it becomes a poem, or a building, or a dance, or a novel. Creativity is, in a sense, future memory.” If the essence of creativity is linking disparate facts and ideas, then the more facility you have making associations, and the more facts and ideas you have at your disposal, the better you’ll be at coming up with new ideas. As Buzan likes to point out, Mnemosyne, the goddess of memory, was the mother of the Muses. The notion that memory and creativity are two sides of the same coin sounds counterintuitive. Remembering and creativity seem like opposite, not complementary, processes. But the idea that they are one and the same is actually quite old, and was once even taken for granted. The Latin root inventio is the basis of two words in our modern English vocabulary: inventory and invention. And to a mind trained in the art of memory, those two ideas were closely linked. Invention was a product of inventorying. Where do new ideas come from if not some alchemical blending of old ideas? In order to invent, one first needed a proper inventory, a bank of existing ideas to draw on. Not just an inventory, but an indexed inventory. One needed a way of finding just the right piece of information at just the right moment.*  

- Page 183 (location ~ 2803-2815)    

*Buzan has a troubling habit of lapsing into pseudoscience and hyperbole when he describes how wonderfully revolutionary memory training can be, or how he has “changed the lives of millions.” He’s been known to say preposterous things, like “Very young children use 98 percent of all thinking tools. By the time they’re 12, they use about 75 percent. By the time they’re teenagers, they’re down to 50 percent, by the time they’re in university it’s less than 25 percent, and it’s less than 15 percent by the time they’re in industry.” The fact that Buzan can go around making outrageous claims about the brain and not only be widely believed but actually celebrated is evidence of what a wild frontier the world of brain science is, and how much people want to believe that their memories are improvable. The truth is, the operating manual for the brain that Buzan went looking for in college still hasn’t been written.*  

- Page 186 (location ~ 2841-2848)    

*When information goes “in one ear and out the other,” it’s often because it doesn’t have anything to stick to. This is something I was personally confronted with not long ago, when I had the opportunity to visit Shanghai for three days while reporting an article. Somehow I had managed to scoot through two decades of schooling without ever learning even the most basic facts about Chinese history. I’d never learned the difference between Ming and Qing, or even that Kublai Khan was actually a real person.*  

- Page 188 (location ~ 2870-2873)    

*This paradox—it takes knowledge to gain knowledge—is captured in a study in which researchers wrote up a detailed description of a half inning of baseball and gave it to a group of baseball fanatics (“experts” is the term Ericsson would use) and a group of less avid fans to read. Afterward they tested how well their subjects could recall the half inning. The baseball fanatics structured their recollections around important game-related events, like runners advancing and runs scoring. They were able to reconstruct the half inning in sharp detail. One almost got the impression they were reading off an internal scorecard. The less avid fans remembered fewer important facts about the game and were more likely to recount superficial details like the weather. Because they lacked a detailed internal representation of the game, they couldn’t process the information they were taking in. They didn’t know what was important and what was trivial. They couldn’t remember what mattered. Without a conceptual framework in which to embed what they were learning, they were effectively amnesics.*  

- Page 188 (location ~ 2877-2884)    

*Even though it’s described as a syndrome, savantism is not actually a recognized medical condition, and has no set of standard diagnostic criteria. However, Treffert divides savants into three informal categories. There are “splinter skill” savants who have memorized a single esoteric body of trivia, like Treffert’s young patient who can tell you the year and model of a vacuum cleaner just from its unique hum. A second group, which he calls “talented savants,” have developed a more general area of expertise, like drawing or music, which is remarkable only because it stands in such stark contrast to their disability. The third group, prodigious savants, have abilities that would be spectacular by any standard, even if they weren’t accompanied by handicaps in other areas. It’s a subjective scale, but an important one, Treffert believes, because prodigious savants are members of one of the rarest classes of human being on the planet. When a new prodigious savant like Daniel is discovered, it is a very big deal.*  

- Page 192 (location ~ 2937-2943)    

*According to Baron-Cohen, two rare conditions may have conspired to produce Daniel’s savant abilities. The first is synesthesia, the same perceptual disorder that afflicted the journalist S, in which the senses are intertwined. By one estimate, there are more than a hundred different varieties of the disorder. For S, sounds conjured up visual imagery. In Daniel’s case, numbers take on a distinctive shape, color, texture, and emotional “tone.” The number 9, for example, is tall, dark blue, and ominous, while 37 is “lumpy like porridge” and 89 resembles falling snow. Daniel says he has a unique synesthetic reaction like that for every number up to 10,000, and that experiencing numbers in this way allows him to do quick mental math without pencil or paper. To multiply two numbers, he sees each number’s shape floating in his mind’s eye. Intuitively, and without effort, he says, a third shape, the answer, forms in the negative space between them. “It’s like a crystallization. It’s like developing a photo,” Daniel told me. “Division is just the reverse of multiplication. I see the number and I pull it apart in my head. It’s like leaves falling from a tree.” Daniel believes his synesthetic shapes somehow implicitly encode important information about the properties of numbers. Prime numbers, for example, have a “pebble-like quality.” They’re soft and round, without the jagged edges of numbers that can be factorized. Daniel’s other rare condition is Asperger’s syndrome, a form of high-functioning autism. Autism was first identified in 1943 by the child psychiatrist Leo Kanner. He described it as a form of social impairment, a disorder in which, as Kanner put it, patients “treat people as if they were things.” Along with this inability to empathize, autistic individuals have a host of other problems, including language impairment, an extremely focused range of interests, and “an anxiously obsessive desire for the preservation of sameness.” A year after Kanner first wrote about autism, an Austrian pediatrician named Hans Asperger noted another disorder that seemed almost identical except that Asperger’s patients had strong linguistic abilities and fewer intellectual impairments. He called his precocious young patients, with their bottomless wells of arcane trivia, “little professors.” It wasn’t until 1981 that Asperger’s was recognized as its own separate syndrome. Daniel’s Asperger’s diagnosis was made by Baron-Cohen, who runs the Cambridge Autism Research Centre and who also happens to be one of the world’s leading authorities on synesthesia. “If you saw him today, you wouldn’t necessarily think that this guy has a form of autism,” Baron-Cohen told me over tea in his Trinity College office one afternoon. “It’s only in the context of hearing his developmental history. I said to him, ‘Your development suggests that when you were younger you had Asperger’s syndrome, whereas looking at you today, you’ve made such a good adaptation and you’re functioning so very well that you don’t necessarily need a diagnosis. It’s up to you whether you want one or not. He said, ‘Yes, I prefer to have it.’ It gave him a new way of looking at himself. That’s fine. It fits with his profile.”*  

- Page 194 (location ~ 2972-2995)    

*Kim likes to be called the “Kimputer,” but his full name is Laurence Kim Peek. “We named him after Laurence Olivier and Rudyard Kipling’s Kim,” says Fran. When Kim was born, after a difficult pregnancy, it was immediately clear that something was deeply off. His head was a third larger than normal and sprouted a fist-size blister on its backside that the doctors were afraid to remove. For the first three years of his life, Kim dragged his head on the ground as if it were loaded with a heavy weight. He didn’t walk until he was four. His parents were urged to consider a lobotomy. Instead Kim was put on heavy sedatives until he was fourteen. Fran recalls that it was only when Kim was taken off the sedatives that he first started to show an interest in books. He’s been memorizing them ever since. But even though Kim has access to a larger store of knowledge than perhaps anyone else on the planet, he doesn’t seem able to put it toward any end other than itself. He has an IQ of just 87. And no matter how many books of etiquette he may have memorized, his sense of what’s socially appropriate is, to put it generously, esoteric. Standing in a crowd of people in the lobby of the Salt Lake City public library, Kim wrapped his thick arms around my shoulders and gripped me against his paunch and then forcibly gyrated against me. “Joshua Foer, you are a great, great man,” he told me loudly enough to startle a passerby. “You are a handsome man. You are a man of your generation.” And then he let out a deep roar. How Kim can do what he does is a mystery to science. Unlike Dustin Hoffman’s character in Rain Man, Kim is not, apparently, autistic. He’s far too sociable for that diagnosis. He’s something else entirely. In January 1989, the same week that Rain Man was released, a CT scan of Kim’s brain revealed that his cerebellum, an organ crucial to sensory perception and motor function, was severely distended. An earlier scan had discovered that Kim also lacks a corpus callosum, the thick bundle of neurons that connects the left and right hemispheres of the brain, and allows them to communicate. It’s an incredibly rare condition, but how it might contribute to his savantism isn’t at all clear.*  

- Page 200 (location ~ 3062-3078)    

*One of the challenges of developing a theory to explain savant syndrome is that it expresses itself so differently in different individuals. However, there is one neuroanatomical anomaly that turns up again and again in savants, including Kim: damage in the brain’s left hemisphere. Interestingly, the exaggerated abilities of savants are almost always in right-brain sorts of activities, like visual and spatial skills, and savants almost always have trouble with tasks that are supposed to be primarily the left-brain’s domain, such as language. Speech defects are extremely common among savants, which is part of the reason that loquacious, well-spoken Daniel seems so extraordinary. Some researchers have theorized that shutting off certain left-brain activities somehow liberates right-brain skills that had been latent all along. Indeed, people have been known to suddenly acquire savantlike abilities later in life, after a traumatic injury to the left side of the brain. In 1979, a ten-year-old boy named Orlando Serrell took a baseball pitch to the left side of his head and came to with a remarkable capacity to calculate calendar dates and remember the weather on every day of his life. Bruce Miller, a neurologist at the University of California, San Francisco, studies elderly patients with a relatively common form of brain disease called frontotemporal dementia, or FTD. He’s found that in some cases where the FTD is localized on the left side of the brain, people who had never picked up a paintbrush or an instrument can develop extraordinary artistic and musical abilities at the very end of their lives. As their other cognitive skills fade away, they become narrow savants. The fact that people can become savants so spontaneously suggests that those exceptional abilities must lie dormant, to some degree, in all of us. There may be, as Treffert likes to put it, “a little Rain Man” hiding inside every brain. He’s just kept under lock and key by the inhibitory “tyranny of the dominant left hemisphere.”*  

- Page 202 (location ~ 3087-3101)    

*If the rest of us could turn off that top-level processing, would we become savants? There actually is a technology that can selectively, and temporarily, turn off parts of the brain. It’s called transcranial magnetic stimulation, or TMS, and it works by using focused magnetic fields to wreak havoc on the electrical firing of targeted neurons. The deadening effect can last for upwards of an hour. Although TMS is relatively new, it has been used successfully as a noninvasive means of treating problems as diverse as depression, post-traumatic stress disorder, and migraines. But in many ways, TMS’s experimental potential is even more exciting than its therapeutic uses. There are obviously some intractable ethical problems with experimenting on the human brain. Since you can’t go in and mess around with a living brain (HM taught us that), much of what neuroscientists have been able to learn about the brain has been the result of a few “natural experiments” caused by extremely unlikely forms of brain damage (like EP’s). Because TMS allows neuroscientists to turn regions of the brain on and off at will, they can use it to perform repeatable experiments without waiting for someone to walk into their office with a rare lesion that just happens to affect the specific part of the brain they want to study. Allan Snyder, an Australian neuroscientist who popularized TMS as an experimental tool, uses the technique to temporarily induce savantlike artistic skills in otherwise normal people by targeting the left frontotemporal lobe (the same region that is often damaged in savants). After having the left temporal lobe zapped, subjects can draw more accurate pictures from memory, and can more quickly estimate the number of dots flashed on a screen. Snyder calls his device a “creativity-amplifying machine.” He might as well call it the savant cap.*  

- Page 203 (location ~ 3112-3124)    

*Talking to a few experts, I learned that anyone who has done mental multiplication might have suspicions about those sliding fingers. One of the most common techniques for calculating the product of two large numbers is known as cross multiplication. It involves doing a sequence of individual multiplications of single-digit numbers and then combining them together in the end. To my eye, this appeared to be what Daniel may have been doing on the table. Daniel denies this. He says it’s just a fidget that helps him concentrate. “There are a lot of people in the world who can do those kinds of things, but they’re still pretty impressive,” Ben Pridmore told me. In addition to competing on the memory circuit, Ben also competes in the Mental Calculation World Cup, a biennial contest in which participants carry out mental calculations far more extreme than Daniel’s, including multiplying eight-digit numbers without pencil or paper. None of these top calculators make any claims about seeing numerical shapes that fuse and divide in their minds’ eyes. They all readily admit to using techniques detailed in countless books and Web sites. I asked Ronald Doerfler, author of one of those books, Dead Reckoning: Calculating Without Instruments, to watch Brainman and tell me what he thought. “I’m not fantastically impressed with any of that,” he said of Daniel’s mathematical talents, and added, “The lore of mental calculators is rife with misdirection.”*  

- Page 205 (location ~ 3138-3148)    

*As late as the nineteenth century, the term “savant” had an entirely different connotation than it has today. It was the highest epithet that could be bestowed on a man of learning. A savant was someone who had mastered multiple fields, who traded in abstract ideas, who “consecrate[d] their energies to the search for truth,” as Charles Richet, the author of the 1927 book The Natural History of a Savant, put it. The term had nothing to do with singular abilities or a prodigious memory. And yet over the last century the word’s meaning has changed. In 1887, John Langdon Down, better known for the chromosomal disorder that bears his name, coined the term “idiot savant.” The word “idiot,” regarded as politically incorrect, eventually fell away. In a world in which our everyday memories have atrophied and we’ve become totally estranged from the idea of a disciplined memory, “savant” has gone from being a term of art and an emblem of intellectual accomplishment to being a freakish condition, a syndrome. You’d never hear a polymath like Oliver Sacks described as a savant today, though he, as much as anyone, meets the dictionary definition. Today, the word is reserved for people like the autistic twins that Sacks famously wrote about, who were supposedly able to count 111 matches the instant they spilled onto the floor. So what about someone like Daniel? One of the oldest myths about savants is that they were destined to be born into this world as geniuses, but by some terrible twist of fate had all of their aptitudes curtailed but one.*  

- Page 213 (location ~ 3260-3271)    

*Though I’d been operating with inferior mnemonotechnics in the numbers event, when it came to speed cards, the next challenge, I was the only competitor armed with what Ed referred to as “the latest European weaponry.” Most of the Americans were still placing a single card in each locus, and even the guys who’d been competing for years, like Ram and “Ice Man” Chester, were at best turning two cards into a single image. In fact, only a couple of years ago it was entirely unheard of for anyone to be able to memorize a whole pack of cards at the U.S. championship. Thanks to Ed, the PAO system I was using packed three cards into a single image, which meant that it was at least 50 percent more efficient than what was being used by any of the other Americans. It was a huge advantage. Even if Maurice, Chester, and Ram were going to wipe me in the other disciplines, I hoped I might be able to run up my score in speed cards.*  

- Page 223 (location ~ 3416-3422)  
