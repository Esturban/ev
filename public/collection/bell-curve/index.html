<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Esteban | Ëˆe-stÉ™-vÉ™n - /collection/bell-curve/</title>

<meta name="description" content="Bite-sized ideas sourced from the internet">

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<!-- plugins -->

<link rel="stylesheet" href="/hugo-theme-console/css/terminal-0.7.1.min.css">

<link rel="stylesheet" href="/hugo-theme-console/css/animate-3.7.2.min.css">

<link rel="stylesheet" href="/hugo-theme-console/css/console.css">

<link rel="stylesheet" href="/css/hugo-easy-gallery.css">

<link rel="stylesheet" href="/css/style.css">

<script src="https://kit.fontawesome.com/0e201c44f1.js" crossorigin="anonymous"></script>
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
    
<link rel="apple-touch-icon-precomposed" sizes="57x57" href="favicon/apple-touch-icon-57x57.png" />
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="favicon/apple-touch-icon-114x114.png" />
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="favicon/apple-touch-icon-72x72.png" />
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="favicon/apple-touch-icon-144x144.png" />
<link rel="apple-touch-icon-precomposed" sizes="60x60" href="favicon/apple-touch-icon-60x60.png" />
<link rel="apple-touch-icon-precomposed" sizes="120x120" href="favicon/apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon-precomposed" sizes="76x76" href="favicon/apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="favicon/apple-touch-icon-152x152.png" />
<link rel="icon" type="image/png" href="favicon/favicon-196x196.png" sizes="196x196" />
<link rel="icon" type="image/png" href="favicon/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/png" href="favicon/favicon-32x32.png" sizes="32x32" />
<link rel="icon" type="image/png" href="favicon/favicon-16x16.png" sizes="16x16" />
<link rel="icon" type="image/png" href="favicon/favicon-128.png" sizes="128x128" />
<meta name="application-name" content="&nbsp;"/>
<meta name="msapplication-TileColor" content="#FFFFFF" />
<meta name="msapplication-TileImage" content="favicon/mstile-144x144.png" />
<meta name="msapplication-square70x70logo" content="favicon/mstile-70x70.png" />
<meta name="msapplication-square150x150logo" content="favicon/mstile-150x150.png" />
<meta name="msapplication-wide310x150logo" content="favicon/mstile-310x150.png" />
<meta name="msapplication-square310x310logo" content="favicon/mstile-310x310.png" />

<meta property="og:title" content="Bell Curve (Richard J. Herrnstein)" />
<meta property="og:description" content="Bite-sized ideas sourced from the internet" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/collection/bell-curve/" /><meta property="article:published_time" content="2017-05-15T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/favicon/apple-touch-icon-57x57.png"/>

<meta name="twitter:title" content="Bell Curve (Richard J. Herrnstein)"/>
<meta name="twitter:description" content="Hola, this is el summary"/>

    
</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              <a href="/" class="no-style site-name">estebanvalencia.com</a>:~# <a href='/collection'>collection</a>/<a href='/collection/bell-curve'>bell-curve</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="/me/" typeof="ListItem">me/</a></li>
                
                <li><a href="/collection/" typeof="ListItem">collection/</a></li>
                
                <li><a href="/photos/" typeof="ListItem">photos/</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Bell Curve (Richard J. Herrnstein)</h1><p> May. 15, 2017</p>

<p>Read time: 401 minutes and
    12 seconds.</p>
<!-- layouts/blog/single.html --><!-- ... -->
tags: 
 
<ul class = "list-inline">
    <li class = "pill list-inline-item">
      <a href="/tags/books/">books</a>
   </li> <li class = "pill list-inline-item">
      <a href="/tags/review/">review</a>
   </li></ul>



<p><em>Spearman noted that as the data from many different mental tests were accumulating, a curious result kept turning up: If the same group of people took two different mental tests, anyone who did well (or poorly) on one test tended to do similarly well (or poorly) on the other. In statistical terms, the scores on the two tests were positively correlated. This outcome did not seem to depend on the specific content of the tests. As long as the tests involved cognitive skills of one sort or another, the positive correlations appeared. Furthermore, individual items within tests showed positive correlations as well. If there was any correlation at all between a pair of items, a person who got one of them right tended to get the other one right, and vice versa for those who got it wrong. In fact, the pattern was stronger than that. It turned out to be nearly impossible to devise items that plausibly measured some cognitive skill and were not positively correlated with other items that plausibly measured some cognitive skill, however disparate the pair of skills might appear to be. The size of the positive correlations among the pairs of items in a test did vary a lot, however, and it was this combination—positive correlations throughout the correlation matrix, but of varying magnitudes—that inspired Spearman’s insight.7 Why are almost all the correlations positive? Spearman asked. Because, he answered, they are tapping into the same general trait.</em></p>
<ul>
<li>Page 24 (location ~ 362-373)</li>
</ul>
<p><em>Because intelligence tests purported to test rigorously an important and valued trait about people (including ourselves and our loved ones), IQ also became one of the most visible and controversial products of social science. The first wave of public controversy occurred during the first decades of the century, when a few testing enthusiasts proposed using the results of mental tests to support outrageous racial policies. Sterilization laws were passed in sixteen American states between 1907 and 1917, with the elimination of mental retardation being one of the prime targets of the public policy. “Three generations of imbeciles are enough,” Justice Oliver Wendell Holmes declared in an opinion upholding the constitutionality of such a law.9 It was a statement made possible, perhaps encouraged, by the new enthusiasm for mental testing.</em></p>
<ul>
<li>Page 26 (location ~ 397-403)</li>
</ul>
<p><em>During the 1930s, mental tests evolved and improved as their use continued to spread throughout the world. David Wechsler worked on the initial version of the tests that would eventually become the Wechsler Adult Intelligence Scale and the Wechsler Intelligence Scale for Children, the famous WAIS and WISC. Terman and his associates published an improved version of the Stanford-Binet. But these tests were individually administered and had to be scored by trained personnel, and they were therefore too expensive to administer to large groups of people. Psychometricians and test publishers raced to develop group-administered tests that could be graded by machine. In the search for practical, economical measurements of intelligence, testing grew from a cottage industry to big business. World War II stimulated another major advance in the state of the art, as psychologists developed paper-and-pencil tests that could accurately identify specific military aptitudes, even ones that included a significant element of physical aptitude (such as an aptitude for flying airplanes). Shortly after the war, psychologists at the University of Minnesota developed the Minnesota Multiphasic Personality Inventory, the first machine-gradable standardized test with demonstrated validity as a predictor of various personality disorders. Later came the California Psychological Inventory, which measured personality characteristics within the normal range—“social presence” and “self-control,” for example. The testing industry was flourishing, and the annual Mental Measurements Yearbook that cataloged the tests grew to hundreds of pages. Hundreds of millions of people throughout the world were being psychologically tested every year.</em></p>
<ul>
<li>Page 29 (location ~ 440-452)</li>
</ul>
<p><em>Psychometricians of the 1930s had debated whether intelligence is almost entirely produced by genes or whether the environment also plays a role. By the 1960s and 1970s the point of contention had shifted dramatically. It had somehow become controversial to claim, especially in public, that genes had any effect at all on intelligence. Ironically, the evidence for genetic factors in intelligence had greatly strengthened during the very period when the terms of the debate were moving in the other direction. In the psychological laboratory, there was a similar shift. Psychological experimenters early in the century were, if anything, more likely to concentrate on the inborn patterns of human and animal behavior than on how the learning process could change behavior.18 But from the 1930s to the 1960s, the leading behaviorists, as they were called, and their students and disciples were almost all specialists in learning theory. They filled the technical journals with the results of learning experiments on rats and pigeons, the tacit implication being that genetic endowment mattered so little that we could ignore the differences among species, let alone among human individuals, and still discover enough about the learning process to make it useful and relevant to human concerns.19 There are, indeed, aspects of the learning process that cross the lines between species, but there are also enormous differences, and these differences were sometimes ignored or minimized when psychologists explained their findings to the lay public. B. F. Skinner, at Harvard University, more than any other of the leading behaviorists, broke out of the academic world into public attention with books that applied the findings of laboratory research on animals to human society at large.</em></p>
<ul>
<li>Page 31 (location ~ 464-477)</li>
</ul>
<p><em>The contrary notion—that individual differences could not easily be diminished by government intervention—collided head-on with the enthusiasm for egalitarianism, which itself collided head-on with a half-century of IQ data indicating that differences in intelligence are intractable and significantly heritable and that the average IQ of various socioeconomic and ethnic groups differs. In 1969, Arthur Jensen, an educational psychologist and expert on testing from the University of California at Berkeley, put a match to this volatile mix of science and ideology with an article in the Harvard Educational Review.21 Asked by the Review’s editors to consider why compensatory and remedial education programs begun with such high hopes during the War on Poverty had yielded such disappointing results, Jensen concluded that the programs were bound to have little success because they were aimed at populations of youngsters with relatively low IQs, and success in school depended to a considerable degree on IQ. IQ had a large heritable component, Jensen also noted. The article further disclosed that the youngsters in the targeted populations were disproportionately black and that historically blacks as a population had exhibited average IQs substantially below those of whites.</em></p>
<ul>
<li>Page 32 (location ~ 482-492)</li>
</ul>
<p><em>The uproar was exacerbated by William Shockley, who had won the Nobel Prize in physics for his contributions to the invention of the transistor but had turned his attention to human variation toward the end of his career. As eccentric as he was brilliant, he often recalled the eugenicists of the early decades of the century. He proposed, as a “thought exercise,” a scheme for paying people with low IQs to be sterilized.23 He supported (and contributed to) a sperm bank for geniuses. He seemed to relish expressing sensitive scientific findings in a way that would outrage or disturb as many people as possible. Jensen and Shockley, utterly unlike as they were in most respects, soon came to be classed together as a pair of racist intellectual cranks. Then one of us, Richard Herrnstein, an experimental psychologist at Harvard, strayed into forbidden territory with an article in the September 1971 Atlantic Monthly.</em></p>
<ul>
<li>Page 33 (location ~ 500-508)</li>
</ul>
<p><em>A movement that had begun in the 1960s gained momentum in the early 1970s, as major school systems throughout the country, including those of Chicago, New York, and Los Angeles, limited or banned the use of group-administered standardized tests in public schools. A number of colleges announced that they would no longer require the Scholastic Aptitude Test as part of the admissions process. The legal movement against tests reached its apogee in 1978 in the case of Larry P. Judge Robert Peckham of the U.S. District Court in San Francisco ruled that it was unconstitutional to use IQ tests for placement of children in classes for the educably mentally retarded if the use of those tests resulted in placement of “grossly disproportionate” numbers of black children.27</em></p>
<ul>
<li>Page 34 (location ~ 518-524)</li>
</ul>
<p><em>The classicists work within the tradition begun by Spearman, seeking to identify the components of intelligence much as physicists seek to identify the structure of the atom. As of the 1990s, the classicists are for practical purposes unanimous in accepting that g sits at the center of the structure in a dominating position—not just as an artifact of statistical manipulation but as an expression of a core human mental ability much like the ability Spearman identified at the turn of the century. In their view, g is one of the most thoroughly demonstrated entities in the behavioral sciences and one of the most powerful for understanding socially significant human variation.</em></p>
<ul>
<li>Page 39 (location ~ 588-593)</li>
</ul>
<p><em>Many of these efforts proved to have lasting value. For example, Cattell’s distinction between fluid and crystallized intelligence remains a useful conceptual contrast, just as other work has done much to clarify what lies in the domain of specific abilities that g cannot account for. But no one has been able to devise a set of tests that do not reveal a large general factor of intellectual ability—in other words, something very like Spearman’s g. Furthermore, the classicists point out, the best standardized tests, such as a modern IQ test, do a reasonably good job of measuring g. When properly administered, the tests are not measurably biased against socioeconomic, ethnic, or racial subgroups. They predict a wide variety of socially important outcomes.</em></p>
<ul>
<li>Page 40 (location ~ 605-610)</li>
</ul>
<p><em>Yes, the revisionists argue, human intelligence has a structure, but is it worth investing all that effort in discovering what it is? The preoccupation with structure has engendered preoccupation with summary scores, the revisionists say. That, after all, is what an IQ score represents: a composite of scores that individually measure quite distinct intellectual processes. “Of course,” Sternberg writes, “a tester can always average over multiple scores. But are such averages revealing, or do they camouflage more than they reveal? If a person is a wonderful visualizer but can barely compose a sentence, and another person can write glowing prose but cannot begin to visualize the simplest spatial images, what do you really learn about these two people if they are reported to have the same IQ?”</em></p>
<ul>
<li>Page 42 (location ~ 629-635)</li>
</ul>
<p><em>The first part of Sternberg’s triarchy attempts to describe the internal architecture of intellectual functioning, the means by which humans translate sensory inputs into mental representations, allocate mental resources, infer conclusions from raw material, and acquire skills. This architectural component of Sternberg’s theory bears a family resemblance to the classicists’ view of the dimensions of intelligence, but it emphasizes process over structure. The second part of the triarchic theory addresses the role of intelligence in routinizing performance, starting with completely novel tasks that test a person’s insightfulness, flexibility, and creativity, and eventually converting them to routine tasks that can be done without conscious thought. Understand this process, Sternberg argues, and we have leverage not just for measuring intelligence but for improving it. The third part of Sternberg’s triarchy attacks the question that has been central to the controversy over intelligence tests: the relationship of intelligence to the real world in which people function. In Sternberg’s view, people function by means of three mechanisms: adaptation (roughly, trying to make the best of the situation), shaping the external environment so that it conforms more closely to the desired state of affairs, or selecting a new environment altogether. Sternberg laments the inadequacies of traditional intelligence tests in capturing this real-world aspect of intelligence and seeks to develop tests that will do so—and, in addition, lead to techniques for teaching people to raise their intelligence.</em></p>
<ul>
<li>Page 42 (location ~ 640-652)</li>
</ul>
<p><em>Gardner’s general definition of intelligent behavior does not seem radical at all. For Gardner, as for many other thinkers on intelligence, the notion of problem solving is central. “A human intellectual competence must entail a set of skills of problem solving,” he writes, “enabling the individual to resolve genuine problems or difficulties that he or she encounters and, when appropriate, to create an effective product—and also must entail the potential for finding or creating problems—thereby laying the groundwork for the acquisition of new knowledge.”39 Gardner’s view is radical (a word he uses himself to describe his theory) in that he rejects, virtually without qualification, the notion of a general intelligence factor, which is to say that he denies g. Instead, he argues the case for seven distinct intelligences: linguistic, musical, logical-mathematical, spatial, bodily-kinesthetic, and two forms of “personal intelligence,” the intrapersonal and the interpersonal, each based on its own unique computational capacity.40 Gardner rejects the criticism that he has merely redefined the word intelligence by broadening it to include what may more properly be called talents: “I place no particular premium on the word intelligence, but I do place great importance on the equivalence of various human faculties,” he writes. “If critics [of his theory] were willing to label language and logical thinking as talents as well, and to remove these from the pedestal they currently occupy, then I would be happy to speak of multiple talents.”</em></p>
<ul>
<li>Page 44 (location ~ 661-673)</li>
</ul>
<p><em>He is untroubled by the fact that tests of the varying intelligences in his theory seem to be intercorrelated: “I fear . . . that I cannot accept these correlations at face value. Nearly all current tests are so devised that they call principally upon linguistic and logical facility. . . . Accordingly, individuals with these skills are likely to do well even in tests of musical or spatial abilities, while those who are not especially facile linguistically and logically are likely to be impaled on such standardized tests.”43 And in general, he invites his readers to disregard the thorny complexities of the classical and revisionist approaches: “When it comes to the interpretation of intelligence testing, we are faced with an issue of taste or preference rather than one on which scientific closure is likely to be reached.”</em></p>
<ul>
<li>Page 45 (location ~ 679-685)</li>
</ul>
<p><em>Suppose that the question at issue regards individuals: “Given two 11 year olds, one with an IQ of 110 and one with an IQ of 90, what can you tell us about the differences between those two children?” The answer must be phrased very tentatively. On many important topics, the answer must be, “We can tell you nothing with any confidence.” It is well worth a guidance counselor’s time to know what these individual scores are, but only in combination with a variety of other information about the child’s personality, talents, and background. The individual’s IQ score all by itself is a useful tool but a limited one. Suppose instead that the question at issue is: “Given two sixth-grade classes, one for which the average IQ is 110 and the other for which it is 90, what can you tell us about the difference between those two classes and their average prospects for the future?” Now there is a great deal to be said, and it can be said with considerable confidence—not about any one person in either class but about average outcomes that are important to the school, educational policy in general, and society writ large. The data accumulated under the classical tradition are extremely rich in this regard, as will become evident in subsequent chapters. If instead we were more concerned with the development of cognitive processes than with aggregate social and economic outcomes, we would correspondingly spend more time discussing the work of the revisionists. That we do not reflects our focus, not a dismissal of their work.</em></p>
<ul>
<li>Page 46 (location ~ 692-703)</li>
</ul>
<p><em>And even beyond intelligence and talents, people vary temperamentally, in personality, style, and character. But we confess to reservations about using the word intelligence to describe such factors as musical abilities, kinesthetic abilities, or personal skills. It is easy to understand how intelligence (ordinarily understood) is part of some aspects of each of those human qualities—obviously, Bach was engaging in intelligent activity, and so was Ted Williams, and so is a good used-car salesman—but the part intelligence plays in these activities is captured fairly well by intelligence as the classicists and revisionists conceive of it. In the case of music and kinesthetics, talent is a word with a domain and weight of its own, and we are unclear why we gain anything by discarding it in favor of another word, intelligence, that has had another domain and weight. In the case of intrapersonal and interpersonal skills, conventional intelligence may play some role, and, to the extent that other human qualities matter, words like sensitivity, charm, persuasiveness, insight—the list could go on and on—have accumulated over the centuries to describe them. We lose precision by using the word intelligence to cover them all.</em></p>
<ul>
<li>Page 46 (location ~ 706-714)</li>
</ul>
<p><em>One of the most insidious but also widespread errors regarding IQ, especially among people who have high IQs, is the assumption that another person’s intelligence can be inferred from casual interactions. Many people conclude that if they see someone who is sensitive, humorous, and talks fluently, the person must surely have an above-average IQ. This identification of IQ with attractive human qualities in general is unfortunate and wrong. Statistically, there is often a modest correlation with such qualities. But modest correlations are of little use in sizing up other individuals one by one. For example, a person can have a terrific sense of humor without giving you a clue about where he is within thirty points on the IQ scale. Or a plumber with a measured IQ of 100—only an average IQ—can know a great deal about the functioning of plumbing systems. He may be able to diagnose problems, discuss them articulately, make shrewd decisions about how to fix them, and, while he is working, make some pithy remarks about the president’s recent speech.</em></p>
<ul>
<li>Page 47 (location ~ 719-726)</li>
</ul>
<p><em>All of this is another way of making a point so important that we will italicize it now and repeat elsewhere: Measures of intelligence have reliable statistical relationships with important social phenomena, but they are a limited tool for deciding what to make of any given individual. Repeat it we must, for one of the problems of writing about intelligence is how to remind readers often enough how little an IQ score tells about whether the human being next to you is someone whom you will admire or cherish. This thing we know as IQ is important but not a synonym for human excellence.</em></p>
<ul>
<li>Page 48 (location ~ 733-737)</li>
</ul>
<p><em>Here are six conclusions regarding tests of cognitive ability, drawn from the classical tradition, that are by now beyond significant technical dispute: 1. There is such a thing as a general factor of cognitive ability on which human beings differ. 2. All standardized tests of academic aptitude or achievement measure this general factor to some degree, but IQ tests expressly designed for that purpose measure it most accurately. 3. IQ scores match, to a first degree, whatever it is that people mean when they use the word intelligent or smart in ordinary language. 4. IQ scores are stable, although not perfectly so, over much of a person’s life. 5. Properly administered IQ tests are not demonstrably biased against social, economic, ethnic, or racial groups. 6. Cognitive ability is substantially heritable, apparently no less than 40 percent and no more than 80 percent.</em></p>
<ul>
<li>Page 50 (location ~ 752-760)</li>
</ul>
<p><em>This does not mean that the experts should leave the room with their differences resolved. All six points can be accurate as general rules and still leave room for differences in the theoretical and practical conclusions that people of different values and perspectives draw from them (and from the mass of material about cognitive ability and testing not incorporated in the six points). Radicals in the Gardner mold might still balk at all the attention being paid to intelligence as the tests measure it. But these points, in themselves, are squarely in the middle of the scientific road. Having said this, however, we are left with a dilemma. The received wisdom in the media is roughly 180 degrees opposite from each of the six points. To prove our case, taking each point and amassing a full account of the evidence for and against, would lead us to write a book just about them. Such books have already been written. There is no point in our trying to duplicate them.</em></p>
<ul>
<li>Page 50 (location ~ 767-774)</li>
</ul>
<p><em>Human society has always had some measure of cognitive stratification. The best hunters among the Bushmen of the Kalahari tend to score above the average of their tribe on modern intelligence tests and so, doubtless, would have the chief ministers in Cheop’s Egypt.1 The Mandarins who ran China for centuries were chosen by examinations that tested for understanding of the Confucian classics and, in so doing, screened for intelligence. The priests and monks of medieval Europe, recruited and self-selected for reasons correlated with cognitive ability, must have been brighter than average. This differentiation by cognitive ability did not coalesce into cognitive classes in premodern societies for various reasons. Clerical celibacy was one. Another was that the people who rose to the top on their brains were co-opted by aristocratic systems that depleted their descendants’ talent, mainly through the mechanism known as primogeniture. Because parents could not pick the brightest of their progeny to inherit the title and land, aristocracies fell victim to regression to the mean: children of parents with above-average IQs tend to have lower IQs than their parents, and their children’s IQs are lower still. Over the course of a few generations, the average intelligence in an aristocratic family fell toward the population average, hastened by marriages that matched bride and groom by lineage, not ability.</em></p>
<ul>
<li>Page 52 (location ~ 796-806)</li>
</ul>
<p><em>Even in less rigidly stratified societies, stratification by cognitive ability has been weak and inconsistent until this century because the number of very bright people was so much greater than the specialized jobs for which high intelligence is indispensable. A true cognitive elite requires a technological society. This raises a distinction that is so important, and forgetting it can so easily lead to needless misunderstanding, that it is worth emphasizing: To say that most of the people in the cognitively demanding positions of a society have a high IQ is not the same as saying that most of the people with high IQs are in such positions. It is possible to have cognitive screening without having cognitive classes. Mathematical necessity tells us that a large majority of the smart people in Cheop’s Egypt, dynastic China, Elizabethan England, and Teddy Roosevelt’s America were engaged in ordinary pursuits, mingling, working, and living with everyone else. Many were housewives. Most of the rest were farmers, smiths, millers, bakers, carpenters, and shopkeepers. Social and economic stratification was extreme, but cognitive stratification was minor.</em></p>
<ul>
<li>Page 54 (location ~ 816-824)</li>
</ul>
<p><em>A large proportion of the class came from a handful of America’s most exclusive boarding schools; Phillips Exeter and Phillips Andover alone contributed almost 10 percent of the freshmen that year. And yet for all its apparent exclusivity, Harvard was not so hard to get into in the fall of 1952. An applicant’s chances of being admitted were about two out of three, and close to 90 percent if his father had gone to Harvard.1 With this modest level of competition, it is not surprising to learn that the Harvard student body was not uniformly brilliant. In fact, the mean SAT-Verbal score of the incoming freshmen class was only 583, well above the national mean but nothing to brag about.2 Harvard men came from a range of ability that could be duplicated in the top half of many state universities.</em></p>
<ul>
<li>Page 55 (location ~ 842-849)</li>
</ul>
<p><em>Unquestionably, suddenly, but for no obvious reason, Harvard had become a different kind of place. The proportion of the incoming students from New England had dropped by a third. Public school graduates now outnumbered private school graduates. Instead of rejecting a third of its applicants, Harvard was rejecting more than two-thirds—and the quality of those applicants had increased as well, so that many students who would have been admitted in 1952 were not even bothering to apply in 1960. The SAT scores at Harvard had skyrocketed. In the fall of 1960, the average verbal score was 678 and the average math score was 695, an increase of almost a hundred points for each test. The average Harvard freshman in 1952 would have placed in the bottom 10 percent of the incoming class by 1960.</em></p>
<ul>
<li>Page 56 (location ~ 852-858)</li>
</ul>
<p><em>The story of higher education in the United States during the twentieth century is generally taken to be one of the great American success stories, and with good reason. The record was not without blemishes, but the United States led the rest of the world in opening college to a mass population of young people of ability, regardless of race, color, creed, gender, and financial resources. But this success story also has a paradoxically shadowy side, for education is a powerful divider and classifier. Education affects income, and income divides. Education affects occupation, and occupations divide. Education affects tastes and interests, grammar and accent, all of which divide. When access to higher education is restricted by class, race, or religion, these divisions cut across cognitive levels. But school is in itself, more immediately and directly than any other institution, the place where people of high cognitive ability excel and people of low cognitive ability fail. As America opened access to higher education, it opened up as well a revolution in the way that the American population sorted itself and divided itself. Three successively more efficient sorting processes were at work: the college population grew, it was recruited by cognitive ability more efficiently, and then it was further sorted among the colleges.</em></p>
<ul>
<li>Page 57 (location ~ 860-869)</li>
</ul>
<p><em>A compilation of the studies conducted over the course of the century suggests that the crucial decade was the 1950s. The next figure shows the data for the students in the top quartile (the top 25 percent) in ability and is based on the proportion of students entering college (though not necessarily finishing) in the year following graduation from high school. Again, the lines highlight trends set in particular periods, here 1925-1950 and 1950-1960. From one period to the next, the proportion of bright students getting to college leaped to new heights. There are two qualifications regarding this figure. First, it is based on high school graduates—the only data available over this time period—and therefore drastically understates the magnitude of the real change from the 1920s to the 1960s and thereafter, because so many of the top quartile in ability never made it through high school early in the century (see Chapter 6). It is impossible to be more precise with the available data, but a reasonable estimate is that as of the mid-1920s, only about 15 percent of all of the nation’s youth in the top IQ quartile were going on to college.4 It is further the case that almost all of those moving on to college in the 1920s were going to four-year colleges, and this leads to the second qualification to keep in mind: By the 1970s and 1980s, substantial numbers of those shown as continuing to college were going to a junior college, which are on average less demanding than four-year colleges. Interpreting all the available data, it appears that the proportion of all American youth in the top IQ quartile who went directly to four-year colleges rose from roughly one youth in seven in 1925 to about two out of seven in 1950 to more than four out of seven in the early 1960s, where it has remained, with perhaps a shallow upward trend, ever since.</em></p>
<ul>
<li>Page 59 (location ~ 901-914)</li>
</ul>
<p><em>Between the 1920s and the 1960s, the largest change in the probability of going to college was at the top of the cognitive ability distribution. By 1960, a student who was really smart—at or near the 100th percentile in IQ—had a chance of going to college of nearly 100 percent.7 Furthermore, as the figure shows, going to college had gotten more dependent on intelligence at the bottom of the distribution, too.8 A student at the 30th percentile had only about a 25 percent chance of going to college—lower than it had been for high school graduates in the 1920s. But a student in the 80th percentile had a 70 percent chance of going to college, well above the proportion in the 1920s.</em></p>
<ul>
<li>Page 61 (location ~ 930-936)</li>
</ul>
<p><em>Didn’t Equal Opportunity in Higher Education Really Open Up During the 1960s? The conventional wisdom holds that the revolution in higher education occurred in the last half of the 1960s, as part of the changes of the Great Society, especially its affirmative action policies. We note here that the proportion of youths going to college rose about as steeply in the 1950s as in the 1960s, as shown in the opening figure in this chapter and the accompanying discussion. Chapter 19 considers the role played by affirmative action in the changing college population of recent decades.</em></p>
<ul>
<li>Page 62 (location ~ 941-946)</li>
</ul>
<p><em>Prior to World War II, America had a stratum of elite colleges just as it has now, with the Ivy League being the best known. Then as now, these schools attracted the most celebrated faculty, had the best libraries, and sent their graduates on to the best graduate schools and to prestigious jobs. Of these elite schools, Harvard was among the most famous and the most selective. But what was true of Harvard then was true of the other elite schools. They all had a thin layer of the very brightest among their students but also many students who were merely bright and a fair number of students who were mediocre. They tapped only a fragment of the cognitive talent in the country. The valedictorian in Kalamazoo and the Kansas farm girl with an IQ of 140 might not even be going to college at all. If they did, they probably went to the nearest state university or to a private college affiliated with their church.</em></p>
<ul>
<li>Page 63 (location ~ 963-969)</li>
</ul>
<p><em>The IQ equivalent of the average of all Pennsylvania colleges was 107, which put the average Pennsylvania student at the 68th percentile, considerably below the average of the elite schools. But ten Pennsylvania colleges had freshman classes with mean IQs that put them at the 75th to 90 percentiles.13 In other words, students going to any of several Pennsylvania colleges were, on average, virtually indistinguishable in cognitive ability from the students in the Ivy League and the Seven Sisters. Now let us jump to 1964, the first year for which SAT data for a large number of Pennsylvania colleges are available. We repeat the exercise, this time using the SAT-Verbal test as the basis for analysis.14 Two important changes had occurred since 1928. The average freshman in a Pennsylvania college in 1964 was much smarter than the average Pennsylvania freshman in 1928—at about the 89th percentile. At the same time, however, the elite colleges, using the same fourteen schools represented in the 1928 data, had moved much further out toward the edge, now boasting an average freshman who was at the 99th percentile of the nation’s youth.</em></p>
<ul>
<li>Page 65 (location ~ 983-992)</li>
</ul>
<p><em>If the word democracy springs to your tongue, note that democracy—at least in the economic sense—had little to do with it. The Harvard freshman class of 1960 comprised fewer children from low-income families, not more, than the freshman class in 1952.17 And no wonder. Harvard in 1950 had been cheap by today’s standards. In 1950, total costs for a year at Harvard were only $8,800—in 1990 dollars, parents of today’s college students will be saddened to learn. By 1960, total costs there had risen to $12,200 in 1990 dollars, a hefty 40 percent increase. According to the guidelines of the times, the average family could, if it stretched, afford to spend 20 percent of its income to send a child to Harvard.18 Seen in that light, the proportion of families who could afford Harvard decreased slightly during the 1950s.19 Scholarship help increased but not fast enough to keep pace.</em></p>
<ul>
<li>Page 66 (location ~ 1007-1015)</li>
</ul>
<p><em>though the proportion of families with incomes sufficient to pay for a Harvard education did not increase significantly during the 1950s, the raw number did. Using the 20-percent-of-family-income rule, the number of families that could afford Harvard increased by 184,000 from 1950 to 1960. Using a 10 percent rule, the number increased by 55,000. Only a small portion of these new families had children applying to college, but the number of slots in the freshmen classes of the elite schools was also small. College enrollment increased from 2.1 million students in 1952 to 2.6 million by 1960, meaning a half-million more competitors for available places. It would not take much of an increase in the propensity to seek elite educations to produce a substantial increase in the annual applications to Harvard, Yale, and the others.</em></p>
<ul>
<li>Page 68 (location ~ 1037-1042)</li>
</ul>
<p><em>Philip Cook and Robert Frank have drawn together a wide variety of data documenting the increasing concentration.25 There are, for example, the Westinghouse Science Talent Search finalists. In the 1960s, 47 percent went to the top seven colleges (as ranked in the Barron’s list that Cook and Frank used). In the 1980s, that proportion had risen to 59 percent, with 39 percent going to just three colleges (Harvard, MIT, and Princeton).26 Cook and Frank also found that from 1979 to 1989, the percentage of students scoring over 700 on the SAT-Verbal who chose one of the “most competitive colleges” increased from 32 to 43 percent.27 The degree of partitioning off of the top students as of the early 1990s has reached startling proportions. Consider the list of schools that were named as the nation’s top twenty-five large universities and the top twenty-five small colleges in a well-known 1990 ranking.28 Together, these fifty schools accounted for just 59,000 out of approximately 1.2 million students who entered four-year institutions in the fall of 1990—fewer than one out of twenty of the nation’s freshmen in four-year colleges. But they took in twelve out of twenty of the students who scored in the 700s on their SAT-Verbal test. They took in seven out of twenty of students who scored in the 600s.</em></p>
<ul>
<li>Page 69 (location ~ 1050-1062)</li>
</ul>
<p><em>Now we are talking about schools that enrolled a total of only 18,000 freshmen, one out of every sixty-seven nationwide. Just these ten schools—Harvard, Yale, Stanford, University of Pennsylvania, Princeton, Brown, University of California at Berkeley, Cornell, Dartmouth, and Columbia—soaked up 31 percent of the nation’s students who scored in the 700s on the SAT-Verbal. Harvard and Yale alone, enrolling just 2,900 freshmen—roughly 1 out of every 400 freshmen—accounted for 10 percent. In other words, scoring above 700 is forty times more concentrated in the freshman classes at Yale and Harvard than in the national SAT population at large—and the national SAT population is already a slice off the top of the distribution.</em></p>
<ul>
<li>Page 70 (location ~ 1064-1069)</li>
</ul>
<p><em>The college population has grown a lot while its mean IQ has risen a bit. Most bright people were not going to college in 1930 (or earlier)—waiting on the bench, so to speak, until the game opened up to them. By 1990, the noncollege population, drained of many bright youngsters, had shifted downward in IQ. While the college population grew, the gap between college and noncollege populations therefore also grew. The largest change, however, has been the huge increase in the intelligence of the average student in the top dozen universities, up a standard deviation and a half from where the Ivies and the Seven Sisters were in 1930. One may see other features in the figure evidently less supportive of cognitive partitioning. Our picture suggests that for every person within the ranks of college graduates, there is another among those without a college degree who has just as high an IQ—or at least almost. And as for the graduates of the dozen top schools,33 while it is true that their mean IQ is extremely high (designated by the +2.7 SDs to which the line points), they are such a small proportion of the nation’s population that they do not even register visually on this graph, and they too are apparently outnumbered by people with similar IQs who do not graduate from those colleges, or do not graduate from college at all. Is there anything to be concerned about? How much partitioning has really occurred?</em></p>
<ul>
<li>Page 73 (location ~ 1106-1116)</li>
</ul>
<p><em>The sword cuts both ways. Although they are not likely to be among our readers, the circles at the bottom of the educational scale comprise lower and narrower ranges of IQ today than they did in 1930. When many youngsters in the top 25 percent of the intelligence distribution who formerly would have stopped school in or immediately after high school go to college instead, the proportion of high-school-only persons whose intelligence is in the top 25 percent of the distribution has to fall correspondingly. The occupational effect of this change is that bright youngsters who formerly would have become carpenters or truck drivers or postal clerks go to college instead, thence to occupations higher on the socioeconomic ladder. Those left on the lower rungs are therefore likely to be lower and more homogeneous intellectually. Likewise their neighborhoods, which get drained of the bright and no longer poor, have become more homogeneously populated by a less bright, and even poorer, residuum. In other chapters we focus on what is happening at the bottom of the distribution of intelligence.</em></p>
<ul>
<li>Page 75 (location ~ 1139-1147)</li>
</ul>
<p><em>For the nationally representative NLSY sample, most of whom attended college in the late 1970s and through the 1980s, the median overlap is as follows: By this measure, there is only about 7 percent overlap between people with only a high school diploma and people with a B.A. or M.A. And even this small degree of overlap refers to all colleges. If you went to any of the top hundred colleges and universities in the country, the measure of overlap would be a few percentage points. If you went to an elite school, the overlap would approach zero. Overlap Across the Educational Partitions Groups Being Compared Median Overlap High school graduates with college graduates 7% High school graduates with Ph.D.s, M.D.s, or LL.B.s 1% College graduates with Ph.D.s, M.D.s, and LL.Bs 21% Even among college graduates, the partitions are high. Only 21 percent of those with just a B.A. or a B.S. had scores as high as the median for those with advanced graduate degrees. Once again, these degrees of overlap are for graduates of all colleges. The overlap between the B.A. from a state teachers’ college and an MIT Ph.D. can be no more than a few percentage points.</em></p>
<ul>
<li>Page 76 (location ~ 1154-1168)</li>
</ul>
<p><em>The national percentage of 18-year-olds with the ability to get a score of 700 or above on the SAT-Verbal test is in the vicinity of one in three hundred. Think about the consequences when about half of these students are going to universities in which 17 percent of their classmates also had SAT-Vs in the 700s and another 48 percent had scores in the 600s.35 It is difficult to exaggerate how different the elite college population is from the population at large—first in its level of intellectual talent, and correlatively in its outlook on society, politics, ethics, religion, and all the other domains in which intellectuals, especially intellectuals concentrated into communities, tend to develop their own conventional wisdoms.</em></p>
<ul>
<li>Page 77 (location ~ 1173-1178)</li>
</ul>
<p><em>Four out of five of these adopted people had been placed with their adopting families in their first year of life; the average age of placement overall was 3 months. To all intents and purposes, then, the adoptees shared little common environment with their biological siblings, but they shared a home environment with their adoptive siblings. In adulthood, they were compared with both their biological siblings and their adoptive siblings, the idea being to see whether common genes or common home life determined where they landed on the occupational ladder. The biologically related siblings resembled each other in job status, even though they grew up in different homes. And among them, the full siblings had more similar job status than the half siblings. Meanwhile, adoptive siblings were not significantly correlated with each other in job status.</em></p>
<ul>
<li>Page 82 (location ~ 1246-1252)</li>
</ul>
<p><em>Now consider Americans in the top 10 percent (the top decile, in other words) in cognitive ability—everyone over the age of 25, including housewives, the retired, and others who are not counted as being part of the labor force. These people are represented by the middle line in the graph. In 1900, the number of jobs in the high-IQ professions soaked up only about one out of twenty of these talented people. By 1990, they soaked up almost five times as many, or one out of four. Finally, consider the top line in the graph, which is limited to Americans who are in both the top decile of IQ and the labor force. In 1900, about one out of eleven was in one of the high-IQ professions; by 1990, more than one out of three. This still leaves almost two out of three of them unaccounted for, but we will get to them in the next section of the chapter.</em></p>
<ul>
<li>Page 84 (location ~ 1276-1282)</li>
</ul>
<p><em>We have little to tell us exactly what is happening now, but we know what the situation was fifty years ago, through Lewis Terman’s famous study of 1,500 highly gifted children who were born in the early 1900s and followed throughout their lives. Their average IQs were over three standard deviations above the mean, meaning that the Terman sample represented about l/300th of the population. As of 1940, the members of the Terman sample who had finished their schooling were engaged in high-IQ professions at three times the rate of people in the top 10 percent—24 percent for the Terman sample against 8 percent for the top decile in 1940, as the preceding figure shows.16 If that was the case in 1940, when fewer than one in twelve people in the top decile were working in high-IQ professions, what might be the proportion for a comparable sample today? Presumably much higher, though how much higher is impossible to estimate with the available data.</em></p>
<ul>
<li>Page 85 (location ~ 1296-1303)</li>
</ul>
<p><em>The changes in our twelve high-IQ professions understate how much occupational cognitive segregation there has been in this century. We lack data about other professions and occupations in which mean IQ may be comparably high (e.g., military officers, writers, journalists). But the biggest omission involves business executives. For while the mean IQ of all people who go into business cannot be near 120,18 both common sense and circumstantial evidence suggest that people who rise to the upper echelons of large businesses tend to have high IQs and that this tendency has increased during the course of the century.</em></p>
<ul>
<li>Page 86 (location ~ 1305-1310)</li>
</ul>
<p><em>A Wall Street tycoon (himself a Harvard alumnus) writing in 1908 advised parents that “practical business is the best school and college” for their sons who sought a business career and that, indeed, a college education “is in many instances not only a hindrance, but absolutely fatal to success.”</em></p>
<ul>
<li>Page 86 (location ~ 1314-1316)</li>
</ul>
<p><em>The proportion of CEOs who came from wealthy families had dropped from almost half in 1900 and a third in 1950 to 5.5 percent by 1976.23 The CEO of 1976 was still disproportionately likely to be Episcopalian but much less so than in 1900—and by 1976 he was also disproportionately likely to be Jewish, unheard of in 1920 or earlier. In short, social and economic background was no longer nearly as important in 1976 as in the first half of the century. Educational level was becoming the high road to the executive suite at the same time that education was becoming more dependent on cognitive ability, as Chapter 1 showed. The figure above traces the change in highest educational attainment from 1900 to 1976 for CEOs of the largest U.S. companies.</em></p>
<ul>
<li>Page 87 (location ~ 1329-1334)</li>
</ul>
<p><em>The decline of the high school-educated chief executive was fairly steady throughout the period. College-educated CEOs surged into the executive suite in the 1925-1950 period. But as in the case of educational stratification, the most dramatic shift occurred after 1950, represented by the skyrocketing proportion of chief executives who had attended graduate school.24 By 1976, 40 percent of the Fortune 500 companies were headed by individuals whose background was in finance or law, fields of study that are highly screened for intelligence. So we are left with this conservative interpretation: Nobody knows what the IQ mean or distribution was for executives at the turn of the century, but it is clear that, as of the 1990s, the cognitive screens were up. How far up? The broad envelope of possibilities suggests that senior business executives soak up a large proportion of the top IQ decile who are not engaged in the dozen high-IQ professions. The constraints leave no other possibility.</em></p>
<ul>
<li>Page 88 (location ~ 1338-1345)</li>
</ul>
<p><em>professions: Lawyers with higher IQs are, on the average, more productive than lawyers with lower IQs. It holds true for skilled blue-collar jobs: Carpenters with high IQs are also (on average) more productive than carpenters with lower IQs. The relationship holds, although weakly, even among people in unskilled manual jobs. The magnitude of the relationship between cognitive ability and job performance is greater than once thought. A flood of new analyses during the 1980s established several points with large economic and policy implications: Test scores predict job performance because they measure g, Spearman’s general intelligence factor, not because they identify “aptitude” for a specific</em></p>
<ul>
<li>Page 90 (location ~ 1379-1384)</li>
</ul>
<p><em>Most sweepingly important, an employer that is free to pick among applicants can realize large economic gains from hiring those with the highest IQs. An economy that lets employers pick applicants with the highest IQs is a significantly more efficient economy. Herein lies the policy problem: Since 1971, Congress and the Supreme Court have effectively forbidden American employers from hiring based on intelligence tests. How much does this policy cost the economy? Calculating the answer is complex, so estimates vary widely, from what one authority thinks was a lower-bound estimate of $80 billion in 1980 to what another authority called an upper-bound estimate of $13 billion for that year. Our main point has nothing to do with deciding how large the loss is or how large the gain would be if intelligence tests could be freely used for hiring. Rather, it is simply that intelligence itself is importantly related to job performance. Laws can make the economy less efficient by forbidding employers to use intelligence tests, but laws cannot make intelligence unimportant.</em></p>
<ul>
<li>Page 91 (location ~ 1388-1396)</li>
</ul>
<p><em>The third possibility is that cognitive ability itself—sheer intellectual horsepower, independent of education—has market value. Seen from this perspective, the college degree is not a credential but an indirect measure of intelligence. People with college degrees tend to be smarter than people without them and, by extension, more valuable in the marketplace. Employers recruit at Stanford or Yale not because graduates of those schools know more than graduates of less prestigious schools but for the same generic reason that Willie Sutton gave for robbing banks. Places like Stanford and Yale are where you find the coin of cognitive talent.</em></p>
<ul>
<li>Page 92 (location ~ 1407-1412)</li>
</ul>
<p><em>The most comprehensive modern surveys of the use of tests for hiring, promotion, and licensing, in civilian, military, private, and government occupations, repeatedly point to three conclusions about worker performance, as follows. 1. Job training and job performance in many common occupations are well predicted by any broadly based test of intelligence, as compared to narrower tests more specifically targeted to the routines of the job. As a corollary: Narrower tests that predict well do so largely because they happen themselves to be correlated with tests of general cognitive ability. 2. Mental tests predict job performance largely via their loading on g. 3. The correlations between tested intelligence and job performance or training are higher than had been estimated prior to the 1980s. They are high enough to have economic consequences.</em></p>
<ul>
<li>Page 99 (location ~ 1504-1511)</li>
</ul>
<p><em>Job performance may be measured in many different ways.15 Sometimes it is expressed as a natural quantitative measure (how many units a person produces per hour, for example), sometimes as structured ratings by supervisors or peers, sometimes as analyses of a work sample. When these measures of job productivity are correlated with measures of intelligence, the overall correlation, averaged over many tests and many jobs, is about .4. In the study of job performance and tests, the correlation between a test and job performance is usually referred to as the validity of the test, and we shall so refer to it for the rest of the discussion.16 Mathematically, validity and the correlation coefficient are identical. Later in the chapter we will show that a validity of .4 has large economic implications, and even validities half as large may warrant worrying about.</em></p>
<ul>
<li>Page 101 (location ~ 1535-1541)</li>
</ul>
<p><em>The lowest modern estimate of validity for cognitive ability is the one contained in the report by a panel convened by the National Academy of Sciences, Fairness in Employment Testing.21 That report concluded that the mean validity is only about .25 for the GATB, in contrast to the Hunter estimate of .45 (which we cited earlier). Part of the reason was that the Hartigan committee (we name it for its chairman, Yale statistician John Hartigan), analyzing 264 studies after 1972, concluded that validities had generally dropped in the more recent studies. But the main source of the difference in validities is that the committee declined to make any correction whatsoever for restriction of range (see above and note 6). It was, in effect, looking at just the tackles already in the NFL; Hunter was considering the population at large. The Hartigan committee’s overriding concern, as the title of their report (Fairness in Employment Testing) indicates, was that tests not be used to exclude people, especially blacks, who might turn out to be satisfactory workers. Given that priority, the committee’s decision not to correct for restriction of range makes sense. But failing to correct for restriction of range produces a misleadingly low estimate of the overall relationship of IQ to job performance and its economic consequences.22 Had the Hartigan committee corrected for restriction of range; the estimates of the relationship would have been .35 to .40, not much less than Hunter’s.</em></p>
<ul>
<li>Page 103 (location ~ 1575-1586)</li>
</ul>
<p><em>In assigning recruits to training schools, the services use particular combinations of subtests from a test battery that all recruits take, the Armed Services Vocational Aptitude Battery (ASVAB).23 The Pentagon’s psychometricians have tried to determine whether there is any practical benefit of using different weightings of the subtests for different jobs rather than, say, just using the overall score for all jobs. The overall score is itself tantamount to an intelligence test. One of the most comprehensive studies of the predictive power of intelligence tests was by Malcolm Ree and James Earles, who had both the intelligence test scores and the final grades from military school for over 78,000 air force enlisted personnel spread over eighty-nine military specialties. The personnel were educationally homogeneous (overwhelmingly high school graduates without college degrees), conveniently “controlling” for educational background.24 What explains how well they performed? For every one of the eighty-nine military schools, the answer was g—Charles Spearman’s general intelligence. The correlations between g alone and military school grade ranged from an almost unbelievably high .90 for the course for a technical job in avionics repair down to .41 for that for a low-skill job associated with jet engine maintenance.25 Most of the correlations were above .7. Overall, g accounted for almost 60 percent of the observed variation in school grades in the average military course, once the results were corrected for range restriction (the accompanying note spells out what it means to “account for 60 percent of the observed variation”).</em></p>
<ul>
<li>Page 105 (location ~ 1600-1613)</li>
</ul>
<p><em>Did cognitive factors other than g matter at all? The answer is that the explanatory power of g was almost thirty times greater than of all other cognitive factors in ASVAB combined. The table below gives a sampling of the results from the eighty-nine specialties, to illustrate the two commanding findings: g alone explains an extraordinary proportion of training success; “everything else” in the test battery explained very little.</em></p>
<ul>
<li>Page 106 (location ~ 1614-1617)</li>
</ul>
<p><em>In one of the few major studies involving civilian jobs, performance in twenty-eight occupations correlated virtually as well with an estimate of g from GATB scores as it did with the most predictively weighted individual subtest scores in the battery.29 The author concluded that, for samples in the range of 100 to 200, a single factor, g, predicts job performance as well as, or better than, batteries of weighted subtest scores. With larger samples, for which it is possible to pick up the effect of less potent influences, there may be some modest extra benefit of specialized weighted scores. At no level of sampling, however, does g become anything less than the best single predictor known, across the occupational spectrum. Perhaps the most surprising finding has been that tests of general intelligence often do better in predicting future job performance than do contrived tests of job performance itself. Attempts to devise measures that are specifically keyed to a job’s tasks—for example, tests of filing, typing, answering the telephone, searching in records, and the like for an office worker—often yield low-validity tests, unless they happen to measure g, such as a vocabulary test. Given how pervasive g is, it is almost impossible to miss it entirely with any test, but some tests are far more efficient measures of it than others.</em></p>
<ul>
<li>Page 108 (location ~ 1647-1657)</li>
</ul>
<p><em>Now imagine devising a test that would enable an employer to choose the best busboy among applicants. One important aspect of the test would measure diligence and good spirits. Perhaps the employer should weigh the results of this part of the test more heavily than anything else, if his choice is between a diligent and cheerful applicant and a slightly smarter but sulky one. But when it comes to measuring performance in general for most applicants, it is easy to see why the results will match the findings of the literature we just discussed. Job-specific items reveal mostly whether an applicant has ever been a busboy before. But that makes very little difference to job productivity, because a bright person can pick up the basic routine in the course of a few shifts. The g-loaded items, on the other hand, will reveal whether the applicant will ever become the kind of busboy who will clear table 12 before he clears table 20 because he relates the needed task to something that happened twenty minutes earlier regarding table 15. And that is why employers who want to select productive busboys should give applicants a test of general intelligence rather than a test of busboy skills. The kind of test that would pass muster with the courts—a test of job-specific skills—is a less effective kind of test to administer. What applies to busboys applies ever more powerfully as the jobs become more complex.</em></p>
<ul>
<li>Page 109 (location ~ 1670-1680)</li>
</ul>
<p><em>The busboy example leads to another question that bears on how we should think about cognitive ability and job productivity: How much can experience counterbalance ability? Yes, the smart busboy will be more productive than the less-smart busboy a week into the job, and, yes, perhaps there will always be a few things that the smart busboy can do that the less smart cannot. But will the initial gap in productivity narrow as the less-smart busboy gains experience? How much, and how quickly? Separately, job performance relates to both experience and intelligence, but the relationships differ.31 That is, people who are new to a job learn quickly at first, then more slowly. A busboy who has, say, one month on the job may for that reason outperform someone who started today, but the one-month difference in experience will have ceased to matter in six months. No comparable leveling-off effect has been observed for increasing intelligence. Wherever on the scale of intelligence pairs of applicants are, the smarter ones not only will outperform the others, on the average, but the benefit of having a score that is higher by a given amount is approximately the same throughout the range. Or, to put it more conservatively, no one has produced good evidence of diminishing returns to intelligence.</em></p>
<ul>
<li>Page 110 (location ~ 1681-1690)</li>
</ul>
<p><em>Some convergence has been found when SATs are used as the measure of ability and grade point average is used as the measure of achievement.33 Students with differing SATs sometimes differ more in their freshman grades than in later years. That is why President Bok granted predictive value to the SAT only for first-year grades.34 On the other hand, the shrinking predictive power may be because students learn which courses they are likely to do well in: They drop out of physics or third-year calculus, for example, and switch to easier courses. They find out which professors are stingy with A’s and B’s. At the U.S. Military Academy, where students have very little choice in courses, there is no convergence in grades.</em></p>
<ul>
<li>Page 111 (location ~ 1694-1700)</li>
</ul>
<p><em>The data used for this analysis were top heavy with higher-complexity jobs, yielding a higher-than-usual validity of .53 for test scores. However, even if we were to substitute the more conservative validity estimate of .4, the test score would remain the best predictor, though with close competition from biographical data.41 The method that many people intuitively expect to be the most accurate, the job interview, has a poor record as a predictor of job performance, with a validity of only .14.</em></p>
<ul>
<li>Page 113 (location ~ 1732-1736)</li>
</ul>
<p><em>Put more technically and precisely, one standard deviation of the distribution of workers’ annual productivities in a typical occupation is worth 40 percent of the average worker’s annual income.43 New work suggests the premium may actually be twice as large. Since the larger estimate has yet to be confirmed, we will base our calculations on the more conservative estimate.44 To take a specific example, for a $20,000-a-year job, which is correctly priced for an average worker, the incremental value of hiring a new worker who is one standard deviation above the mean—at the 84th percentile—is $8,000 per year.45 Hiring a worker for a $20,000-a-year job who is one standard deviation below the mean—at the 16th percentile—would cost the employer $8,000 in lost output.</em></p>
<ul>
<li>Page 115 (location ~ 1753-1760)</li>
</ul>
<p><em>We may make this concrete with some hypothetical calculations. Imagine a dental office, consisting of dentist and receptionist. Assume that the annual salary of an average dentist is $100,000 and that of the receptionist $25,000, and that these are correctly priced. For whatever reasons, society finds the dentist to be worth four times as much as the receptionist.47 Suppose further that you are an employer—a Health Maintenance Organization (HMO), for example—who hires both dentists and receptionists. By using a certain selection procedure, you can improve the quality of your new hirees, so that instead of hiring people who are, on average, at the 50th percentile of proficiency (which is what would happen if you picked randomly from the entire pool of receptionists and dentists looking for jobs), you instead could hire people who are, on average, at the 84th percentile. What is this screening procedure worth to you? For the value of the output produced, we use a standard deviation of .5 of the annual income for dentists and of .15 for that of receptionists, based on values actually observed.48</em></p>
<ul>
<li>Page 116 (location ~ 1767-1775)</li>
</ul>
<p><em>We are not home yet, for although we know what it is worth to hire these more proficient dentists and receptionists, we have not yet factored in the validity of the selection test. The correlation between test score and proficiency is roughly .6 for dentists and .2 for receptionists, again based on observation and approximating the top and bottom of the range illustrated in the figure below. Given that information, we may estimate the expected output difference between two dentists who score at the 50th and 84th percentiles on an intelligence test as being worth $30,000 a year.50 The corresponding difference between two receptionists who score at the 50th and 84th percentiles in intelligence is $750 a year. And this is what we meant by an “interaction effect”: the wage of the dentist is only four times that of the receptionist. But the value to the employer of hiring brighter dentists is forty times greater than the value of hiring comparably brighter receptionists.</em></p>
<ul>
<li>Page 116 (location ~ 1778-1786)</li>
</ul>
<p><em>Since the pivotal Supreme Court decision of Griggs v. Duke Power Co. in 1971, no large American employer has been able to hire from the top down based on intelligence tests. Estimates vary widely for how much the American economy loses by not doing so, from what Hunter and Hunter conclude is a minimum loss of $80 billion in 1980 (and in 1980 dollars) to what the Hartigan committee thought was a maximum loss of $13 billion for that year.56 The wide range reflects the many imponderables in making these calculations. For one thing, many attributes of an applicant other than a test score are correlated with intelligence—educational level, for example. Schooling captures some, but not all, of the predictive value of intelligence. Or consider an employer using family connections to hire instead of tests. A bright worker is likely to have a bright sister or brother. But the average IQ score difference between siblings is eleven or twelve points, so, again, test scores would predict proficiency better than judging an applicant by the work of a brother or sister.</em></p>
<ul>
<li>Page 118 (location ~ 1800-1808)</li>
</ul>
<p><em>To recapitulate a complex discussion: Proficiency in most common civilian and military occupations can be predicted by IQ, with an over-all validity that may conservatively be placed at .4. The more demanding a job is cognitively, the more predictive power such a test has, but no common job is so undemanding that the test totally lacks predictiveness. For the job market as a whole, cognitive ability predicts proficiency better than any other known variable describing an individual, including educational level. Intelligence tests are usually more predictive of proficiency than are paper-and-pencil tests that are specifically based on a job’s activities. For selecting large numbers of workers, there may be some added predictive power, usually small, when a score on a narrower test of performance is combined with an intelligence test. For low-complexity jobs, a test of motor skill often adds materially to predictiveness. The predictive power of IQ derives from its loading on g, in Spearman’s sense of general intelligence.</em></p>
<ul>
<li>Page 120 (location ~ 1828-1835)</li>
</ul>
<p><em>A case study of what happens when a public service is able to hire from the top down on a test of cognitive ability, drawing on a large applicant pool, comes out of New York City. In April 1939, after a decade of economic depression, New York City attracted almost 30,000 men to a written and physical examination for 300 openings in the city’s police force, a selection ratio of approximately one in a hundred.57 The written test was similar to the intelligence test then being given by the federal civil service. Positions were offered top down for a composite score on the mental and physical tests, with the mental test more heavily weighted by more than two to one. Not everyone accepted the offer, but, times being what they were, the 300 slots were filled by men who earned the top 350 scores. Inasmuch as the performance of police officers has been shown to correlate significantly with scores on intelligence tests,58 this group of men should have made outstanding policemen. And they did, achieving extraordinarily successful careers in and out of policing. They attained far higher than average rank as police officers. Of the entire group, four have been police chiefs, four deputy commissioners, two chiefs of personnel, one a chief inspector, and one became commissioner of the New York Police Department. They suffered far fewer disciplinary penalties, and they contributed significantly to the study and teaching of policing and law enforcement. Many also had successful careers as lawyers, businessmen, and academics after leaving the police department.</em></p>
<ul>
<li>Page 120 (location ~ 1836-1848)</li>
</ul>
<p><em>Such a calculation would be based on four variables: the predictive power of the test for the job at hand, the variation in worker productivity for the job at hand, the proportion of job applicants that are to be selected, and the cost of testing. The conclusion would often be that testing is profitable. Even a marginally predictive test can be economically important if only a small fraction of applicants is to be selected. Even a marginally predictive test may have a telling economic impact if the variation in productivity is wide. And for most occupations, the test is more than marginally predictive. In the average case, a test with a .4 validity, the employer who uses a cognitive test captures 40 percent of the profit that would be realized from a perfectly predictive test—no small advantage. In an era when a reliable intelligence test can be administered in twelve minutes, the costs of testing can be low—lower in terms of labor than, for example, conducting an interview or checking references.</em></p>
<ul>
<li>Page 121 (location ~ 1850-1857)</li>
</ul>
<p><em>The main point is rather that intelligence itself is importantly related to job performance. Getting rid of intelligence tests in hiring—as policy is trying to do—will not get rid of the importance of intelligence. The alternatives that employers have available to them—biographical data, reference checks, educational record, and so forth—are valid predictors of job performance in part because they imperfectly reflect something about the applicant’s intelligence.</em></p>
<ul>
<li>Page 122 (location ~ 1858-1862)</li>
</ul>
<p><em>Another force for cognitive partitioning is the increasing physical segregation of the cognitive elite from the rest of society. Members of the cognitive elite work in jobs that usually keep them off the shop floor, away from the construction site, and close to others who also tend to be smart. Computers and electronic communication make it increasingly likely that people who work mainly with their minds collaborate only with other such people. The isolation of the cognitive elite is compounded by its choices of where to live, shop, play, worship, and send its children to school. Its isolation is intensified by an irony of a mobile and democratic society like America’s. Cognitive ability is a function of both genes and environment, with implications for egalitarian social policies. The more we succeed in giving every youngster a chance to develop his or her latent cognitive ability, the more we equalize the environmental sources of differences in intelligence. The irony is that as America equalizes the circumstances of people’s lives, the remaining differences in intelligence are increasingly determined by differences in genes. Meanwhile, high cognitive ability means, more than ever before, that the chances of success in life are good and getting better all the time. Putting it all together, success and failure in the American economy, and all that goes with it, are increasingly a matter of the genes that people inherit. Add to this the phenomenon known as assortative mating. Likes attract when it comes to marriage, and intelligence is one of the most important of those likes. When this propensity to mate by IQ is combined with increasingly efficient educational and occupational stratification, assortative mating by IQ has more powerful effects on the next generation than it had on the previous one. This process too seems to be getting stronger, part of the brew creating an American class system.</em></p>
<ul>
<li>Page 123 (location ~ 1874-1887)</li>
</ul>
<p><em>The table below gives the percentage change in real wages for fulltime male workers5 at three educational levels during the 1980s, broken out by whether they are new workers (one to five or twenty-six to thirty-five years of work experience). The dramatic changes occurred among young men just coming into the labor market. High school graduates and dropouts saw their real wages plunge, while young men with college educations enjoyed a healthy increase.6 Meanwhile, experienced older men saw little real change in income whatever their level of education. Why the difference between the age groups? Interpretively, wages for men with many years of experience reflect their work history as well as their immediate economic value. Wages for people just entering the labor force are more purely an expression of prevailing market forces. The job market reevaluated schooling during the past two decades: Educated workers, having been devalued in the 1970s, became increasingly valuable in the 1980s, in comparison with less educated workers.7 Education, Experience, and Wages, 1979-1987   Percentage Change in Wages New workers (1-5 years of experience)   Less than 12 years of school -15.8 High school degree -19.8 16 or more years of school +10.8 Old workers (26-35 years of experience)   Less than 12 years of school -1.9 High school degree -2.8 16 or more years of school +1.8 Source: Adapted from Katz and Murphy, 1990, Table 1.</em></p>
<ul>
<li>Page 127 (location ~ 1936-1959)</li>
</ul>
<p><em>Why have the economic returns to education lately risen, thereby widening the income gap between the educated and the uneducated? Perhaps, say some commentators, the wage inequality problem is technological, as machines displace people from low-skill jobs. Perhaps schools are failing to teach people skills that they used to teach, or maybe the schools are doing as well as ever but the blue-collar jobs that require only low-level skills are emigrating to countries where labor is cheaper, thereby creating an oversupply of less educated workers in America. Perhaps the welfare system is eroding the need to work among the low-skill population, or the weakening labor unions are not protecting their economic interests, or a declining real minimum wage is letting the wage structure sag at the low end. These possibilities all bear on a crucial issue: How much good would it do to improve education for the people earning low wages? If somehow the government can cajole or entice youths to stay in school for a few extra years, will their economic disadvantage in the new labor market go away? We doubt it. Their disadvantage might be diminished, but only modestly. There is reason to think that the job market has been rewarding not just education but intelligence.</em></p>
<ul>
<li>Page 128 (location ~ 1960-1969)</li>
</ul>
<p><em>As a first cut at the problem, the changing wages have something to do with the shifting occupational structure of our economy. High-status, and therefore relatively high-paying, jobs are tipped toward people with high intelligence, as Chapter 2 showed. As the high-end jobs have become more numerous, demand must rise for the intellectual abilities that they require. When demand rises for any good, including intelligence, the price (in this case, the wages) goes up. Purely on economic grounds, then, wage inequality grew as the economic demand for intelligence climbed. We further know from the data discussed in Chapter 3 that cognitive ability affects how well workers at all levels do their jobs. If smarter workers are, on average, better workers, there is reason to believe that income within job categories may be correlated with intelligence. Still further, we know that the correlation between intelligence and income is not much diminished by partialing out the contributions of education, work experience, marital status, and other demographic variables.15 Such a finding strengthens the idea that the job market is increasingly rewarding not just education but intelligence.</em></p>
<ul>
<li>Page 130 (location ~ 1990-1999)</li>
</ul>
<p><em>Perhaps most obviously is that technology has increased the economic value of intelligence. As robots replace factory workers, the factory workers’ jobs vanish, but new jobs pop up for people who can design, program, and repair robots. The new jobs are not necessarily going to be filled by the same people, for they require more intelligence than the old ones did. Today’s technological frontier is more complex than yesterday’s. Even in traditional industries like retailing, banking, mining, manufacturing, and farming, management gets ever more complex. The capacity to understand and manipulate complexity, as earlier chapters showed, is approximated by g, or general intelligence. We would have predicted that a market economy, faced with this turn of events, would soon put intelligence on the sales block. It has. Business consultancy is a new profession that is soaking up a growing fraction of the graduates of the elite business schools. The consultants sell mainly their trained intelligence to the businesses paying their huge fees.</em></p>
<ul>
<li>Page 132 (location ~ 2012-2019)</li>
</ul>
<p><em>A second reason involves the effects of scale, spurred by the growth in the size of corporations and markets since World War II. A person who can dream up a sales campaign worth another percentage point or two of market share will be sought after. What “sought after” means in dollars and cents depends on what a point of market share is worth. If it is worth $500,000, the market for his services will produce one range of salaries. If a point of market share is worth $5 million, he is much more valuable. If a point of market share is worth $100 million, he is worth a fortune. Now consider that since just 1960, the average annual sales, per corporation, of America’s five hundred largest industrial corporations has jumped from $1.8 billion to $4.6 billion (both figures in 1990 dollars). The same gigantism has affected the value of everything from the ability to float successful bond offerings to the ability to negotiate the best prices for volume purchases by huge retail chains. The magnitude of the economic consequences of ordinary business transactions has mushroomed, and with it the value of people who can do their work at a marginally higher level of skill. All the evidence we have suggests that such people have, among their other characteristics, high intelligence. There is no reason to think that this process will stop soon.</em></p>
<ul>
<li>Page 132 (location ~ 2019-2028)</li>
</ul>
<p><em>America has taken great pride in the mobility of generations: enterprising children of poor families are supposed to do better than their parents, and the wastrel children of the rich are supposed to fritter away the family fortune. But in modern America, this mobility has its limits. The experts now believe that the correlation between fathers’ and sons’ income is at least .4 and perhaps closer to .5.21 Think of it this way: The son of a father whose earnings are in the bottom 5 percent of the distribution has something like one chance in twenty (or less) of rising to the top fifth of the income distribution and almost a fifty-fifty chance of staying in the bottom fifth. He has less than one chance in four of rising above even the median income.22 Economists search for explanations of this phenomenon in structural features of the economy. We add the element of intellectual stratification. Most people at present are stuck near where their parents were on the income distribution in part because IQ, which has become a major predictor of income, passes on sufficiently from one generation to the next to constrain economic mobility.</em></p>
<ul>
<li>Page 134 (location ~ 2052-2061)</li>
</ul>
<p><em>Cognitive segregation is also being intensified by failures of government in large cities. As urban school systems deteriorate, people with money relocate to rich suburbs because that is where the good public school systems are; if they remain in the city, they send their children to private schools, which are even more homogeneous. As crime rates rise, people with money relocate to suburbs where the crime rates are low, or they concentrate ever more densely within the safer parts of the city. As urban tax rates rise, the middle class flees, leaving behind even more starkly segregated poles of rich and poor. Bright working-class youngsters mix with children of every other level of ability in elementary school, but they are increasingly likely to be drawn away to the more intellectually homogeneous high school courses, thence to college. Much of the cognitive talent that used to be in the working-class neighborhood is being whisked up and out of the community through an educational system that is increasingly driven by academic performance.</em></p>
<ul>
<li>Page 138 (location ~ 2115-2122)</li>
</ul>
<p><em>How Much Is IQ a Matter of Genes? In fact, IQ is substantially heritable. The state of knowledge does not permit a precise estimate, but half a century of work, now amounting to hundreds of empirical and theoretical studies, permits a broad conclusion that the genetic component of IQ is unlikely to be smaller than 40 percent or higher than 80 percent.25 The most unambiguous direct estimates, based on identical twins raised apart, produce some of the highest estimates of heritability.26 For purposes of this discussion, we will adopt a middling estimate of 60 percent heritability, which, by extension, means that IQ is about 40 percent a matter of environment. The balance of the evidence suggests that 60 percent may err on the low side.</em></p>
<ul>
<li>Page 140 (location ~ 2135-2141)</li>
</ul>
<p><em>What we want to know is how much of the variation in IQ in a population—the aggregated differences among the individuals27—is due to variations in genetic endowments and how much is due to variations in environment. If all the population variation in IQ is due to variations in environment, then the heritability is 0;28 if half is due to environmental variations, it is .5; if none is due to environmental variations, it is 1.0. Heritability, in other words, is a ratio that ranges between 0 and 1 and measures the relative contribution of genes to the variation observed in a trait.29 Specialists have come up with dozens of procedures for estimating heritability. Nonspecialists need not concern themselves with nuts and bolts, but they may need to be reassured on a few basic points. First, the heritability of any trait can be estimated as long as its variation in a population can be measured. IQ meets that criterion handily. There are, in fact, no other human traits—physical or psychological—that provide as many good data for the estimation of heritability as the IQ. Second, heritability describes something about a population of people, not an individual. It makes no more sense to talk about the heritability of an individual’s IQ than it does to talk about his birthrate. A given individual’s IQ may have been greatly affected by his special circumstances even though IQ is substantially heritable in the population as a whole. Third, the heritability of a trait may change when the conditions producing variation change. If, one hundred years ago, the variations in exposure to education were greater than they are now (as is no doubt the case), and if education is one source of variation in IQ, then, other things equal, the heritability of IQ was lower then than it is now.</em></p>
<ul>
<li>Page 140 (location ~ 2143-2157)</li>
</ul>
<p><em>This last point is especially important in the modern societies, with their intense efforts to equalize opportunity. As a general rule, as environments become more uniform, heritability rises. When heritability rises, children resemble their parents more, and siblings increasingly resemble each other; in general, family members become more similar to each other and more different from people in other families. It is the central irony of egalitarianism: Uniformity in society makes the members of families more similar to each other and members of different families more different.</em></p>
<ul>
<li>Page 141 (location ~ 2158-2162)</li>
</ul>
<p><em>The purest of the direct comparisons is based on identical (monozygotic, MZ) twins reared apart, often not knowing of each other’s existence. Identical twins share all their genes, and if they have been raised apart since birth, then the only environment they shared was that in the womb. Except for the effects on their IQs of the shared uterine environment, their IQ correlation directly estimates heritability. The most modern study of identical twins reared in separate homes suggests a heritability for general intelligence between .75 and .80, a value near the top of the range found in the contemporary technical literature.31 Other direct estimates use data on ordinary siblings who were raised apart or on parents and their adopted-away children. Usually, the heritability estimates from such data are lower but rarely below .4.</em></p>
<ul>
<li>Page 142 (location ~ 2167-2173)</li>
</ul>
<p><em>Indirect methods compare the IQ correlations between people with different levels of shared genes growing up in comparable environments—siblings versus half-siblings or versus cousins, for example, or MZ twins versus fraternal (dizygotic, DZ) twins, or nonadoptive siblings versus adoptive siblings. The underlying idea is that, for example, if full siblings raised in the same home and half-siblings raised in the same home differ in their IQ correlations, it is because they differ in the proportion of genes they share: full siblings share about 50 percent of genes, half siblings about 25 percent. Similarly, if siblings raised in unshared environments and cousins raised in unshared environments differ in their IQ correlations, it is because of the differing degrees of genetic overlap between cousins and siblings and not because of differing environmental influences, which are unshared by definition. And so on. Fleshed out in some sort of statistical model, this idea makes it possible to estimate the heritability, but the modeling can get complex. Some studies use mixtures of direct and indirect methods.</em></p>
<ul>
<li>Page 142 (location ~ 2174-2182)</li>
</ul>
<p><em>Finally, and most surprisingly, the evidence is growing that whatever variation is left over for the environment to explain (i.e., 40 percent of the total variation, if the heritability of IQ is taken to be .6), relatively little can be traced to the shared environments created by families.38 It is, rather, a set of environmental influences, mostly unknown at present, that are experienced by individuals as individuals. The fact that family members resemble each other in intelligence in adulthood as much as they do is very largely explained by the genes they share rather than the family environment they shared as children. These findings suggest deep roots indeed for the cognitive stratification of society.</em></p>
<ul>
<li>Page 144 (location ~ 2195-2201)</li>
</ul>
<p><em>The United States is still very far from this state of affairs at the extremes. If one thinks of babies growing up in slums with crack-addicted mothers, at one extreme, compared to children growing up in affluent, culturally rich homes with parents dedicated to squeezing every last IQ point out of them, then even a heritability of .6 leaves room for considerable change if the changes in environment are commensurably large. We take up the evidence on that issue in detail in Chapter 17, when we consider the many educational and social interventions that have attempted to raise IQ. But those are, by definition, the extremes, the two tails of the distribution of environments. Moving a child from an environment that is the very worst to the very best may make a big difference. In reality, what most interventions accomplish is to move children from awful environments to ones that are merely below average, and such changes are limited in their potential consequences when heritability so constrains the limits of environmental effects.</em></p>
<ul>
<li>Page 145 (location ~ 2213-2220)</li>
</ul>
<p><em>Consider 100 Harvard/Radcliffe marriages from the class of 1930 versus another 100 from the class of 1964. We stipulate that the propensity to marry people of similar intelligence has not changed in the intervening thirty-four years. Nonetheless, the ones who marry in 1964 will produce a set of children with considerably higher mean IQ than the ones who married in 1930, because the level of intelligence at Harvard and Radcliffe had risen so dramatically. How much difference can it make? If the average Harvard man in the class of 1930 married the average Radcliffe woman in the same graduating class—as far as we can tell, both would have had IQs of about 117—then the expected mean IQ of their children, after taking regression to the mean into account, will be about 114, or at the 82d percentile.45 But average Harvard and Radcliffe newlyweds in the class of 1964 were likely to have children with a mean IQ of about 124, at the 95th percentile. In terms of distributions rather than averages, about a third of the children of the Harvard newlyweds of 1930 could be expected to have IQs of less than 110—not even college material by some definitions.46 In contrast, only 6 percent of the children of the Harvard newlyweds of 1965 could be expected to fall below this cutoff. Meanwhile, only about 22 percent of the children of the 1930 newlyweds could be expected to match or exceed the average of the children of the 1965 newlyweds. In such numbers lurk large social effects.</em></p>
<ul>
<li>Page 147 (location ~ 2241-2252)</li>
</ul>
<p><em>The increase in homogamy was most pronounced among college-educated persons. Specifically, the odds of a college graduate’s marrying someone who was not a college graduate declined from 44 percent in 1940 to 35 percent in Mare’s most recent data (for 1985 to 1987). The proportion hit a low of 33 percent in the 1980 data.47 Because educational attainment and IQ are so closely linked and became more closely linked in the postwar period, Mare’s results suggest a substantial increase in assortative mating by IQ, with the greatest change occurring at the upper levels of IQ.</em></p>
<ul>
<li>Page 148 (location ~ 2257-2261)</li>
</ul>
<p><em>The second effect of feminism is less ponderable but may be important anyway. Not so many years ago, the cliché was true: brains were not considered sexy in a woman, and many men undervalued brains as an asset in a prospective spouse or even felt threatened by smart women. Such attitudes may linger in some men, but feminism has surely weakened them and, to some degree, freed relationships among men and women so that a woman’s potential for occupational success can take as dominant a place in the man’s marriage calculus as it has traditionally taken in the woman’s.50 We speculate that the effect has been most liberating among the brightest. If we are right, then the trends in educational homogamy that Mare has demonstrated are an understated reflection of what is really going on. Intermarriage among people in the top few percentiles of intelligence may be increasing far more rapidly than suspected.</em></p>
<ul>
<li>Page 149 (location ~ 2280-2287)</li>
</ul>
<p><em>In depressing contrast, we have been envisioning a society that becomes increasingly quiescent at the top, as a cognitive elite moves toward the upper income brackets and runs most of the institutions of society, taking on some of the characteristics of a caste. Is the situation really so extreme? To some extent, not yet. For example, national surveys still indicate that fewer than 60 percent in the top quartile of intelligence actually complete a bachelor’s degree.51 This would seem to leave a lot of room for churning. But when we focus instead on the students in the top few centiles of cognitive ability (from which the nation’s elite colleges pick almost exclusively), an extremely high proportion are already being swept into the comfortable precincts of the cognitive elite.52 In the NLSY, for example, 81 percent of those in the top 5 percent of IQ had obtained at least a bachelor’s degree by 1990, when the youngest members of the sample were 25 years old.53</em></p>
<ul>
<li>Page 150 (location ~ 2290-2299)</li>
</ul>
<p><em>We will also argue that cognitive ability is an important factor in thinking about the nature of the present problems, whether or not cognitive ability is a cause. For example, if many of the single women who have babies also have low IQ, it makes no difference (in one sense) whether the low IQ caused them to have the babies or whether the path of causation takes a more winding route. The reality that less intelligent women have most of the out-of-wedlock babies affects and constrains public policy, whatever the path of causation. The simple correlation, unadjusted for other factors—what social scientists called the zero-order correlation—between cognitive ability and social behaviors is socially important.</em></p>
<ul>
<li>Page 154 (location ~ 2349-2354)</li>
</ul>
<p><em>The Panel Study of Income Dynamics, begun in 1968 and the nation’s longest-running longitudinal database, administered a brief vocabulary test in 1972 to part of its sample, but the scores allow only rough discriminations among people in the lower portions of the distribution of intelligence. The National Longitudinal Survey begun by the Department of Education in 1972 (not to be confused with the NLSY) provides answers to many questions associated with educational outcomes. The department’s more ambitious study, High School and Beyond, conducted in the early 1980s, is also useful. But the mother lode for scholars who wish to understand the relationship of cognitive ability to social and economic outcomes is the NLSY, whose official name is the National Longitudinal Survey of Labor Market Experience of Youth. When the study began in 1979, the participants in the study were aged 14 to 22.3 There were originally 12,686 of them, chosen to provide adequate sample sizes for analyzing crucial groups (for example, by oversampling blacks, Latinos, and low-income whites), and also incorporating a weighting system so that analysts could determine the correct estimates for nationally representative samples of their age group. Sample attrition has been kept low and the quality of the data, gathered by the National Opinion Research Council under the supervision of the Center for Human Resources Research at Ohio State University, has been excellent. The NLSY is unique because it combines in one database all the elements that hitherto had to be studied piecemeal. Only the NLSY combined detailed information on the childhood environment and parental socioeconomic status and subsequent educational and occupational achievement and work history and family formation and—crucially for our interests—detailed psychometric measures of cognitive skills.</em></p>
<ul>
<li>Page 155 (location ~ 2365-2379)</li>
</ul>
<p><em>But What About Other Explanations? We do not have the choice of leaving the issue of causation at that, however. Because intelligence has been such a taboo explanation for social behavior, we assume that our conclusions will often be resisted, if not condemned. We can already hear critics saying, “If only they had added this other variable to the analysis, they would have seen that intelligence has nothing to do with X.” A major part of our analysis accordingly has been to anticipate what other variables might be invoked and seeing if they do in fact attenuate the relationship of IQ to any given social behavior. This was not a scattershot effort. For each relationship, we asked ourselves if evidence, theory, or common sense suggests another major causal story. Sometimes it did. When looking at whether a new mother went on welfare, for example, it clearly was not enough to know the general socioeconomic background of the woman’s parents. It was also essential to examine her own economic situation at the time she had the baby: Whatever her IQ is, would she go on welfare if she had economic resources to draw on? At this point, however, statistical analysis can become a bottomless pit. It is not uncommon in technical journals to read articles built around the estimated effects of a dozen or more independent variables. Sometimes the entire set of variables is loaded into a single regression equation. Sometimes sets of equations are used—modeling even more complex relationships, in which all the variables can exert mutual effects on one another.</em></p>
<ul>
<li>Page 160 (location ~ 2441-2453)</li>
</ul>
<p><em>Education shapes tastes and values in ways that are independent of the cognitive ability of the student. At the same time, however, the role of education versus IQ as calculated by a regression equation is tricky to interpret, for four reasons. First, the number of years of education that a youth gets is caused to an important degree by both the parents’ SES and the youth’s own academic ability. In the NLSY, for example, the correlation of years of education with parental SES and youth’s IQ are +.50 and +.64, respectively. This means that when years of education is used as an independent variable, it is to some extent expressing the effects of SES and IQ in another form. Second, any role that education plays independent of intelligence is likely to be discontinuous. For example, it may make a big difference to many outcomes that a person has a college degree. But how is one to interpret the substantive difference between one year of college and two? Between one year of graduate school and two? They are unlikely to be nearly as important as the difference between “a college degree” and “no college degree.” Third, variables that are closely related can in some circumstances produce a technical problem known as multicollinearity, whereby the solutions produced by regression equations are unstable and often misleading. Fourth and finally, to take education’s regression coefficient seriously tacitly assumes that intelligence and education could vary independently and produce similar results. No one can believe this to be true in general: indisputably, giving nineteen years of education to a person with an IQ of 75 is not going to have the same impact on life as it would for a person with an IQ of 125. The effects of education, whatever they may be, depend on the coexistence of suitable cognitive ability in ways that often require complex and extensive modeling of interaction effects—once again, problems that we hope others will take up but would push us far beyond the purposes of this book.</em></p>
<ul>
<li>Page 161 (location ~ 2460-2475)</li>
</ul>
<p><em>low intelligence is a stronger precursor of poverty than low socioeconomic background. Whites with IQs in the bottom 5 percent of the distribution of cognitive ability are fifteen times more likely to be poor than those with IQs in the top 5 percent. How does each of these causes of poverty look when the other is held constant? Or to put it another way: If you have to choose, is it better to be born smart or rich? The answer is unequivocally “smart.” A white youth reared in a home in which the parent or parents were chronically unemployed, worked at only the most menial of jobs, and had not gotten past ninth grade, but of just average intelligence—an IQ of 100—has nearly a 90 percent chance of being out of poverty by his or her early 30s. Conversely, a white youth born to a solid middle-class family but with an IQ equivalently below average faces a much higher risk of poverty, despite his more fortunate background. When the picture is complicated by adding the effects of sex, marital status, and years of education, intelligence remains more important than any of them, with marital status running a close second. Among people who are both smart and well educated, the risk of poverty approaches zero.</em></p>
<ul>
<li>Page 163 (location ~ 2491-2499)</li>
</ul>
<p><em>The first is that poverty cannot be a simple, direct cause of such problems as crime, illegitimacy, and drug abuse. Probably no single observation about poverty is at once so indisputable and so ignored. It is indisputable because poverty was endemic at a time when those problems were minor. We know that reducing poverty cannot, by itself, be expected to produce less criminality, illegitimacy, drug abuse, or the rest of the catalog of social problems, else the history of the twentieth century would have chronicled their steep decline. The second point illustrated by the graph of poverty is that the pool of poor people must have changed over time. As late as the 1940s, so many people were poor in economic terms that to be poor did not necessarily mean to be distinguishable from the rest of the population in any other way. To rephrase the dialogue between F. Scott Fitzgerald and Ernest Hemingway, the poor were different from you and me: They had less money. But that was almost the only reliable difference. As affluence spread, people who escaped from poverty were not a random sample of the population. When a group shrinks from over 50 percent of the population to the less than 15 percent that has prevailed since the late 1960s, the people who are left behind are likely to be disproportionately those who suffer not only bad luck but also a lack of energy, thrift, farsightedness, determination—and brains. The third point of the graph is that some perspective is in order about what happened to poverty during the 1960s and the famous War on Poverty. The trendline we show for 1936-1969 would have had about the same slope if we had chosen any of the decades in between to calculate it. The United States was not only getting richer but had been reducing the percentage of people below the modern poverty line for at least three decades before the 1960s came to a close. We will not reopen here the continuing debate about why progress came to an end when it did.</em></p>
<ul>
<li>Page 164 (location ~ 2512-2526)</li>
</ul>
<p><em>The stability of IQ over time in the general population has been studied for decades, and the main findings are not in much dispute among psychometricians. Up to about 4 or 5 years of age, measures of IQ are not of much use in predicting later IQ. Indeed, you will get a better prediction of the child’s IQ at age 15 by knowing his parents’ IQ than by any test of the child given before age 5.3 Between ages 5 and 10, the tests rapidly become more predictive of adult IQ.4 After about the age of 10, the IQ score is essentially stable within the constraints of measurement error.5 On the comparatively rare occasions when large changes in IQ are observed, there is usually an obvious explanation. The child had been bedridden with a long illness before one of the tests, for example, or there was severe emotional disturbance at the time of one or both of the tests.</em></p>
<ul>
<li>Page 166 (location ~ 2538-2545)</li>
</ul>
<p><em>The lowest scores indicate poverty, meager education, and the most menial jobs. Suppose we then take the SES index and divide all the NLSY youngsters into five socioeconomic classes on exactly the same basis that we defined cognitive classes (split into categories of 5-20-50-20-5 percent of the population). We then ask, What percentage of people who came from those socioeconomic backgrounds were below the poverty line in their late 20s and early 30s (i.e., in 1989)? We exclude those who were still in school. The answer for non-Latino whites in the NLSY sample is shown in the following table. What could be plainer? Hardly any of the lucky 5 percent who had grown up in the most advantaged circumstances were in poverty (only 3 percent). Meanwhile, the white children of parents in the lowest socioeconomic class had a poverty rate of 24 percent. Rank hath its privileges, and in the United States one of those privileges is to confer economic benefits on your children. The way to avoid poverty in the United States is to be born into an advantaged home.</em></p>
<ul>
<li>Page 168 (location ~ 2563-2570)</li>
</ul>
<p><em>Taken one variable at a time, the data fit both hypotheses: Poverty is associated with socioeconomic disadvantage and even more strongly with cognitive disadvantage. Which is really explaining the relationship? And so we introduce a way of assessing the comparative roles of intelligence and socioeconomic background, which we will be using several times in the course of the subsequent chapters. We want to disentangle the comparative roles of cognitive ability and socioeconomic background in explaining poverty. The dependent variable, poverty, has just two possible values: Yes, the family had an income below the poverty line in 1989, or no, its income was above the poverty line. The statistical method is a type of regression analysis specifically designed to estimate relationships for a yes-no kind of dependent variable.9 In our first look at this question, we see how much poverty depends on three independent variables: IQ, age, and parental socioeconomic status (hereafter called “parental SES”). The sample consists of all whites in the NLSY who were out of school in 1989.10 We are asking a straightforward question: Given information about intelligence, socioeconomic status, and age, what is our best estimate of the probability that a family was below the poverty line in 1989? for which a computer, using the suitable software, can provide an answer. Then we ask a second question: Taking the other factors into account, how much remaining effect does any one of the independent variables have on the probability of being in poverty? for which the computer can also provide an answer.</em></p>
<ul>
<li>Page 170 (location ~ 2596-2609)</li>
</ul>
<p><em>When we apply these questions to the NLSY data, the figure below shows what emerges. First, age in itself is not important in determining whether someone is in poverty once the other factors of intelligence and parental family background are taken into account.11 Statistically, its impact is negligible. This leaves us with the two competing explanations that prompted the analysis in the first place: the socioeconomic background in which the NLSY youth grew up, and his own IQ score. The black line lets you ask, “Imagine a person in the NLSY who comes from a family of exactly average socioeconomic background and exactly average age.12 What are this person’s chances of being in poverty if he is very smart? Very dumb?” To find out his chances if he is smart, look toward the far right-hand part of the graph. A person with an IQ 2 SDs above the mean has an IQ of 130, which is higher than 98 percent of the population. Reading across to the vertical axis on the left, that person has less than a 2 percent chance of being in poverty (always assuming that his socioeconomic background was average). Now think about someone who is far below average in cognitive ability, with an IQ 2 SDs below the mean (an IQ of 70, higher than just 2 percent of the population). Look at the far left-hand part of the graph. Now, our imaginary person with an average socioeconomic background has about a 26 percent chance of being in poverty. The gray line lets you ask, “Imagine a person in the NLSY who is exactly average in IQ and age. What are this person’s chances of being in poverty if he came from an extremely advantaged socioeconomic background? An extremely deprived socioeconomic background?” As the gray line indicates, the probability of being in poverty rises if he was raised by parents who were low in socioeconomic status, but only gradually.</em></p>
<ul>
<li>Page 171 (location ~ 2610-2624)</li>
</ul>
<p><em>In general, the visual appearance of the graph lets you see quickly the result that emerges from a close analysis: Cognitive ability is more important than parental SES in determining poverty.13 This does not mean that socioeconomic background is irrelevant. The magnitude of the effect shown in the graph and its statistical regularity makes socioeconomic status significant in a statistical sense. To put it into policy terms, the starting line remains unequal in American society, even among whites. On the other hand, the magnitude of the disadvantage is not as large as one might expect. For example, imagine a white person born in 1961 who came from an unusually deprived socioeconomic background: parents who worked at the most menial of jobs, often unemployed, neither of whom had a high school education (a description of what it means to have a socioeconomic status index score in the 2d centile on socioeconomic class). If that person has an IQ of 100—nothing special, just the national average—the chance of falling below a poverty-level income in 1989 was 11 percent.</em></p>
<ul>
<li>Page 172 (location ~ 2633-2641)</li>
</ul>
<p><em>In sum: Low intelligence means a comparatively high risk of poverty. If a white child of the next generation could be given a choice between being disadvantaged in socioeconomic status or disadvantaged in intelligence, there is no question about the right choice.</em></p>
<ul>
<li>Page 173 (location ~ 2645-2647)</li>
</ul>
<p><em>COMPLICATING THE ISSUE: POVERTY AMONG CHILDREN How does the information we have just presented help in trying to understand the nature of poverty in America? To illustrate, consider one of the most painful topics in recent American social policy, the growing proportion of poor who consist of children. As of the 1991 figures, 22 percent of all children under the age of 15 were below the official poverty line, twice as high as the poverty rate among those age 15 and over.14 It is a scandalously high figure in a country as wealthy as the United States. Presumably every reader wishes for policies that would reduce poverty among children. Why are so many children in poverty in a rich country? In political debate, the question is usually glossed over. An impression is conveyed that poverty among children is something that has grown everywhere in the United States, for all kinds of families, for reasons vaguely connected with economic troubles, ungenerous social policies during the 1980s, and discrimination against women and minority groups.</em></p>
<ul>
<li>Page 174 (location ~ 2666-2675)</li>
</ul>
<p><em>Poverty among children has always been much higher in families headed by a single woman, whether she is divorced or never married. For families headed by a single woman, the poverty rate in 1991 was 36 percent; for all other American families, 6 percent.16 Indeed, the national poverty rate for households headed by a single woman has been above 30 percent since official poverty figures began to be available in 1959.17 The equation is brutally simple: The higher the proportion of children who live in households headed by single women, then, ceteris paribus, the higher the proportion of children who will live in poverty.</em></p>
<ul>
<li>Page 175 (location ~ 2676-2682)</li>
</ul>
<p><em>Poverty Among Children: The Role of the Mother’s IQ What does IQ add to this picture? It allows us to focus sharply on who is poor and why, and to dispense with a number of mistaken ideas. To see how, let us consider women, and specifically women with children.19 Here is the graph that results when we ask how often mothers with differing IQs and differing family structures suffer from poverty. (In the figure, the effects of the mothers’ socioeconomic background are held constant, as are the number of children, which is factored into the calculation of the poverty line.) The first, glaring point of the figure is that marriage is a powerful poverty preventive, and this is true for women even of modest cognitive ability. A married white woman with children who is markedly below average in cognitive ability—at the 16th centile, say, one standard deviation below the mean—from an average socioeconomic background had only a 10 percent probability of poverty.</em></p>
<ul>
<li>Page 176 (location ~ 2685-2693)</li>
</ul>
<p><em>The second point of the graph is that to be without a husband in the house is to run a high risk of poverty, even if the woman was raised in an average socioeconomic background. Such a woman, with even an average IQ, ran a 33 percent chance of being in poverty. If she was unlucky enough to have an IQ of only 85, she had more than a 50 percent chance—five times as high as the risk faced by a married woman of identical IQ and socioeconomic background. Even a woman with a conspicuously high IQ of 130 (two standard deviations above the mean) was predicted to have a poverty rate of 10 percent if she was a single mother, which is quite high compared to white women in general. Perhaps surprisingly, it did not make much difference which of the three kinds of “nonmarriage”—separation, divorce, or no marriage at all—was involved. The results for all three groups of women were drastically different from the results for married women, and quite similar to each other (which is why they are grouped in the figure.)</em></p>
<ul>
<li>Page 176 (location ~ 2696-2703)</li>
</ul>
<p><em>The third obvious conclusion is that IQ is extremely important in determining poverty among women without a husband present. A poverty rate of 10 percent for women with IQs of 130 may be high compared to some standards, but it is tiny compared to the steeply rising probabilities of poverty that characterize women with below average cognitive ability.</em></p>
<ul>
<li>Page 177 (location ~ 2703-2705)</li>
</ul>
<p><em>There are few clearer arguments for bringing cognitive ability into the analysis of social problems. Consider the hundreds of articles written about poverty among children and about the effects of single-parent families on poverty. Of course, these are important factors: Children are more often poor than adults. Family breakup is responsible for a major portion of the increase in child poverty. But if analysts are trying to understand the high rates of poverty among children, it must be done against the background that whatever other factors increase the risk of poverty among unmarried mothers, they hit unmarried mothers at low levels of intelligence much harder than they do those at high levels of intelligence—even after socioeconomic background is held constant.</em></p>
<ul>
<li>Page 178 (location ~ 2718-2723)</li>
</ul>
<p><em>reality. Einstein’s injunction that solutions should be as simple as possible, but no simpler, still applies. At the same time, social science often seems more in need of the inverse injunction, to introduce as much complexity as necessary, but no more. Complications can make us forget what we were trying to understand in the first place. Here is where we believe the situation stands: By complicating the picture, we raise additional questions: Education is important in affecting poverty; the appropriate next step is to explore how intelligence and socioeconomic status are related to years of education. Marriage is important in determining poverty; we should explore how intelligence and socioeconomic status are related to marriage. These things we shall do in subsequent chapters. But the simple picture, with only IQ, parental SES, and age in the equation, restricted to our all-white sample, continues to tell a story of its own. A major theme in the public dialogue in the United States has been that socioeconomic disadvantage is the primary driving force behind poverty. The simple picture shows that it just isn’t so for whites.22 The high rates of poverty that afflict certain segments of the white population are determined more by intelligence than by socioeconomic background. The force and relevance of this statement does not seem to us diminished by the complications it does not embrace.</em></p>
<ul>
<li>Page 178 (location ~ 2729-2739)</li>
</ul>
<p><em>Dropout is extremely rare throughout the upper half of the IQ distribution. Socioeconomic background has its most powerful effect at the lowest end of the social spectrum, among students who are already below average in intelligence. Being poor has a small effect on dropping out of school independent of IQ; it has a sizable independent effect on whether a person finishes school with a regular diploma or a high school equivalency certificate. To raise the chances of getting a college degree, it helps to be in the upper half of the distribution for either IQ or socioeconomic status. But the advantage of a high IQ outweighs that of high status. Similarly, the disadvantage of a low IQ outweighs that of low status. Youngsters from poor backgrounds with high IQs are likely to get through college these</em></p>
<ul>
<li>Page 181 (location ~ 2761-2767)</li>
</ul>
<p><em>Dropout is extremely rare throughout the upper half of the IQ distribution. Socioeconomic background has its most powerful effect at the lowest end of the social spectrum, among students who are already below average in intelligence. Being poor has a small effect on dropping out of school independent of IQ; it has a sizable independent effect on whether a person finishes school with a regular diploma or a high school equivalency certificate. To raise the chances of getting a college degree, it helps to be in the upper half of the distribution for either IQ or socioeconomic status. But the advantage of a high IQ outweighs that of high status. Similarly, the disadvantage of a low IQ outweighs that of low status. Youngsters from poor backgrounds with high IQs are likely to get through college these days, but those with low IQs, even if they come from well-to-do backgrounds, are not.</em></p>
<ul>
<li>Page 181 (location ~ 2761-2768)</li>
</ul>
<p><em>Low intelligence is one of the best predictors of school failure, and students who fail a grade or two are likely to have the least attachment to school. And yet this relationship, as strong as it is now, is also new. The very concept of school failure is a modern invention. In the era of the one-room schoolhouse, students advanced at their own pace. There were no formal grade levels, no promotions to the next grade, hence no way to fail.1 “Dropping out” is an even more recent concept, created by the assumption that it is normal to remain in school through age 17. Until recently, it wasn’t typical. In 1900, the high school diploma was the preserve of a tiny minority of American youth: The number of those who got one amounted to only 6 percent of the crop of potential seniors that year. This figure, known as the graduation ratio, is calculated as the percentage of the 17-year-old population.2 Perhaps even more startling, it was not until the beginning of World War II that the graduation ratio first passed the 50 percent mark. The figure shows the story from 1900 to 1990.3 The trendlines that overlie the data indicate two broad phases in this ninety-year history. The first phase, from 1908 until the early 1920s, featured moderate expansion of high school education. It did not appear moderate at the time—the graduation rate more than doubled from 1900 to 1922—but the growth was nonetheless moderate by comparison with steep surge from 1922 until the beginning of World War II.</em></p>
<ul>
<li>Page 181 (location ~ 2769-2781)</li>
</ul>
<p><em>Americans today take it for granted that the goal is to graduate everyone and that a high school dropout rate is a social evil. But earlier thinkers, even those in our liberal tradition, were dubious about educating the entire population beyond the rudiments of literacy. Voltaire’s view that “the lower classes should be guided, not educated,” was typical until this century.5 Even early in this century, many observers feared that unqualified youngsters were being educated beyond their abilities. “We must turn back the clock,” one prominent educator wrote in 1936, “to take some five million boys and girls from the educational dole.”6 And yet when the psychometricians sought to document the fear that the country was trying to educate the ineducable, they found little evidence for it. One investigator, Frank Finch, assembled all of the competent studies of the intelligence of high school students conducted from 1916 (the earliest study he could find) to 1942. The mean IQ of ninth graders in these studies was 105; the mean IQ of the twelfth graders or graduates was 107, trivially different.7 The data suggest that the large number of youngsters who dropped out between ninth grade and high school graduation averaged less than 105 in IQ, but not by much (a calculation explained in the note).</em></p>
<ul>
<li>Page 182 (location ~ 2789-2800)</li>
</ul>
<p><em>WHITE HIGH SCHOOL DROPOUT IN THE NLSY Who drops out of high school these days? The following table shows the story for NLSY whites in the various cognitive classes. The results could hardly be starker. Among whites in the top quartile (Classes I and II together), virtually everyone got a high school education. In the bottom quartile of the IQ distribution (Classes IV and V together), 39 percent of whites did not.12 This huge discrepancy is also predictable, however, given the close relationship between IQ and educational attainment—so predictable that we should pause for a moment before viewing dropout rates with alarm. Is a 39 percent dropout rate for students in the lowest quartile of IQ “high”? From one perspective, it seems so, considering how essential education appears to be for making a living. From another perspective, it is remarkable that over 60 percent of white youths with IQs under 90 did get a high school education. It is particularly remarkable that nearly half of the youths in Class V, with IQs of 75 and under, completed a high school education, despite being on the borderline (or beyond) of the clinical definition of retarded.</em></p>
<ul>
<li>Page 184 (location ~ 2818-2827)</li>
</ul>
<p><em>In their unemployment rates, job tenure, and wages, the GEDs look more like dropouts than they look like high school graduates, raising the possibility that they differ from other high school graduates in a variety of ways that makes it dangerous to lump all people with “a high school education” into a single group. We know from our own analyses that the white GEDs in the NLSY had an average IQ half a standard deviation lower than the average for white high school graduates. Furthermore, apart from the specifics of the data, it is apparent that the nature of the GED student’s behavior—giving up on school, then later returning to pass the examination—is different in kind from that of both the dropout who leaves school and never goes back, and from that of the youth who sticks with four consecutive years of schooling and gets a diploma.</em></p>
<ul>
<li>Page 186 (location ~ 2849-2855)</li>
</ul>
<p><em>parents. Dropout rates were extremely low for white students who were of at least average intelligence or socioeconomic background. But dropout rates rose rapidly when those variables fell below average, with the rise being precipitous for students with low IQ. A closer look at these numbers dispels the stereotype of the high school dropout as the bright but unlucky youngster whose talents are wasted because of economic disadvantage or a school system that cannot hold onto him—the stereotype that people have in mind when they lament the American dropout rate because it is frittering away the nation’s human capital.17 Among whites, hardly anyone in the NLSY fit that description. Of the whites who dropped out never to return, only three-tenths of 1 percent met a realistic definition of the gifted-but-disadvantaged dropout (top quartile of IQ, bottom quartile of socioeconomic background.) Another eight-tenths of 1 percent were in the top quartile of IQ and the third quartile of the socioeconomic distribution. Even when we relax the definition to include everyone who is from the top half of the IQ distribution and the bottom half of the socioeconomic distribution—a very loose definition indeed—we are talking about a grand total of only 5.5 percent of the permanent dropouts, or half of 1 percent of American whites in the NLSY.</em></p>
<ul>
<li>Page 187 (location ~ 2863-2873)</li>
</ul>
<p><em>To put it technically, the effects of socioeconomic status and intelligence interact. A white youth who had both low cognitive ability and a poor socioeconomic background was at even more risk of dropout than the separate effects of each variable would lead one to expect.19 Of white youths who were in the bottom</em></p>
<ul>
<li>Page 188 (location ~ 2878-2881)</li>
</ul>
<p><em>Interpretively, the brighter dropouts may go back to get a GED, but they continue to share in common with the permanent dropouts a lower-class social background that has not inculcated a work ethic that makes for success in the labor force.20 Thus, GEDs are more like normal graduates in their intelligence but more like other dropouts in their success in the labor force. All of this interpretation is speculative, and we will leave it to others to determine whether these possibilities stand up to examination. Meanwhile, the results emphasize the need for more open exploration of a topic that has been almost as taboo in some circles as IQ: the possibility that “lower class” in its old-fashioned sense has an impact on how people behave. One concrete result of this analysis bears on the presentation in this book. The differences between GED graduates and those with regular diplomas are too great to justify grouping them together. Whenever we refer to “a high school education” throughout the rest of Part II, we are referring specifically to the normal high school career, completed by a diploma. GED graduates are excluded.</em></p>
<ul>
<li>Page 189 (location ~ 2896-2905)</li>
</ul>
<p><em>THE COMPARATIVE ROLE OF IQ AND FAMILY BACKGROUND IN GETTING A COLLEGE DEGREE As a general statement, the relationship of IQ to educational attainment seems to have been remarkably stable. Twenty years ago, one of the leading texts on the Wechsler Adult Intelligence Scale reported that the mean of high school graduates was about 105, the mean of college graduates was 115, and the mean of people getting medical degrees and Ph.D.s was about 125.21 The book, published in 1972, was based on clinical experience in the 1950s and 1960s. This summary is virtually identical to the story told by the NLSY for whites (who correspond most closely with the college population in the 1950s and early 1960s). The mean IQ of high school graduates was 106, the mean of college graduates was 116, and the mean of people with professional degrees was 126. The relative roles of socioeconomic status and IQ in getting a bachelor’s degree for youths of the late 1970s and 1980s are shown in the figure below.</em></p>
<ul>
<li>Page 190 (location ~ 2905-2913)</li>
</ul>
<p><em>Economists distinguish between being unemployed and being out of the labor force. The unemployed are looking for work unsuccessfully. Those out of the labor force are not looking, at least for the time being. Among young white men in their late 20s and early 30s, both unemployment and being out of the labor force are strongly predicted by low cognitive ability, even after taking other factors into account. Many of the white males in the NLSY who were out of the labor force had the obvious excuse: They were still in college or graduate school. Of those not in school, 15 percent spent at least a month out of the labor force in 1989. The proportion was more than twice as high in cognitive Class V as in Class I. Socioeconomic background was not the explanation. After the effects of IQ were taken into account, the probability of spending time out of the labor force went up, not down, as parental SES rose. Why are young men out of the labor force? One obvious possibility is physical disability. Yet here too cognitive ability is a strong predictor: Of the men who described themselves as being too disabled to work, more than nine out of ten were in the bottom quarter of the IQ distribution; fewer than one in twenty were in the top quarter. A man’s IQ predicted whether he described himself as disabled better than the kinds of job he had held. We do not know why intelligence and physical problems are so closely related, but one possibility is that less intelligent people are more accident prone.</em></p>
<ul>
<li>Page 192 (location ~ 2944-2955)</li>
</ul>
<p><em>LABOR FORCE DROPOUT To qualify as “participating in the labor force,” it is not necessary to be employed; it is necessary only to be looking for work. Seen from this perspective, there are only a few valid reasons why a man might not be in the labor force. He might be a full-time student; disabled; institutionalized or in the armed forces; retired; independently wealthy; staying at home caring for the children while his wife makes a salary. Or, it may be argued, a man may legitimately be out of the labor force if he is convinced that he cannot find a job even if he tries. But this comes close to exhausting the list of legitimate reasons. As of the 1990 interview wave, the members of the NLSY sample were in an ideal position for assessing labor force participation. They were 25 to 33 years old, in their prime working years, and they were indeed a hardworking group. Ninety-three percent of them had jobs. Fewer than 5 percent were out of the labor force altogether. What had caused that small minority to drop out of the labor force? And was there any relationship between being out of the labor force and intelligence?</em></p>
<ul>
<li>Page 195 (location ~ 2976-2985)</li>
</ul>
<p><em>If we had run this analysis with just socioeconomic background and age as the explanatory variables, we would have found a mildly interesting but unsurprising result: Holding age constant, white men from more privileged backgrounds have a modestly smaller chance of dropping out of the labor force than white men from deprived backgrounds. But when IQ is added to the equation, the role of socioeconomic background either disappears entirely or moves in the opposite direction. Given equal age and IQ, a young man from a family with high socioeconomic status was more likely to spend time out of the labor force than the young man from a family with low socioeconomic status.3 In contrast, IQ had a large positive impact on staying at work. A man of average age and socioeconomic background in the 2d centile of IQ had almost a 20 percent chance of spending at least a month out of the labor force, compared to only a 5 percent chance for a man at the 98th centile.</em></p>
<ul>
<li>Page 197 (location ~ 3008-3015)</li>
</ul>
<p><em>It is not hard to imagine why high intelligence helps keep a man at work. As Chapter 3 discussed, competence in the workplace is related to intelligence, and competent people more than incompetent people are likely to find the workplace a congenial and rewarding place. Hence, other things equal, they are more likely than incompetent people to be in the labor force. Intelligence is also related to time horizons. A male in his 20s has many diverting ways to spend his time, from traveling the world to seeing how many women he can romance, all of them a lot more fun than working forty hours a week at a job. A shortsighted man may be tempted to take a few months off here and there; he thinks he can always pick up again when he feels like it. A farsighted man tells himself that if he wants to lay the groundwork for a secure future, he had better establish a record as a reliable employee now, while he is young. Statistically, smart men tend to be more farsighted than dumb men. In contrast to IQ, the role of parental SES is inherently ambiguous. One possibility is that growing up in a privileged home foretells low dropout rates, because the parents in such households socialize their sons to conventional work. But this relationship may break down among the wealthy, whose son has the option of living comfortably without a weekly paycheck. In any case, aren’t working-class homes also adamant about raising sons to go out and get a job? And don’t young men from lower-class homes have a strong economic incentive to stay in the labor force because they are likely to need the money? The statistical relationship with parental SES that shows up in the analysis suggests that higher status may facilitate labor force dropout, at least for short periods.</em></p>
<ul>
<li>Page 197 (location ~ 3019-3031)</li>
</ul>
<p><em>EDUCATION. Conducting the analysis separately for our two educational samples (those with a bachelor’s degree, no more and no less, and those with a high school diploma, no more and no less) does not change the picture. High intelligence played a larger independent role in reducing labor force dropout among the college sample than among the high school sample. And for both samples, high socioeconomic background did not decrease labor force dropout independent of IQ and age. Once again, the probability of dropout actually increased with socioeconomic background.</em></p>
<ul>
<li>Page 198 (location ~ 3035-3039)</li>
</ul>
<p><em>JOB DISABILITIES In the preceding analysis, we excluded all the cases in which men reported that they were unable to work. But it is not that simple. Low cognitive ability increases the risk of being out of the labor force for healthy young men, but it also increases the risk of not being healthy. The breakdown by cognitive classes is shown in the following table. The relationship of IQ with both variables is conspicuous but more dramatic for men reporting that their disability prevents them from working. The rate per 1,000 of men who said they were prevented from working by a physical disability jumped sevenfold from Class III to Class IV, and then more than doubled again from Class IV to Class V. Job Disability Among Young White Males No. per 1,000 Who Reported Being Prevented from Working by Health Problems Cognitive Class No. per 1,000 Who Reported Limits in Amount or Kind of Work by Health Problems 0 I Very Bright 13 5 II Bright 21 5 III Normal 37 36 IV Dull 45 78 V Very dull 62 11 Overall average 33</em></p>
<ul>
<li>Page 199 (location ~ 3040-3059)</li>
</ul>
<p><em>A moment’s thought suggests a plausible explanation: Men with low intelligence work primarily in blue-collar, manual jobs and thus are more likely to get hurt than are men sitting around conference tables. Being injured is more likely to shrink the job market for a blue-collar worker than a for a white-collar worker. An executive with a limp can still be an executive; a manual laborer with a limp faces a more serious job impediment.</em></p>
<ul>
<li>Page 200 (location ~ 3059-3062)</li>
</ul>
<p><em>But given that both men have blue-collar jobs, the man with an IQ of 85 had double the probability of a work disability of a man with an IQ of 115. Might there be something within job categories to explain away this apparent relationship of IQ to job disability? We explored the question from many angles, as described in the extended note, and the finding seems to be robust. For whatever reasons, white men with low IQs are more likely to report being unable to work because of health than their smarter counterparts, even when the occupational hazards have been similar.4 Why might intelligence be related to disability, independent of the line of work itself? An answer leaps to mind: The smarter you are, the less likely that you will have accidents. In Lewis Terman’s sample of people with IQs above 140 (see Chapter 2), accidents were well below the level observed in the general population.</em></p>
<ul>
<li>Page 201 (location ~ 3068-3075)</li>
</ul>
<p><em>UNEMPLOYMENT Men who are out of the labor force are in one way or another unavailable for work; unemployed men, in contrast, want work but cannot find it. The distinction is important. The nation’s unemployment statistics are calculated on the basis of people who are looking for work, not on those who are out of the labor force. Being unemployed is transitory, a way station on the road to finding a job or dropping out of the work force. But it is hard to see much difference between unemployment and dropping out in the relationship with intelligence.</em></p>
<ul>
<li>Page 202 (location ~ 3088-3092)</li>
</ul>
<p><em>A CONCLUSION AND A REMINDER ABOUT INTERPRETING RARE EVENTS The most basic implication of the analysis is that intelligence and its correlates—maturity, farsightedness, and personal competence—are important in keeping a person employed and in the labor force. Because such qualities are not entirely governed by economic conditions, the question of who is working and who is not cannot be answered just in terms of what jobs are available. This does not mean we reject the relevance of structural or economic conditions. In bad economic times, we assume, finding a job is harder for the mature and farsighted as well as for the immature and the shortsighted, and it is easier to get discouraged and drop the search. Our goal is to add some leavening to the usual formulation. The state of the economy matters, but so do personal qualities, a point that most economists would probably accept if it were brought to their attention so baldly, but somehow it gets left out of virtually all discussions of unemployment and labor force participation.</em></p>
<ul>
<li>Page 204 (location ~ 3120-3127)</li>
</ul>
<p><em>For marriage, the general rule is that the more intelligent get married at higher rates than the less intelligent. This relationship, which applies across the range of intelligence, is obscured among people with high levels of education because college and graduate school are powerful delayers of marriage. Divorce has long been more prevalent in the lower socioeconomic and educational brackets, but this turns out to be explained better by cognitive level than by social status. Once the marriage-breaking impact of low intelligence is taken into account, people of higher socioeconomic status are more likely to get divorced than people of lower status. Illegitimacy, one of the central social problems of the times, is strongly related to intelligence. White women in the bottom 5 percent of the cognitive ability distribution are six times as likely to have an illegitimate first child as those in the top 5 percent. One out of five of the legitimate first babies of women in the bottom 5 percent was conceived prior to marriage, compared to fewer than one out of twenty of the legitimate babies to women in the top 5 percent. Even among young women who have grown up in broken homes and among young women who are poor—both of which foster illegitimacy—low cognitive ability further raises the odds of giving birth illegitimately. Low cognitive ability is a much stronger predisposing factor for illegitimacy than low socioeconomic background.</em></p>
<ul>
<li>Page 205 (location ~ 3139-3150)</li>
</ul>
<p><em>We know from work by Robert Retherford that in premodern societies the wealthy and successful married at younger ages than the poor and underprivileged.3 Retherford further notes that intelligence and social status are correlated wherever they have been examined; hence, we can assume that intelligence—via social status—facilitated’marriage in premodern societies. With the advent of modernity, however, this relationship flips over. Throughout the West since the nineteenth century, people in the more privileged sector of society have married later and at lower rates than the less privileged. We examine the demographic implications of this phenomenon in Chapter 15. For now, the implication is that in late-twentieth-century America, we should expect to find lower marriage rates among the highly intelligent in the NLSY.</em></p>
<ul>
<li>Page 208 (location ~ 3178-3184)</li>
</ul>
<p><em>Among men, other images have recently become part of the culture: the intelligent, successful, and unmarried heterosexual male who cannot make a commitment and the intelligent, successful, and unmarried homosexual male who no longer needs to go through the motions of a marriage. At the other end of the scale, there are similar reasons in research and common sense to suggest that marriage rates will tend to be low among people at the very bottom of the IQ distribution.4 For a number of reasons, having to do with everything from initiative to romance to economics, people with very low IQs are likely to be at a disadvantage in competing for marriage partners. Our first look at the NLSY data conforms to these expectations, though not dramatically. The next table shows the situation for the NLSY sample among whites who had reached the age of 30. There were surprises in these results for us, and perhaps for some of our readers. We would not have guessed that the average age of marriage for people in the top 5 percent of the intelligence distribution was only 25, for example.5 A main point of the table is to introduce the theme threaded throughout the chapter: Our, your, and the media’s impressions of the state of the American family are not necessarily accurate.</em></p>
<ul>
<li>Page 208 (location ~ 3187-3198)</li>
</ul>
<p><em>The Role of Education The real culprit in explaining marriage rates in a young population is education. In the rest of the chapters of Part II, we point out many instances in which taking education into account does not much affect IQ’s independent role. Not so with marriage. When we take education into account, the apparent relationship reverses: The probability of marrying goes up, not down, for people with high IQs—a result found in other databases as well.6 Our standard analysis with the two educational samples, high school graduates (no more and no less) and college graduates (no more and no less) elucidates this finding. The next figure shows that neither IQ nor socioeconomic background was important in determining marriage for the college sample. In sharp contrast, IQ made a significant difference in the high school sample. A high school graduate from an average socioeconomic background who was at the bottom of the IQ distribution (2 standard deviations below the mean) had a 60 percent chance of having married. A high school graduate at the top of the IQ distribution had an 89 percent chance of having married. Meanwhile, the independent role of socioeconomic status in the high school sample was either slightly negative or nil (the downward slope is not statistically significant).</em></p>
<ul>
<li>Page 211 (location ~ 3221-3231)</li>
</ul>
<p><em>It is clear to all researchers who examine the data that higher education is associated with lower levels of divorce. This was certainly true of the NLSY, where the college sample (persons with a bachelor’s degree, no more and no less) had a divorce rate in the first five years of marriage that was less than half that of the high school sample: 7 percent compared to 19 percent. But this raw outcome is deceptive.11 Holding some critical other things equal—IQ, socioeconomic status, age, and date of marriage—the divorce rate for the high school graduates in the first five years of marriage was lower than for college graduates. For whom did IQ make more difference: the high school sample or the college sample? The answer is the college sample, by far. For them, the probability of divorce in the first five years plunged from 28 percent for someone with an IQ of 100 to 9 percent for someone with an IQ of 130. The much more minor effect of IQ among high school graduates was not statistically significant.</em></p>
<ul>
<li>Page 214 (location ~ 3281-3288)</li>
</ul>
<p><em>Do Broken Families Beget Broken Families? One other cause of divorce is mentioned so commonly that it requires exploration: a broken home in the preceding generation. The children of divorced parents have an elevated risk themselves of getting divorced.13 It is not hard to think of reasons why: They have not witnessed how a successful marriage works, they are more likely to see divorce as an acceptable alternative, the turbulence of a failing marriage leaves psychological scars, and so forth.14 None of these reasons has an obvious connection with cognitive ability. They could be valid without necessarily affecting the independent prophylactic role that being smart plays in preventing (or perhaps simply delaying) divorce. And so indeed it worked out in the NLSY. Given a young person of average IQ and socioeconomic background, the probability of divorce within the first five years of marriage was lowest for those who at age 14 had been living with both parents (20 percent), a bit higher for those who had been living with a remarried parent (22 percent), and higher still for those living with an un-remarried or never-married mother (25 percent)15 These are not large effects, however, and are not significant in a statistical sense.</em></p>
<ul>
<li>Page 215 (location ~ 3289-3300)</li>
</ul>
<p><em>One final point about the divorce results is worth noting, however. These findings may help explain the common observation that divorce is less likely when the husband has high education, income, or socioeconomic status or that marriages are more likely to fall apart if they start when the couple is afflicted with unemployment.16 If we had showed a breakdown of divorce rates in the NLSY by social and economic measures alone, we too would have shown such effects.</em></p>
<ul>
<li>Page 216 (location ~ 3306-3310)</li>
</ul>
<p><em>In the seventy-one years from 1920 to 1990, the proportion of children born to single women in the United States went from less than 3 percent, roughly where it had been throughout American history, to 30 percent.18 It would have been about 6 percent had the trendline established from 1920 to 1952 remained unchanged. The trendline shifted upward during the 1950s, but not dramatically. If we had maintained the trendline established from 1952 to 1963, the United States would have had about 11 percent of births out of wedlock in 1991. Instead, the figure was 30 percent, the result of a steep, sustained increase that gatlered steam in the mid-1960s and continued into the early 1990s. The increase for the most recent available year, 1991, was one of the largest in history. There are no signs as we write that illegitimacy is reaching an asymptote. Anyone who is trying to understand social trends must also realize that the magic of compound interest has created an even more explosive rise in the population of unmarried mothers and children.</em></p>
<ul>
<li>Page 218 (location ~ 3330-3338)</li>
</ul>
<p><em>In the seventy-one years from 1920 to 1990, the proportion of children born to single women in the United States went from less than 3 percent, roughly where it had been throughout American history, to 30 percent.18 It would have been about 6 percent had the trendline established from 1920 to 1952 remained unchanged. The trendline shifted upward during the 1950s, but not dramatically. If we had maintained the trendline established from 1952 to 1963, the United States would have had about 11 percent of births out of wedlock in 1991. Instead, the figure was 30 percent, the result of a steep, sustained increase that gatlered steam in the mid-1960s and continued into the early 1990s. The increase for the most recent available year, 1991, was one of the largest in history. There are no signs as we write that illegitimacy is reaching an asymptote. Anyone who is trying to understand social trends must also realize that the magic of compound interest has created an even more explosive rise in the population of unmarried mothers and children. In 1960, for example, there were just 73,000 never-married mothers between the ages of 18 and 34. In 1980, there were 1.0 million.</em></p>
<ul>
<li>Page 218 (location ~ 3330-3339)</li>
</ul>
<p><em>Illegitimacy and IQ If IQ is a factor in illegitimacy, as we will conclude it is, it must be in combination with other things (as common sense would suggest), because IQ itself has not changed nearly enough in recent years to account for the explosive growth in illegitimacy.21 But we will also be exploring the possibility that some of these “other things” that have changed in the last three decades—broken homes and the welfare system being prime suspects—interact with intelligence, making it still more likely than before that a woman of low cognitive ability will have a baby out of wedlock. Among other reasons that cognitive ability may be related to illegitimacy, we have this causal model in mind: The smarter a woman is, the more likely that she deliberately decides to have a child and calculates the best time to do it. The less intelligent the woman is, the more likely that she does not think ahead from sex to procreation, does not remember to use birth control, does not carefully consider when and under what circumstances she should have a child. How intelligent a woman is may interact with her impulsiveness, and hence her ability to exert self-discipline and restraint on her partner in order to avoid pregnancy. The result is a direct and strong relationship between high intelligence and the likelihood that a child is conceived after marriage, and between low intelligence and the likelihood that the child will be born out of wedlock.</em></p>
<ul>
<li>Page 218 (location ~ 3343-3354)</li>
</ul>
<p><em>The relationship of teenage illegitimacy to social and cognitive factors was first treated in detail in an analysis of the High School and Beyond survey published by the RAND Corporation in 1988.24 The report revealed that more than three-quarters of the teenage girls in this national sample who had babies while they were still of high school age came from families in the bottom half of the socioeconomic stratum. More than half came from the bottom quartile. This finding also held true among just the white teenage girls who had babies out of wedlock, with 70 percent coming from the bottom half of the socioeconomic distribution and only 12 percent from the top quartile.25 The RAND study was also the first to reveal that cognitive ability played an important role, independent of socioeconomic status.26 The data from the NLSY generally confirm those reported in the RAND analysis. On the surface, white illegitimacy is associated with socioeconomic status: About 9 percent of babies of women who come from the upper socioeconomic quartile are illegitimate, compared to about 23 percent of the children of women who come from the bottom socioeconomic quartile. But white women of varying status backgrounds differ in cognitive ability as well. Our standard analysis with IQ, age, and parental SES as independent variables helps to clarify the situation. The dependent variable is whether the first child was born out of wedlock.</em></p>
<ul>
<li>Page 222 (location ~ 3403-3415)</li>
</ul>
<p><em>In the NLSY, the statistics contrast even more starkly. Among white women in the NLSY who had a bachelor’s degree (no more, no less) and who had given birth to a child, 99 percent of the babies were born within marriage. In other words, there is virtually no independent role for IQ to play among women in the college sample. It is true that the women in that 1 percent who gave birth out of wedlock were more likely to have the lower test scores—independent of any effect of their socioeconomic backgrounds—but this is of theoretical interest only.</em></p>
<ul>
<li>Page 224 (location ~ 3430-3434)</li>
</ul>
<p><em>The difference between coming from a traditional family versus anything else was large, with the stepfamily about halfway between the traditional family and the mother-only family. As we examined the role of family structure with different breakdowns (the permutations of arrangements that can exist are numerous), a few patterns kept recurring. It seemed that girls who were still living with their biological father at age 14 were protected from having their first baby out of wedlock. The girls who had been living with neither biological parent (usually living with adopted parents) were also protected. The worst outcomes seemed conspicuously associated with situations in which the 14-year-old had been living with the biological mother but not the biological father. Here is one such breakdown. The odds that a white woman’s first baby would be born out of wedlock (again assuming average intelligence and socioeconomic background) were: 8 percent if the biological mother, but not the biological father, was absent by age 14. 8 percent if both biological parents were absent at age 14 (mostly adopted children). 10 percent if both biological parents were present at age 14. 23 percent if the biological father was absent by age 14 but not the biological mother.</em></p>
<ul>
<li>Page 225 (location ~ 3445-3455)</li>
</ul>
<p><em>The controversy about the welfare explanation, in either the “enabling” or “bribe” version, has been intense, with many issues still unresolved.32 Whichever version is employed, the reason for focusing on the role of poverty is obvious: For affluent young women, the welfare system is obviously irrelevant. They are restrained from having babies out of wedlock by moral considerations or by fear of the social penalties (both of which still exist, though weakened, in middle-class circles), by a concern that the child have a father around</em></p>
<ul>
<li>Page 227 (location ~ 3471-3475)</li>
</ul>
<p><em>The controversy about the welfare explanation, in either the “enabling” or “bribe” version, has been intense, with many issues still unresolved.32 Whichever version is employed, the reason for focusing on the role of poverty is obvious: For affluent young women, the welfare system is obviously irrelevant. They are restrained from having babies out of wedlock by moral considerations or by fear of the social penalties (both of which still exist, though weakened, in middle-class circles), by a concern that the child have a father around the house, and because having a baby would interfere with their plans for the future.</em></p>
<ul>
<li>Page 227 (location ~ 3471-3476)</li>
</ul>
<p><em>To put the question in operational terms: Among NLSY white mothers who were below the poverty line in the year prior to giving birth, what proportion of the babies were born out of wedlock? The answer is 44 percent. Among NLSY white mothers who were anywhere above the poverty line in the year before giving birth, what proportion of the babies were born out of wedlock? The answer is only 6 percent. It is a huge difference and makes a prima facie case for those who argue that poverty itself, presumably via the welfare system, is an important cause of illegitimacy.</em></p>
<ul>
<li>Page 228 (location ~ 3492-3496)</li>
</ul>
<p><em>Our main purpose has been to demonstrate that low intelligence is an important independent cause of illegitimacy, and to do so we have considered the role of poverty. In reality, however, we have also opened up many new avenues of inquiry that we cannot fully pursue without writing an entire book on this subject alone. For example, the results raise many questions to be asked about the “culture of poverty” argument. To the extent that a culture of poverty is at work, transmitting dysfunctional values from one generation to the next, it seems paradoxical that low socioeconomic background does not foster illegitimacy once poverty in the year prior to birth is brought into the picture. But the main task posed by these results is to fill in the reason for that extremely strong relationship between low IQ and illegitimacy within the population of poor white women. The possibilities bear directly on some of the core issues in the social policy debate.</em></p>
<ul>
<li>Page 230 (location ~ 3513-3519)</li>
</ul>
<p><em>People have had reason to assume for many years that welfare mothers are concentrated at the low end of the cognitive ability distribution, if only because they have generally done poorly in school. Beyond that, it makes sense that smarter women can more easily find jobs and resist the temptations of welfare dependency than duller ones, even if they have given birth out of wedlock. The link is confirmed in the NLSY. Over three-quarters of the white women who were on welfare within a year of the birth of their first child came from the bottom quartile of IQ, compared to 5 percent from the top quartile. When we subdivide welfare recipients into two groups, “temporary” and “chronic,” the link persists, though differently for the two groups. Among women who received welfare temporarily, low IQ is a powerful risk factor even after the effects of marital status, poverty, age, and socioeconomic background are statistically extracted. For chronic welfare recipiency, the story is more complicated. For practical purposes, white women with above-average cognitive ability or above-average socioeconomic background do not become chronic welfare recipients. Among the restricted sample of low-IQ, low-SES, and relatively uneducated white women who are chronically on welfare, low socioeconomic background is a more powerful predictor than low IQ, even after taking account of whether they were themselves below the poverty line at the time they had their babies.</em></p>
<ul>
<li>Page 232 (location ~ 3543-3554)</li>
</ul>
<p><em>Aid to Families with Dependent Children (AFDC), was created in the mid-1930s. Originally AFDC was a popular idea. No one in the community was a likelier object of sympathy than the young widow with small children to raise, and AFDC seemed to be a way to help her stay home with her children until they were old enough to begin taking care of her in their turn. And if some of the women going on AFDC had not been widowed but abandoned by no-good husbands, most people thought that they should be helped too, though some people voiced concerns that helping such women undermined marriage. But hardly anyone had imagined that never-married women would be eligible for AFDC. It came as a distressing surprise to Frances Perkins, the first woman cabinet member and a primary sponsor of the legislation, to find that they were.1 But not only were they eligible; within a few years after AFDC began, they constituted a large and growing portion of the caseload. This created much of the general public’s antagonism toward AFDC: It wasn’t just the money, it was the principle of the thing. Why should hardworking citizens support immorality? Such complaints about welfare go far back into the 1940s and even the 1930s, but, at least from our perspective in the 1990s, it was much ado about a comparatively small problem, as the next figure shows. After a slow and meandering rise since the end of World War II, the welfare caseload was still less than 2 percent of families when John F. Kennedy took office.</em></p>
<ul>
<li>Page 232 (location ~ 3558-3569)</li>
</ul>
<p><em>Welfare mothers have been estimated to have reading skills that average three to five years below grade level.3 Poor reading skills and little schooling define populations with lower-than-average IQ, so even without access to IQ tests, it can be deduced that welfare mothers have lower-than-average intelligence. But can it be shown that low IQ has an independent link with welfare itself, after taking account of the less direct links via being poor and being an unwed mother?4 By a direct link, we mean something like this: The smarter the woman is, the more likely she will be able to find a job, the more likely she will be able to line up other sources of support (from parents or the father of the child), and the more farsighted she is likely to be about the dangers of going on welfare. Even within the population of women who go on welfare, cognitive ability will vary, and the smarter ones will be better able to get off. No database until the NLSY has offered the chance to test these hypotheses in detail for a representative population. We begin as usual with a look at the unadorned relationship with cognitive class. Use of welfare is uncommon but not rare among these white mothers, as the table below shows. Overall, 12 percent of the white mothers in the NLSY received welfare within a year of the birth of their first child; 9 percent had become chronic recipients by our definition of chronic welfare recipients (meaning that they had reported at least five years of welfare income). Overall, 21 percent of white mothers had received assistance from AFDC at some point in their lives.</em></p>
<ul>
<li>Page 234 (location ~ 3584-3596)</li>
</ul>
<p><em>Which White Women Go on Welfare After the Birth of the First Child? Percentage of Mothers Who Went on AFDC Within a Year of First Birth Cognitive Class Percentage of Mothers Who Became Chronic Welfare Recipients 1 I Very bright ” 4 II Bright 2 12 III Normal 8 21 IV Dull 17 55 V Very dull 31 12 Overall average 9 * Sample = 17, with no one qualifying as a chronic welfare recipient. Minimum sample reported: 25.</em></p>
<ul>
<li>Page 235 (location ~ 3600-3614)</li>
</ul>
<p><em>For that reason, the analysis that yielded the figure below extracted the effects of the marital status of the mother and whether she was below the poverty line in the year before birth, in addition to the usual three variables.</em></p>
<ul>
<li>Page 237 (location ~ 3624-3625)</li>
</ul>
<p><em>The dependent variable is whether the mother received welfare benefits during the year after the birth of her first child. As the black line indicates, cognitive ability predicts going on welfare even after the effects of marital status and poverty have been extracted. This finding is worth thinking about, for it is not intuitively predictable. Presumably much of the impact of low intelligence on being on welfare—the failure to look ahead, to consider consequences, or to get an education—is already captured in the fact that the woman had a baby out of wedlock. Other elements of competence, or lack of it, are captured in the fact that the woman was poor before the baby was born. Yet holding the effects of age, poverty, marital status, and parental SES constant, a white woman with an IQ at the 2d centile had a 47 percent chance of going on welfare, compared to the 8 percent chance facing a white woman at the 98th centile.</em></p>
<ul>
<li>Page 237 (location ~ 3625-3632)</li>
</ul>
<p><em>The white women who had met our definition of chronic welfare recipient in the NLSY by the 1990 interview fit this profile to some extent. For example, of the white women who gave birth to an illegitimate baby before they were 19 (that is, they probably got pregnant before they would normally have graduated from high school) and stayed single, 22 percent became chronic welfare recipients by our definition—a high percentage compared to women at large. On the other hand, 22 percent is a long way from 100 percent. Even if we restrict the criteria further so that we are talking about single teenage mothers who were below the poverty line, the probability of becoming a chronic welfare recipient goes up only to 28 percent. To get an idea of how restricted the population of chronic welfare mothers is, consider the 152 white women in the NLSY who met our definition of a chronic welfare recipient and also had IQ scores. None of them was in Cognitive Class I, and only five were even in Class II. Only five had parents in the top quartile in socioeconomic class. One lone woman of the 152 was from the top quartile in ability and from the top quartile in socioeconomic background. White women with above-average cognitive ability or socioeconomic background rarely become chronic welfare recipients.</em></p>
<ul>
<li>Page 238 (location ~ 3649-3658)</li>
</ul>
<p><em>The Role of Education White chronic welfare recipients are virtually all women with modest education at best, as set out in the next table. More than half of the chronic welfare recipients had not gotten a high school diploma; only six-tenths of 1 percent had gotten a college education. As in the case of IQ and socioeconomic status, this is a radically unrepresentative sample of white women.10 It is obviously impossible (as well as unnecessary) to analyze chronic welfare recipiency among college graduates.</em></p>
<ul>
<li>Page 240 (location ~ 3671-3675)</li>
</ul>
<p><em>Why? Apparently the women who did not finish high school and had an illegitimate child were selected for low intelligence, especially if they had the child while still in high school.12 The average IQ of these women was about 91, and analysis tells us that further variation in cognitive ability does not have much power to predict which ones become chronic welfare cases.13 Instead, for this narrowly screened group of women, family background matters more. Without trying to push the analysis much further, a plausible explanation is that for most white American parents, having a school-aged child go on welfare is highly stigmatizing to them.</em></p>
<ul>
<li>Page 241 (location ~ 3689-3694)</li>
</ul>
<p><em>As social scientists often do, we have spent much effort burrowing through analyses that ultimately point to simple conclusions. Here is how a great many parents around America have put it to their daughters: Having a baby without a husband is a dumb thing to do. Going on welfare is an even dumber thing to do, if you can possibly avoid it. And so it would seem to be among the white women in the NLSY. White women who remained childless or had babies within marriage had a mean IQ of 105. Those who had an illegitimate baby but never went on welfare had a mean IQ of 98. Those who went on welfare but did not become chronic recipients had a mean IQ of 94. Those who became chronic welfare recipients had a mean IQ of 92.15 Altogether, almost a standard deviation separated the IQs of white women who became chronic welfare recipients from those who remained childless or had children within marriage. In Chapter 8, we demonstrated that a low IQ is a factor in illegitimate births that cannot be explained away by the woman’s socioeconomic background, a broken family, or poverty at the time the child was conceived. In particular, poor women of low intelligence seemed especially likely to have illegitimate babies, which is consistent with the idea that the prospect of welfare looms largest for women who are thinking least clearly about their futures.</em></p>
<ul>
<li>Page 242 (location ~ 3703-3713)</li>
</ul>
<p><em>Everyone agrees, in the abstract and at the extremes, that there is good parenting and poor parenting. This chapter addresses the uncomfortable question: Is the competence of parents at all affected by how intelligent they are? It has been known for some time that socioeconomic class and parenting are linked, both to disciplinary practices and to the many ways in which the intellectual and emotional development of the child are fostered. On both counts, parents with higher socioeconomic status look better. At the other end of the parenting continuum, neglect and abuse are heavily concentrated in the lower socioeconomic classes. Whenever an IQ measure has been introduced into studies of parent-child relationships, it has explained away much of the differences that otherwise would have been attributed to education or social class, but the examples are sparse. The NLSY provides an opportunity to fill in a few of the gaps. With regard to prenatal and infant care, low IQ among the white mothers in the NLSY sample was related to low birth weight, even after controlling for socioeconomic background, poverty, and age of the mother. In the NLSY’s surveys of the home environment, mothers in the top cognitive classes provided, on average, better environments for children than the mothers in the bottom cognitive classes. Socioeconomic background and current poverty also played significant roles, depending on the specific type of measure and the age of the children.</em></p>
<ul>
<li>Page 243 (location ~ 3723-3734)</li>
</ul>
<p><em>To put it more plainly, Kohn found that working-class parents were more likely to use physical punishment impulsively, when the parents themselves needed the relief, not when it was likely to do the child the most good. The middle-class way sounds like “better” behavior on the part of parents, not just a neutral socioeconomic difference in parenting style, and this raises a point that scholars on child development bend over backward to avoid saying explicitly: Generally, and keeping in mind the many exceptions, the conclusion to be drawn from the literature on parenting is that middle-class people are in fact better parents, on average, than working-class people. Readers who bridle at this suggestion are invited to reread the Kohn quotation above and ask themselves whether they can avoid making a value judgment about it. Parenting differences among the social classes are not restricted to matters of discipline. Other major differences show up in the intellectual development of the child. Anthropologist Shirley Brice Heath6 gives vivid examples in her description of parenting in “Roadville,” a white lower-class community in the Carolinas, versus “Gateway,” a nearby community of white middle-class parents.7 The parents of Roadville were just as devoted to their children as the parents of Gateway.</em></p>
<ul>
<li>Page 247 (location ~ 3779-3789)</li>
</ul>
<p><em>the center of attention as Gateway babies. But the interactions differed, Heath found. Take bedtime stories, for example. In middle-class Gateway, the mother or father encouraged the children to ask questions and talk about what the stories meant, pointing at items on the page and asking what they were. The middle-class parents praised right answers and explained what was wrong with wrong ones.8 It is no great stretch to argue, as Robert Sternberg and others do, that this interaction amounts to excellent training for intelligence tests. Lower-class Roadville parents did not do nearly as much of that kind of explaining and asking.9 When the children were learning to do new tasks, the Roadville</em></p>
<ul>
<li>Page 248 (location ~ 3791-3797)</li>
</ul>
<p><em>Roadville newborns came home to nurseries complete with the same mobiles, pictures, and books that the Gateway babies had. From an early age, Roadville children were held on laps and read to, talked to, and otherwise made as much the center of attention as Gateway babies. But the interactions differed, Heath found. Take bedtime stories, for example. In middle-class Gateway, the mother or father encouraged the children to ask questions and talk about what the stories meant, pointing at items on the page and asking what they were. The middle-class parents praised right answers and explained what was wrong with wrong ones.8 It is no great stretch to argue, as Robert Sternberg and others do, that this interaction amounts to excellent training for intelligence tests. Lower-class Roadville parents did not do nearly as much of that kind of explaining and asking.9 When the children were learning to do new tasks, the Roadville parents did not explain the “how” of things the way the Gateway parents did. Instead, the Roadville parents were more likely to issue directives (“Don’t twist the cookie cutter”) and hardly ever gave reasons for their instructions (“If you twist the cutter, the cookies will be rough on the edge”).10 When they got to school, the Roadville and Gateway children continued to differ. The working-class Roadville children performed well in the early tasks of each of the first three grades. They knew the alphabet when they went to kindergarten; they knew how to sit still in class and could perform well in the reading exercises that asked them to identify specific portions of words or to link two items on the same page of the book. But if the teacher asked, “What did you like about the story?” or “What would you have done if you had been the child in that story?” the Roadville children were likely to say “I don’t know” or shrug their shoulders, while the middle-class Gateway children would more often respond easily and imaginatively.</em></p>
<ul>
<li>Page 248 (location ~ 3790-3805)</li>
</ul>
<p><em>To this point, we have been talking about parenting within the normal range. Now we turn to child neglect and child abuse, increasingly labeled “malparenting” in the technical literature. Abuse and neglect are distinct. The physical battering and other forms of extreme physical and emotional punishment that constitute child abuse get most of the publicity, but child neglect is far more common, by ratios ranging from three to one to ten to one, depending on the study.13 Among the distinctions that the experts draw between child abuse and neglect are these: • Abuse is an act of commission, while neglect is more commonly an act of omission. • Abuse is typically episodic and of short duration; neglect is chronic and continual. • Abuse typically arises from impulsive outbursts of aggression and anger; neglect arises from indifference, inattentiveness, or being overwhelmed by parenthood.14 Commonly, neglect is as simple as failure to provide a child with adequate food, clothing, shelter, or hygiene. But it can also mean leaving dangerous materials within reach, not keeping the child away from an open window, or leaving toddlers alone for hours at a time. It means not taking the child to a doctor when he is sick or not giving him the medicine the doctor prescribed. Neglect can also mean more subtle deprivations: habitually leaving babies in cribs for long periods, never talking to infants and toddlers except to scold or demand, no smiles, no bedtime stories. At its most serious, neglect becomes abandonment.</em></p>
<ul>
<li>Page 249 (location ~ 3811-3824)</li>
</ul>
<p><em>We realize that once again we are contradicting what everyone knows, which is that “child abuse and neglect afflict all communities, regardless of race, religion, or economic status,” to pick one formulation of this common belief.19 And in a narrow technical sense, such statements are correct, insofar as neglect and abuse are found at every social and economic level, as is every other human behavior. It is also correct that only a small minority of parents among the poor and disadvantaged neglect or abuse their children. But the way such statements are usually treated in the media, by politicians, and by child advocacy groups is to imply that child neglect and abuse are spread evenly across social classes, as if children have about an equal chance of being abused or neglected whether they come from a rich home or a poor one, whether the mother is a college graduate or a high school dropout. And yet from the earliest studies to the present, malparenting has been strongly associated with socioeconomic class. The people who argue otherwise do not offer data to make their case. Instead, they argue that child neglect and abuse are reported when it happens to poor children but not rich ones. Affluent families are believed to escape the reporting net (by using private physicians, for example, who are less likely to report abuse). Social service agencies are said to be reluctant to intervene in affluent families.20 Poor people are likely to be labeled deviant for behaviors that would go unnoted or unremarked in richer neighborhoods.21</em></p>
<ul>
<li>Page 251 (location ~ 3835-3847)</li>
</ul>
<p><em>• A study of twenty abusive or neglectful mothers and ten comparison mothers from inner-city Rochester, New York, found that maltreating and nonmaltreating mothers differed significantly in their judgment about child behavior and in their problem-solving abilities.38 • A clinical psychological study of ten parents who battered their children severely (six of the children died) classified five as having a “high-grade mental deficiency” (mentally retarded), one as dull, and another as below average. The remaining three were classified as above average.39 • A quantitative study of 113 two-parent families in the Netherlands found that parents with a high level of “reasoning complexity” (a measure of cognitive ability) responded to their children more flexibly and sensitively, while those with low levels of reasoning complexity were more authoritarian and rigid, independent of occupation and education.40 The most extensive clinical studies of neglectful mothers have been conducted by Norman Polansky, whose many years of research began with a sample drawn from rural Appalachia, subsequently replicated with an urban Philadelphia sample. He described the typical neglectful mother as follows: She is of limited intelligence (IQ below 70), has failed to achieve more than an eighth-grade education, and has never held . . . employment . . . . She has at best a vague, or extremely limited, idea of what her children need emotionally and physically. She seldom is able to see things from the point of view of others and cannot take their needs into consideration when responding to a conflict they experience.41</em></p>
<ul>
<li>Page 255 (location ~ 3905-3919)</li>
</ul>
<p><em>Another body of literature links neglectful and abusive parents to personality characteristics that have clear links to low cognitive ability.42 The most extensive evidence describes the impulsiveness, inconsistency, and confusion that mark the parenting style of many abusive parents.43 The abusive parents may or may not punish their children more often or severely in the ordinary course of events than other parents (studies differ on this point),44 but the abuse characteristically comes unpredictably, in episodic bursts. Abusive parents may punish a given behavior on one occasion, ignore it on another, and encourage it on a third. The inconsistency can reach mystifying proportions; one study of parent-child interactions found that children in abusing families had about the same chance of obtaining positive reinforcement for aggressive behaviors as for pro-social behaviors.45 The observed inconsistency of abusing parents was quantified in one of the early and classic studies of child abuse by Leontine Young, Wednesday’s Children. By her calculations, inconsistency was the rule in all of the “severe abuse” families in her sample, in 91 percent of the “moderate abuse” families, 97 percent of the “severe neglect” families, and 88 percent of the “moderate neglect” families.46 In one of the most extensive literature reviews of the behavioral and personality dimensions of abusive parents (as of 1985), the author concluded that the main problem was not that abusive parents were attached to punishment as such but that they were simply incompetent as parents.</em></p>
<ul>
<li>Page 256 (location ~ 3922-3935)</li>
</ul>
<p><em>Prenatal Care In most of the ways that are easily measurable, most white women in the different cognitive classes behaved similarly during pregnancy. Almost everyone got prenatal care, and similar proportions in all cognitive classes began getting it in the early months. If we take the NLSY mothers’ self-descriptions at face value, alcohol consumption during pregnancy was about the same across the cognitive classes.50 The risk of miscarriage or a stillbirth was also spread more or less equally across cognitive classes. Smoking was the one big and medically important difference related to maternal intelligence: The smarter the women, the less they smoked while they were pregnant. Fifty-one percent of the women in the bottom two cognitive classes smoked, and 19 percent of them admitted to smoking more than a pack a day. In the top two cognitive classes, only 16 percent of the white women in the NLSY smoked at all, and only 4 percent admitted to smoking more than a pack a</em></p>
<ul>
<li>Page 258 (location ~ 3948-3956)</li>
</ul>
<p><em>Prenatal Care In most of the ways that are easily measurable, most white women in the different cognitive classes behaved similarly during pregnancy. Almost everyone got prenatal care, and similar proportions in all cognitive classes began getting it in the early months. If we take the NLSY mothers’ self-descriptions at face value, alcohol consumption during pregnancy was about the same across the cognitive classes.50 The risk of miscarriage or a stillbirth was also spread more or less equally across cognitive classes. Smoking was the one big and medically important difference related to maternal intelligence: The smarter the women, the less they smoked while they were pregnant. Fifty-one percent of the women in the bottom two cognitive classes smoked, and 19 percent of them admitted to smoking more than a pack a day. In the top two cognitive classes, only 16 percent of the white women in the NLSY smoked at all, and only 4 percent admitted to smoking more than a pack a day.</em></p>
<ul>
<li>Page 258 (location ~ 3948-3956)</li>
</ul>
<p><em>We have been unable to identify any study that uses tested IQ as an explanatory factor, and, with such a rare event as infant mortality, even the NLSY cannot answer our questions satisfactorily. The results certainly suggest that the questions are worth taking seriously. As of the 1990 survey, the NLSY recorded forty-two deaths among children born to white women with known IQ. Some of these deaths were presumably caused by severe medical problems at birth and occurred in a hospital where the mother’s behavior was irrelevant.57 For infants who died between the second and twelfth month (the closest we can come to defining “after the baby had left the hospital”), the mothers of the surviving children tested six points higher in IQ than the mothers of the deceased babies. (The difference for mothers of children who died in the first month was not quite three points and for the mothers of children who were older than 1 year old when they died, virtually zero.) The samples here are too small to analyze in conjunction with socioeconomic status and other variables.</em></p>
<ul>
<li>Page 263 (location ~ 4023-4030)</li>
</ul>
<p><em>The Role of Preexisting Poverty When we ask whether the mother was in poverty in the year prior to birth, it turns out that a substantial amount of the effect we attribute to socioeconomic background in the figure really reflects whether the mother was already in poverty when the child was born. If you want to know whether a child will spend his first three years in poverty, the single most useful piece of information is whether the mother was already living under the poverty line when he was born. Nevertheless, adding poverty to the equation does not diminish a large independent role for cognitive ability. A child born to a white mother who was living under the poverty line but was of average intelligence had almost a 49 percent chance of living his first three years in poverty. This is an extraordinarily high chance of living in poverty for American whites as a whole.</em></p>
<ul>
<li>Page 264 (location ~ 4043-4050)</li>
</ul>
<p><em>The mothers were questioned about their children’s</em></p>
<ul>
<li>Page 265 (location ~ 4061-4061)</li>
</ul>
<p><em>In the case of the HOME index, the percentages of white children of mothers in the different cognitive classes who are growing up in homes that scored at the bottom are displayed in the table above. It was extremely rare for children of women in the top cognitive classes to grow up in these “worst homes” and quite uncommon for children of women throughout the top three-fourths of the IQ distribution. Only in the bottom cognitive classes did the proportion of such children grow, and then the proportions rose rapidly. Nearly one out of four of the children of the dullest mothers was growing up in a home that also ranked in the bottom decile on the HOME index.</em></p>
<ul>
<li>Page 267 (location ~ 4093-4097)</li>
</ul>
<p><em>The Role of Poverty and Welfare Many of the problems experienced by poor children are usually attributed in both public dialogue and academic writings to poverty itself.64 The reasons for this widely assumed link between poverty and developmental problems are harder to spell out than you might think. To repeat a point that must always be kept in mind when thinking about poverty: Most of the world’s children throughout history have grown up poor, with “poverty” meaning material deprivation far more severe than the meaning of “below the poverty line” in today’s America. Many of the disadvantages today’s children experience are not the poverty itself but the contemporary correlates of poverty: being without a father, for example, or living in high-crime neighborhoods. Today, high proportions of poor children experience these correlates; fifty years ago, comparatively few poor children did. But there are reasons to think that the HOME index might be influenced by poverty. Reading to children is a good thing to do, for example, and raises the HOME score, but children’s books are expensive. It is easier to have books in the house if you can afford to buy them than if you have to trek to the library—perhaps quite far from home—to get them. Similar comments apply to many of the indicators on the HOME index that do not require wealth but could be affected by very low income. We therefore explored how the HOME index was related to the mother’s poverty or welfare recipiency in the calendar year before the HOME score was obtained.65 Poverty proved to be important, with “being in a state of poverty” raising the odds of being in the worst decile of the HOME index from 4 percent to 11 percent, given a mother of average IQ and socioeconomic status.</em></p>
<ul>
<li>Page 268 (location ~ 4109-4123)</li>
</ul>
<p><em>In trying to decide among competing explanations, the simplest thing to do is to enter both poverty and welfare in the analysis and see which wins out. We summarize the outcome by first considering a child whose mother is of average intelligence and socioeconomic background. If his mother is either poor or on welfare (but not both), the odds of having a terrible home environment (bottom decile on the HOME index) are 8 or 9 percent. If the mother has an IQ of 70, the odds shoot up to 18 to 21 percent. If the mother has very low intelligence, is poor, and is also on welfare, the odds rise further, to 34 percent. A table with some of the basic permutations is given in the note.67 Still, many of the causal issues remain unresolved.</em></p>
<ul>
<li>Page 270 (location ~ 4130-4136)</li>
</ul>
<p><em>In trying to decide among competing explanations, the simplest thing to do is to enter both poverty and welfare in the analysis and see which wins out. We summarize the outcome by first considering a child whose mother is of average intelligence and socioeconomic background. If his mother is either poor or on welfare (but not both), the odds of having a terrible home environment (bottom decile on the HOME index) are 8 or 9 percent. If the mother has an IQ of 70, the odds shoot up to 18 to 21 percent. If the mother has very low intelligence, is poor, and is also on welfare, the odds rise further, to 34 percent. A table with some of the basic permutations is given in the note.</em></p>
<ul>
<li>Page 270 (location ~ 4130-4135)</li>
</ul>
<p><em>The pattern shown in the figure generally applies to the four development indicators separately: IQ has a somewhat larger independent effect than socioeconomic background, but of modest size and marginal statistical significance. The Role of Poverty, Welfare, and Illegitimacy We repeated the analyses adding a poverty variable (Was the mother living in poverty in the year the developmental measures were taken?), a welfare variable (Was the mother on AFDC in the year the developmental measures were taken?), and legitimacy variable (Was the child born outside marriage?) When entered separately or in combination, each had a statistically significant independent role.69 Consider the stark contrast between a child born to an unmarried mother, on welfare and in poverty, and a child born to a married mother, not on welfare and above the poverty line. Given a mother with average IQ and socioeconomic background, the chances that the first child had a substantial developmental problem were almost twice as high as those facing the second child—15 percent compared to 8 percent. But taking these factors into account did not wipe out the independent role of either IQ or the mother’s socioeconomic background; in fact, the independent effects of IQ and socioeconomic background after extracting the independent role of poverty, illegitimacy, and welfare, are visually almost indistinguishable from the one shown above.</em></p>
<ul>
<li>Page 276 (location ~ 4221-4231)</li>
</ul>
<p><em>The Role of Education None of the children in the bottom decile of IQ had a mother with a bachelor’s degree. In the high school graduate sample, the independent role of the mother’s IQ remains large and the independent role of socioeconomic background remains small. But in the process of exploring this issue, we came upon an effect of education that is worth exploring: Women who did not complete high school were at much higher risk of producing children in the bottom decile of IQ than women in the high school sample (meaning a high school diploma and exactly 12 years of education), even after controlling for mother’s IQ and socioeconomic background. Additional analyses did not clarify what this finding might mean; we commend it to our colleagues for a full-scale analysis.</em></p>
<ul>
<li>Page 280 (location ~ 4282-4288)</li>
</ul>
<p><em>The Role of Education None of the children in the bottom decile of IQ had a mother with a bachelor’s degree. In the high school graduate sample, the independent role of the mother’s IQ remains large and the independent role of socioeconomic background remains small. But in the process of exploring this issue, we came upon an effect of education that is worth exploring: Women who did not complete high school were at much higher risk of producing children in the bottom decile of IQ than women in the high school sample (meaning a high school diploma and exactly 12 years of education), even after controlling for mother’s IQ and socioeconomic background. Additional analyses did not clarify</em></p>
<ul>
<li>Page 280 (location ~ 4282-4287)</li>
</ul>
<p><em>Most Americans think that crime has gotten far too high. But in the ruminations about how the nation has reached this state and what might be done, too little attention has been given to one of the best-documented relationships in the study of crime: As a group, criminals are below average in intelligence. As with so many of the other problems discussed in the previous six chapters, things were not always so bad. Good crime statistics do not go back very far in the United States, but we do not need statistics to remind Americans alive in the 1990s of times when they felt secure walking late at night, alone, even in poor neighborhoods and even in the nation’s largest cities. In the mid-1960s, crime took a conspicuous turn for the worse. The overall picture using the official statistics is shown in the figure below, expressed as multiples of the violent crime rate in 1950. The figure shows the kind of crime that worries most people most viscerally: violent crime, which consists of robbery, murder, aggravated assault, and rape. From 1950 through 1963, the rate for violent crime was almost flat, followed by an extremely rapid rise from 1964 to 1971, followed by continued increases until the 1980s. The early 1980s saw an interlude in which violent crime decreased noticeably. But the trend-line for 1985-1992 is even steeper than the one for 1963-1980, making it look as if the lull was just that—a brief respite from an increase in violent crime that is now thirty years old.</em></p>
<ul>
<li>Page 282 (location ~ 4317-4328)</li>
</ul>
<p><em>The juvenile delinquents in Leonard Bernstein’s West Side Story tell Officer Krupke that they are “depraved on account of we’re deprived,” showing an astute grasp of the poles in criminological theory: the psychological and the sociological.3 Are criminals psychologically distinct? Or are they ordinary people responding to social and economic circumstances? Theories of criminal behavior were mostly near the sociological pole from the 1950s through the 1970s. Its leading scholars saw criminals as much like the rest of us, except that society earmarks them for a life of criminality. Some of these scholars went further, seeing criminals as free of personal blame, evening up the score with a society that has victimized them. The most radical theorists from the sociological pole argued that the definition of crime was in itself ideological, creating “criminals” of people who were doing nothing more than behaving in ways that the power structure chose to define as deviant. In their more moderate forms, sociological explanations continue to dominate public discourse. Many people take it for granted, for example, that poverty and unemployment cause crime—classic sociological arguments that are distinguished more by their popularity than by evidence.4 Theories nearer the psychological pole were more common earlier in the history of criminology and have lately regained acceptance among experts. Here, the emphasis shifts to the characteristics of the offender rather than to his circumstances. The idea is that criminals are distinctive in psychological (perhaps even biological) ways. They are deficient, depending on the particular theory, in conscience or in self-restraint. They lack normal attachment to the mores of their culture, or they are peculiarly indifferent to the feelings or the good opinion of others. They are overendowed with restless energy or with a hunger for adventure or danger. In a term that was in common use throughout the nineteenth and early twentieth centuries, chronic offenders may be suffering from “moral insanity.”</em></p>
<ul>
<li>Page 283 (location ~ 4338-4353)</li>
</ul>
<p><em>But even if crime is admitted to be a psychological phenomenon, why should intelligence be important? What is the logic that might lead us to expect low intelligence to be more frequently linked with criminal tendencies than high intelligence is?9 One chain of reasoning starts from the observation that low intelligence often translates into failure and frustration in school and in the job market. If, for example, people of low intelligence have a hard time finding a job, they might have more reason to commit crimes as a way of making a living. If people of low intelligence have a hard time acquiring status through the ordinary ways, crime might seem like a good alternative route. At the least, their failures in school and at work may foster resentment toward society and its laws. Perhaps the link between crime and low IQ is even more direct. A lack of foresight, which is often associated with low IQ, raises the attractions of the immediate gains from crime and lowers the strength of the deterrents, which come later (if they come at all). To a person of low intelligence, the threats of apprehension and prison may fade to meaninglessness. They are too abstract, too far in the future, too uncertain.</em></p>
<ul>
<li>Page 287 (location ~ 4389-4398)</li>
</ul>
<p><em>Low IQ may be part of a broader complex of factors. An appetite for danger, a stronger-than-average hunger for the things that you can get only by stealing if you cannot buy them, an antipathy toward conventionality, an insensitivity to pain or to social ostracism, and a host of derangements of various sorts, combined with low IQ, may set the stage for a criminal career. Finally, there are moral considerations. Perhaps the ethical principles for not committing crimes are less accessible (or less persuasive) to people of low intelligence. They find it harder to understand why robbing someone is wrong, find it harder to appreciate the values of civil and cooperative social life, and are accordingly less inhibited from acting in ways that are hurtful to other people and to the community at large. With these preliminaries in mind, let us explore the thesis that, whatever the underlying reasons might be, the people who lapse into criminal behavior are distinguishable from the population at large in their distribution of intelligence.</em></p>
<ul>
<li>Page 287 (location ~ 4398-4406)</li>
</ul>
<p><em>Even in the 1920s, the link was called into question, for example, by psychologist Carl Murchison, who produced data showing that the prisoners of Leavenworth had a higher mean IQ than that of enlisted men in World War I.12 Then in 1931, Edwin Sutherland, America’s most prominent criminologist, wrote “Mental Deficiency and Crime,” an article that effectively put an end to the study of IQ and crime for half a century.13 Observing (accurately) that the ostensible IQ differences between criminals and the general population were diminishing as testing procedures improved, Sutherland leaped to the conclusion that the remaining differences would disappear altogether as the state of the art improved. The difference, in fact, did not disappear, but that did not stop criminology from denying the importance of IQ as a predictor of criminal behavior. For decades, criminologists who followed Sutherland argued that the IQ numbers said nothing about a real difference in intelligence between offenders and nonoffenders. They were skeptical about whether the convicts in prisons were truly representative of offenders in general, and they disparaged the tests’ validity. Weren’t tests just measuring socioeconomic status by other means, and weren’t they biased against the people from the lower socioeconomic classes or the minority groups who were most likely to break the law for other reasons? they asked. By the 1960s, the association between intelligence and crime was altogether dismissed in criminology textbooks, and so it remained until recently. By the end of the 1970s, students taking introductory courses in criminology could read in one widely used textbook that the belief in a correlation between low intelligence and crime “has almost disappeared in recent years as a consequence of more cogent research findings,”14 or learn from another standard textbook of “the practical abandonment of feeblemindedness as a cause of crime.”</em></p>
<ul>
<li>Page 288 (location ~ 4414-4429)</li>
</ul>
<p><em>The Size of the IQ Gap How big is the difference between criminals and the rest of us? Taking the literature as a whole, incarcerated offenders average an IQ of about 92, 8 points below the mean. The population of nonoffenders averages more than 100 points; an informed guess puts the gap between offenders and nonoffenders at about 10 points.19 More serious or more chronic offenders generally have lower scores than more casual offenders.20 The eventual relationship between IQ and repeat offending is already presaged in IQ scores taken when the children are 4 years old.21 Not only is there a gap in IQ between offenders and nonoffenders, but a disproportionately large fraction of all crime is committed by people toward the low end of the scale of intelligence. For example, in a twenty-year longitudinal study of over 500 hundred boys in an unidentified Swedish community, 30 percent of all arrests of the men by the age of 30 were of the 6 percent with IQs below 77 (at the age of 10) and 80 percent were of those with IQs below 100.</em></p>
<ul>
<li>Page 290 (location ~ 4439-4449)</li>
</ul>
<p><em>Do the Unintelligent Ones Commit More Crimes—or Just Get Caught More Often? Some critics continue to argue that offenders whose IQs we know are unrepresentative of the true criminal population; the smart ones presumably slipped through the net. Surely this is correct to some degree. If intelligence has anything to do with a person’s general competence, then it is not implausible that smart criminals get arrested less often because they pick safer crimes or because they execute their crimes more skillfully.25 But how much of a bias does this introduce into the data? Is there a population of uncaught offenders with high IQs committing large numbers of crimes? The answer seems to be no. The crimes we can trace to the millions of offenders who do pass through the criminal justice system and whose IQs are known account for much of the crime around us, particularly the serious crime. There is no evidence for any other large population of offenders, and barely enough crime left unaccounted for to permit such a population’s existence. In the small amount of data available, the IQs of uncaught offenders are not measurably different from the ones who get caught.26 Among those who have criminal records, there is still a significant negative correlation between IQ and frequency of offending.27 Both of these kinds of evidence imply that differential arrests of people with varying IQs, assuming they exist, are a minor factor in the aggregate data.</em></p>
<ul>
<li>Page 291 (location ~ 4453-4465)</li>
</ul>
<p><em>The Role of a Broken Home When people think about the causes of crime, they usually think not only of the role of juvenile delinquent’s age and socioeconomic background but also of what used to be called “broken homes.” It is now an inadequate phrase, because many families do not even begin with a married husband and wife, and many broken homes are reconstituted (in some sense) through remarriage. But whatever the specific way in which a home is not intact, the children of such families are usually more likely to get in trouble with the law than children from intact families.</em></p>
<ul>
<li>Page 300 (location ~ 4593-4597)</li>
</ul>
<p><em>Although family setting had an impact on crime, it did not explain away the predictive power of IQ. For example, a young man from a broken family and an average IQ and socioeconomic background had a 4 percent chance of having been interviewed in jail. Switch his IQ to the 2d centile, and the odds rise to 22 percent. (Switch his socioeconomic background to the 2d centile instead, and the odds rise only from 4 to 5 percent.) The same conclusions apply to the measure of self-reported crime.</em></p>
<ul>
<li>Page 301 (location ~ 4602-4605)</li>
</ul>
<p><em>Most manifestations of civility are too fleeting to be measured and studied. One realm of activity that does leave measurable traces is political involvement, which includes both participation in political activities and some knowledge and sophistication about them. For assessing any relationship between political involvement and IQ, the best data, surprisingly, are from studies of children, and the results are consistent: Brighter children of all socioeconomic classes, including the poorest, learn more rapidly about politics and how government works, and are more likely than duller children to read about, discuss, and participate in political activities. The gap between brighter and duller children in political development widens with age, unlike the static gap across socioeconomic classes.</em></p>
<ul>
<li>Page 303 (location ~ 4639-4645)</li>
</ul>
<p><em>The NLSY does not have the data for pursuing this manifestation of civility, but it permits us to explore another aspect of it: To what extent is high intelligence associated with the behaviors associated with “middle-class values”? The answer is that the brighter young people of the NLSY are also the ones whose lives most resemble a sometimes disdained stereotype: They stick with school, are plugging away in the workforce, and are loyal to their spouse. Insofar as intelligence helps lead people to behave in these ways, it is also a force for maintaining a civil society.</em></p>
<ul>
<li>Page 304 (location ~ 4650-4654)</li>
</ul>
<p><em>America’s political system relies on the civility of its citizens—“civility” not in the contemporary sense of mere politeness but according to an older meaning which a dictionary close at hand defines as “deference or allegiance to the social order befitting a citizen.”1 The wording of the definition is particularly apt in the American case. Civility is not obedience but rather “allegiance” and “deference”—words with old and honorable meanings that are now largely lost. The object of these sentiments is not the government but a social order. And these things are required not of a subject but of a citizen. Taken together, the elements of civility imply behavior that is both considered and considerate—precisely the kind of behavior that the Founders relied upon to sustain their creation, though they would have been more likely to use the word virtue than civility.2 The point is that, given such civility, a free society as envisioned by the Founders is possible. “Civil-ized” people do not need to be tightly constrained by laws or closely monitored by the organs of state. Lacking such civility, they do, and society must over time become much less free. That is why civility was relevant to the Founders’ vision of a free society and also why it remains relevant today.</em></p>
<ul>
<li>Page 304 (location ~ 4655-4665)</li>
</ul>
<p><em>Consider the act of voting. We have friends, conscientious in many ways, who do not vote and who even look at us, registering and voting, often at some inconvenience, with bemused superiority. They point out with indisputable accuracy that our ballots account for less than a millionth of the overall outcome of most statewide elections, not to mention national ones, and that no major political contest in United States history has ever been decided by a single vote.3 Are we behaving irrationally by voting?4 Not if we value civility. In thinking about what it means to vote, a passage in Aristotle’s Politics comes to mind. “Man is by nature a political animal,” Aristotle wrote, “and he who by nature and not by mere accident is without a state, is either a bad man or above humanity; he is like the ‘tribeless, lawless, hearthless one,’ whom Homer denounces.”5 The polling place is a sort of civic hearth. In the aggregate (though not always in every instance) those who do not vote, or who vote less consistently, are weaker in this manifestation of civility than those who do vote consistently. Think inwardly about why you try to keep up with issues that affect your neighborhood or at least try to do some cramming as an election approaches, and why you usually manage to get to the polling place when the election arrives (or feel guilty when you do not). Are we wrong to assume that the reasons have something to do with a consciousness of the duties of being a citizen and good neighbor? Therein lies the modest claim we make here. There is nothing particularly virtuous or civil about being a political activist, but the simpler ways in which we carry on the</em></p>
<ul>
<li>Page 306 (location ~ 4681-4694)</li>
</ul>
<p><em>Consider the act of voting. We have friends, conscientious in many ways, who do not vote and who even look at us, registering and voting, often at some inconvenience, with bemused superiority. They point out with indisputable accuracy that our ballots account for less than a millionth of the overall outcome of most statewide elections, not to mention national ones, and that no major political contest in United States history has ever been decided by a single vote.3 Are we behaving irrationally by voting?4 Not if we value civility. In thinking about what it means to vote, a passage in Aristotle’s Politics comes to mind. “Man is by nature a political animal,” Aristotle wrote, “and he who by nature and not by mere accident is without a state, is either a bad man or above humanity; he is like the ‘tribeless, lawless, hearthless one,’ whom Homer denounces.”5 The polling place is a sort of civic hearth.</em></p>
<ul>
<li>Page 306 (location ~ 4681-4689)</li>
</ul>
<p><em>Younger children tended to see the government in terms of individuals (government = the current president) and as a fixed and absolute entity; older children were better informed, were more likely to think in terms of institutions instead of individuals, and had a clearer sense of the duties of citizenship. The higher a child’s socioeconomic background, the more rapidly his political socialization proceeded. Among the dimensions most affected by socioeconomic status—again, no surprise—was a child’s sense of political efficacy.8 The big surprise in the study was the impact of IQ, which was larger than that of socioeconomic status. Brighter children from even the poorest households and with uneducated parents learned rapidly about politics, about how the government works, and about the possibilities for change. They were more likely to discuss, read about, and participate in political activities than intellectually slower children were. Not only was the gap in political development across cognitive classes larger than the gap across socioeconomic classes, it tended to widen with age, while the gap due to socioeconomic class did not—an important distinction in trying to understand the comparative roles of intelligence and socioeconomic status.</em></p>
<ul>
<li>Page 308 (location ~ 4710-4719)</li>
</ul>
<p><em>When we are able to look behind the isolated vote to broader kinds of political behavior, the same relationship prevails. The landmark study on this topic was conducted by Sidney Verba and Norman Nie, who polled several thousand people representing the national population in 1967 not only about their voting but also about other political activities—campaigning, demonstrating, contacting officials, and so on.16 Verba and Nie identified six categories of political activity, from “totally inactive” at one end to the “totally active” at the other, with four gradations in between. Almost without exception, however political participation was defined, socioeconomic status was not only a significant predictor in a statistical sense, but the differences across classes were large.17 Among the totally inactive (the lowest category), people were almost six times as likely to be from the bottom third in socioeconomic status as from the top third; among the totally active (the highest category), more than four times as many were from the top third as from the bottom third. In between the extremes of political participation, the trends were unbroken and smooth: The higher the level of participation, the more likely the person was from a high-status background; the lower the level of participation, the more likely the person was from a low-status background.</em></p>
<ul>
<li>Page 310 (location ~ 4750-4761)</li>
</ul>
<p><em>A college education raised a person’s probability of voting almost 40 percentage points over what it would be if the person had less than five years of education, independent of income or occupational status; postgraduate education raised it even more. Even for people in the top income category (more than $75,000 per year in 1990 dollars) a college education added 34 percentage points to a person’s probability of voting. Occupational status per se had an even smaller overall effect than income, and it was ambiguous to boot. For example, with education held constant, sales and clerical workers voted at slightly higher rates than professionals or managers.</em></p>
<ul>
<li>Page 311 (location ~ 4766-4771)</li>
</ul>
<p><em>Some of the more cynical dismissals of American political life are similarly answered. Poor and humble workers, it is sometimes argued, are disenfranchised whether they vote or not, because the government does the bidding of the rich and well placed. It is small wonder, then, that they do not vote, this argument continues. But the evidence shows it is not so much the poor and humble who fail to vote; it is the uneducated. It may be easy to believe that the poor are disenfranchised, but it is less obvious why it should be the uneducated (poor or not). What is the cynic to make of the fact that an underpaid but well-educated shop clerk is more likely to vote than a less educated, rich businessman?</em></p>
<ul>
<li>Page 313 (location ~ 4792-4796)</li>
</ul>
<p><em>Our focus on education and intelligence similarly gives insufficient attention to other personal traits that influence political participation.33 People vary in their sense of civic duty and in the strength of their party affiliations, apart from their educational or intellectual level; their personal values color their political allegiances and how intensely they are felt. Their personalities are expressed not just in personal life but also in their political actions (or inactions). The bottom line, then, is not that political participation is simple to describe but that, despite its complexity, so narrow a range of individual factors carries so large a burden of explanation. For example, the zero-order correlations between intelligence and the fourteen political dimensions in the study of high school students described above ranged from .01 to .53, with an average of .22; the average correlation with the youngsters’ socioeconomic background was</em></p>
<ul>
<li>Page 315 (location ~ 4820-4828)</li>
</ul>
<p><em>Our focus on education and intelligence similarly gives insufficient attention to other personal traits that influence political participation.33 People vary in their sense of civic duty and in the strength of their party affiliations, apart from their educational or intellectual level; their personal values color their political allegiances and how intensely they are felt. Their personalities are expressed not just in personal life but also in their political actions (or inactions). The bottom line, then, is not that political participation is simple to describe but that, despite its complexity, so narrow a range of individual factors carries so large a burden of explanation. For example, the zero-order correlations between intelligence and the fourteen political dimensions in the study of high school students described above ranged from .01 to .53, with an average of .22; the average correlation with the youngsters’ socioeconomic background was .09.</em></p>
<ul>
<li>Page 315 (location ~ 4820-4828)</li>
</ul>
<p><em>For many years, “middle-class values” has been a topic of debate in American public life. Many academic intellectuals hold middle-class values in contempt. They have a better reputation among the public at large, however, where they are seen—rightly, in our view—as ways of behaving that produce social cohesion and order. To use the language of this chapter, middle-class values are related to civility. Throughout Part II, we have been examining departures from middle-class values: adolescents’ dropping out of school, babies born out of wedlock, men dropping out of the labor force or ending up in jail, women going on welfare. Let us now look at the glass as half full instead of half empty, concentrating on the people who are doing everything right by conventional standards.</em></p>
<ul>
<li>Page 316 (location ~ 4840-4846)</li>
</ul>
<p><em>East Asians (e.g., Chinese, Japanese), whether in America or in Asia, typically earn higher scores on intelligence and achievement tests than white Americans. The precise size of their advantage is unclear; estimates range from just a few to ten points. A more certain difference between the races is that East Asians have higher nonverbal intelligence than whites while being equal, or perhaps slightly lower, in verbal intelligence. The difference in test scores between African-Americans and European-Americans as measured in dozens of reputable studies has converged on approximately a one standard deviation difference for several decades. Translated into centiles, this means that the average white person tests higher than about 84 percent of the population of blacks and that the average black person tests higher than about 16 percent of the population of whites. The average black and white differ in IQ at every level of socioeconomic status (SES), but they differ more at high levels of SES than at low levels. Attempts to explain the difference in terms of test bias have failed. The tests have approximately equal predictive force for whites and blacks.</em></p>
<ul>
<li>Page 321 (location ~ 4909-4918)</li>
</ul>
<p><em>The first thing to remember is that the differences among individuals are far greater than the differences between groups. If all the ethnic differences in intelligence evaporated overnight, most of the intellectual variation in America would endure. The remaining inequality would still strain the political process, because differences in cognitive ability are problematic even in ethnically homogeneous societies. The chapters in Part II, looking only at whites, should have made that clear. But the politics of cognitive inequality get hotter—sometimes too hot to handle—when they are attached to the politics of ethnicity. We believe that the best way to keep the temperature down is to work through the main facts carefully and methodically. This chapter first reviews the evidence bearing on ethnic differences in cognitive ability, then turns to whether the differences originate in genes or in environments. At the chapter’s end, we summarize what this knowledge about ethnic differences means in practical terms. We frequently use the word ethnic rather than race, because race is such a difficult concept to employ in the American context.1 What does it mean to be “black” in America, in racial terms, when the word black (or African-American) can be used for people whose ancestry is more European than African? How are we to classify a person whose parents hail from Panama but whose ancestry is predominantly African? Is he a Latino? A black? The rule we follow here is to classify people according to the way they classify themselves. The studies of “blacks” or “Latinos” or “Asians” who live in America generally denote people who say they are black, Latino, or Asian—no more, no less.</em></p>
<ul>
<li>Page 323 (location ~ 4938-4951)</li>
</ul>
<p><em>People from Latin America wish to be known according to their national origin: Cuban-American, Mexican-American, Puerto Rican, and so forth. Hispanic is still the U.S. government’s official label, but Latino has gained favor in recent years. We use Latino. Opting for common usage and simplicity, we usually use black instead of African-American and white (which always refers to non-Latino whites) instead of European-American or Anglo. Americans of Asian descent are called Asian when the context leaves no possibility of confusion with Asians living in Asia. We shift to the hyphenated versions for everyone when it would avoid such confusions or when, for stylistic reasons, the hyphenated versions seem appropriate.</em></p>
<ul>
<li>Page 323 (location ~ 4953-4958)</li>
</ul>
<p><em>The NLSY is not much help on this issue. The sample contained only forty-two East Asians (Chinese, Japanese, and Koreans). Their mean IQ was 106, compared to the European-American white mean of 103, consistent with the evidence that East Asians have a higher IQ than whites but based on such a small sample that not much can be made of it. The indeterminancy of the debate is predictable. The smaller the IQ difference, the more questionable its reality, and this has proved to be the case with the East Asian—white difference. It is difficult enough to find two sets of subjects within a single city who can be compared without problems of interpretation. Can one compare test scores obtained in different years with different tests for students of different ages in different cultural settings, drawn from possibly different socioeconomic populations? One answer is that it can be done through techniques that take advantage of patterns observed over many studies. Lynn in particular has responded to each new critique, in some cases providing new data, in others refining earlier estimates, and always pointing to the striking similarity of the results despite the disparity of the tests and settings.</em></p>
<ul>
<li>Page 326 (location ~ 4993-5001)</li>
</ul>
<p><em>In the text we focus on three major racial-ethnic groupings—whites, East Asians, and blacks—because they have dominated both the research and contentions regarding intelligence. But whenever the subject of group differences in IQ comes up, three other questions are sure to be asked: Are Jews really smarter than everyone else? Where do Latinos fit in, compared to whites and blacks? What about women versus men? Jews—specifically, Ashkenazi Jews of European origins—test higher than any other ethnic group.16 The literature indicates that Jews in America and Britain have an overall IQ mean somewhere between a half and a full standard deviation above the mean, with the source of the difference concentrated in the verbal component. In the NLSY, ninety-eight whites with IQ scores identified themselves as Jews. The NLSY did not try to ensure representativeness within ethnic groups other than blacks and Latinos, so we cannot be sure that the ninety-eight Jews in the sample are nationally representative. But it is at least worth noting that their mean IQ was .97 standard deviation above the mean of the rest of the population and .84 standard deviation above the mean of whites who identified themselves as Christian.</em></p>
<ul>
<li>Page 328 (location ~ 5026-5035)</li>
</ul>
<p><em>Answering the question “How large is the difference?” in terms of standard deviations does not convey an intuitive sense of the size of the gap. A rough-and-ready way of thinking about the size of the gap is to recall that one standard deviation above and below the mean cuts off the 84th and 16th percentiles of a normal distribution. In the case of the B/W difference of 1.2 standard deviations found in the NLSY, a person with the black mean was at the 11th percentile of the white distribution, and a person with the white mean was at the 91st percentile of the black distribution. A difference of this magnitude should be thought of in several different ways, each with its own important implications. Recall first that the American black population numbers more than 30 million people. If the results from the NLSY apply to the total black population as of the 1990s, around 100,000 blacks fall into Class I of our five cognitive classes, with IQs of 125 or higher.26 One hundred thousand people is a lot of people. It should be no surprise to see (as one does every day) blacks functioning at high levels in every intellectually challenging field. It is important to understand as well that a difference of 1.2 standard deviations means considerable overlap in the cognitive ability distribution for blacks and whites, as shown for the NLSY population in the figure below. For any equal number of blacks and whites, a large proportion have IQs that can be matched up. This is the distribution to keep in mind whenever thinking about individuals.</em></p>
<ul>
<li>Page 332 (location ~ 5085-5097)</li>
</ul>
<p><em>Predictive bias can work in another way, as when the test is simply less reliable—that is, less accurate—for blacks than for whites. Suppose a test used to select police sergeants is more accurate in predicting the performance of white candidates who become sergeants than in predicting the performance of black sergeants. It doesn’t underpredict for blacks, but rather fails to predict at all (or predicts less accurately). In these cases, the natural remedy would be to give less weight to the test scores of blacks than to those of whites. The key concept for both types of bias is the same: A test biased against blacks does not predict black performance in the real world in the same way that it predicts white performance in the real world. The evidence of bias is external in the sense that it shows up in differing validities for blacks and whites. External evidence of bias has been sought in hundreds of studies. It has been evaluated relative to performance in elementary school, in secondary school, in the university, in the armed forces, in unskilled and skilled jobs, in the professions. Overwhelmingly, the evidence is that the major standardized tests used to help make school and job decisions27 do not underpredict black performance, nor does the expert community find any other general or systematic difference in the predictive accuracy of tests for blacks and whites.</em></p>
<ul>
<li>Page 334 (location ~ 5118-5128)</li>
</ul>
<p><em>Studies comparing blacks and whites on various kinds of IQ tests find that the B/W difference is not created by items that ask about regattas or who wrote Hamlet, or any of the other similar examples cited in criticisms of tests. How can this be? The explanation is complicated and goes deep into the reasons why a test item is “good” or “bad” in measuring intelligence. Here, we restrict ourselves to the conclusion: The B/W difference is wider on items that appear to be culturally neutral than on items that appear to be culturally loaded. We italicize this point because it is both so well established empirically yet comes as such a surprise to most people who are new to this topic. We will elaborate on this finding later in the chapter. In any case, there is no longer an important technical debate over the conclusion that the cultural content of test items is not the cause of group differences in scores.</em></p>
<ul>
<li>Page 337 (location ~ 5154-5161)</li>
</ul>
<p><em>The two parts of the subtest have identical content. They occur at the same time during the test. Each subject does both. But in most studies the black-white difference is about twice as great on backward digits as on forward digits.34 The question arises: How can lack of motivation (or test willingness or any other explanation of that type) explain the difference in performance on the two parts of the same subtest?35 A similar question arises from work on reaction time. Several psychometricians, led by Arthur Jensen, have been exploring the underlying nature of g by hypothesizing that neurologic processing speed is implicated, akin to the speed of the microprocessor in a computer. Smarter people process faster than less smart people. The strategy for testing the hypothesis is to give people extremely simple cognitive tasks—so simple that no conscious thought is involved—and to use precise timing methods to determine how fast different people perform these simple tasks. One commonly used apparatus involves a console with a semicircle of eight lights, each with a button next to it. In the middle of the console is the “home” button. At the beginning of each trial, the subject is depressing the home button with his finger. One of the lights in the semicircle goes on. The subject moves his finger to the button closest to the light, which turns it off. There are more complicated versions of the task (three lights go on, and the subject moves to the one that is farthest from the other two, for example), but none requires much thought, and everybody gets almost every trial “right.” The subject’s response speed is broken into two measurements: reaction time (RT), the time it takes the subject to lift his finger from the home button after a target light goes on, and movement time (MT), the time it takes to move the finger from just above the home button to the target button.36 Francis Galton in the nineteenth century believed that reaction time is associated with intelligence but could not prove it. He was on the right track after all. In modern studies, reaction time is correlated with the results from full-scale IQ tests; even more specifically, it is correlated with the g factor in IQ tests—in some studies, only with the g factor.37 Movement time is much less correlated with IQ or with g.38 This makes sense: Most of the cognitive processing has been completed by the time the finger leaves the home button; the rest is mostly a function of small motor skills.</em></p>
<ul>
<li>Page 338 (location ~ 5177-5198)</li>
</ul>
<p><em>The consistent result of many studies is that white reaction time is faster than black reaction time, but black movement time is faster than white movement time.39 One can imagine an unmotivated subject who thinks the reaction time test is a waste of time and does not try very hard. But the level of motivation, whatever it may be, seems likely to be the same for the measures of RT and MT. The question arises: How can one be unmotivated to do well during one split-second of a test but apparently motivated during the next split-second? Results of this sort argue against easy explanations that appeal to differences in motivation as explanatory of the B/W difference.</em></p>
<ul>
<li>Page 340 (location ~ 5199-5204)</li>
</ul>
<p><em>First version: If you extract the effects of socioeconomic class, what happens to the overall magnitude of the B/W difference? Blacks are disproportionately in the lower socioeconomic classes, and socioeconomic class is known to be associated with IQ. Therefore, many people suggest, part of what appears to be an ethnic difference in IQ scores is actually a socioeconomic difference. The answer to this version of the question is that the size of the gap shrinks when socioeconomic status is statistically extracted. The NLSY gives a result typical of such analyses. The B/W difference in the NLSY is 1.21. In a regression equation in which both race and socioeconomic background are entered, the difference between whites and blacks shrinks to .76 standard deviation.40 Socioeconomic status explains 37 percent of the original B/W difference. This relationship is in line with the results from many other studies.41 The difficulty comes in interpreting what it means to “control” for socioeconomic status. Matching the status of the groups is usually justified on the grounds that the scores people earn are caused to some extent by their socioeconomic status, so if we want to see the “real” or “authentic” difference between them, the contribution of status must be excluded.42 The trouble is that socioeconomic status is also a result of cognitive ability, as people of high and low cognitive ability move to correspondingly high and low places in the socioeconomic continuum. The reason that parents have high or low socioeconomic status is in part a function of their intelligence, and their intelligence also affects the IQ of the children via both genes and environment.</em></p>
<ul>
<li>Page 342 (location ~ 5231-5245)</li>
</ul>
<p><em>the remaining difference is not necessarily more real or authentic than the one we start with. This seems to be a hard point to grasp, judging from the pervasiveness of controlling for socioeconomic status in the sociological literature on ethnic differences. But suppose we were asking whether blacks and whites differed in sprinting speed, and controlled for “varsity status” by examining only athletes on the track teams in Division I colleges. Blacks would probably still sprint faster than whites on the average, but it would be a smaller difference than in the population at large. Is there any sense in which this smaller difference would be a more accurate measure of the racial difference in sprinting ability than the larger difference in the general population? We pose that as an interesting theoretical issue. In terms of numbers, a reasonable rule of thumb is that controlling for socioeconomic status reduces the overall B/W difference by about a third.</em></p>
<ul>
<li>Page 343 (location ~ 5247-5254)</li>
</ul>
<p><em>How Do African-Americans Compare with Blacks in Africa on Cognitive Tests? This question often arises in the context of black-white comparisons in America, the thought being that the African black population has not been subjected to the historical legacy of American black slavery and discrimination and might therefore have higher scores. Many studies of African students in primary and secondary schools, in both urban and rural areas, have included cognitive ability tests. As in the United States, it has been demonstrated in Africa that the same test items that discriminate best among blacks discriminate best among whites and that the same factors that depress white scores (for example, coming from a rural area) depress black scores. The predictive validity of tests for academic and job performance seems to be about the same. In general, the psychometric properties of the standardized tests are the same for blacks living in Africa as for American blacks.44</em></p>
<ul>
<li>Page 344 (location ~ 5267-5275)</li>
</ul>
<p><em>It has been more difficult to assemble data on the score of the average African black than one would expect, given the extensiveness of the test experience in Africa. In the same review of the literature that permitted the above generalizations, for example—a thirty-page article followed by a bibliography of more than 200 titles—not a single average is reported.45 One reason for this reluctance to discuss averages is that blacks in Africa, including urbanized blacks with secondary educations, have obtained extremely low scores. Richard Lynn was able to assemble eleven studies in his 1991 review of the literature. He estimated the median black African IQ to be 75, approximately 1.7 standard deviations below the U.S. overall population average, about ten points lower than the current figure for American blacks.46 Where other data are available, the estimates of the black African IQ fall at least that low and, in some instances, even lower.47 The IQ of “coloured” students in South Africa—of mixed racial background—has been found to be similar to that of American blacks.</em></p>
<ul>
<li>Page 344 (location ~ 5275-5284)</li>
</ul>
<p><em>From 1976 to 1993, the white-black gap in SAT scores narrowed from 1.16 to .88 standard deviation in the verbal portion of the test and from 1.27 to .92 standard deviation in the mathematics portion of the test.54 Comparable narrowing has also brought black and white achievement test scores closer, as presented in Appendix 5. Because the ethnic self-identification of SAT test takers contains some anomalies55 and because the SAT pool is unrepresentative of the general population, the numbers should be interpreted with caution. But even so, the SAT data indicate a narrowing gap. Black SAT test takers improved substantially more in scores than white SAT test takers, and neither the changes in the pool of test takers nor the well-advertised national decline in SAT scores was responsible, for reasons explained in the notes.56</em></p>
<ul>
<li>Page 348 (location ~ 5323-5330)</li>
</ul>
<p><em>EXPLAINING THE CONVERGENCE. Let us assume that during the past two decades black and white cognitive ability as measured by IQ has in fact converged by an amount that is consistent with the convergence in educational aptitude measures such as the SAT or NAEP—a narrowing of approximately .15 to .25 standard deviation units, or the equivalent of two to three IQ points overall.57 Why have the scores converged? The answer calls for speculation. We take for granted that individual variations in cognitive ability depend on both genes and environment (see Chapter 4). In a period as short as twenty years, environmental changes are likely to provide the main reason for the narrowing racial gap in scores.58 Real and important though the problems of the underclass are, and acknowledging that the underclass is disproportionately black, living conditions have improved for most African-Americans since the 1950s—socially, economically, and educationally. Consider the schools that blacks attend, for example. Some schools in the inner cities are worse than they were thirty years ago, but proportionately few blacks live in these worst-of-the-worst areas.</em></p>
<ul>
<li>Page 348 (location ~ 5331-5341)</li>
</ul>
<p><em>The argument can be repeated for public health. If nutrition, shelter, and health care affect intellectual development, then rising standards of living are disproportionately going to show up in rising scores for the economically disadvantaged rather than for the upper classes. For travel and its educational benefits, the argument also applies. Not so long ago, many less advantaged people spent their lives within a few miles of their birthplaces. Today, Americans of nearly all walks of life crowd the interstate roads and the airports. Finally, for that most contemporary form of vicarious travel—the popular media—the leveling is still more dramatic. The modern media can bring the world to everyone in ways that were once open only to the rich. Because blacks are shifted toward the lower end of the socioeconomic range, such improvements benefit them, on average, more than whites. If the improvements affect cognitive development, the black-white gap should have contracted. Beyond this socioeconomic leveling, there might also have been a leveling due to diminishing racism. The legacy of historic racism may still be taking its toll on cognitive development, but we must allow the possibility that it has lessened, at least for new generations. This too might account for some narrowing of the black-white gap.</em></p>
<ul>
<li>Page 349 (location ~ 5345-5354)</li>
</ul>
<p><em>One explanation for the stalled convergence on the NAEP and SAT is that American education stopped improving for everyone, blacks included. This is consistent with the white experience on the SAT, where white scores have also been nearly flat since the mid-1980s. But the logic is suspect. Just because a group at a higher mean stops improving does not imply that a group with a lower mean should also stop improving. On the contrary, pessimists can develop a case that the convergence of black and white SAT scores in the last two decades is symptomatic of what happens when education slows down toward the speed of the slowest ship in the convoy. It may well be that education improves for students at the low end of the distribution but gets worse (or, more optimistically, improves less) for students at the top end.62 If that is the case, the gap between people at the low and high end of the distribution should narrow, but the narrowing will stop once the educational system completes its readjustment favoring less capable students.</em></p>
<ul>
<li>Page 350 (location ~ 5366-5374)</li>
</ul>
<p><em>The real source of the black increase of twenty-three points in the average verbal test score from 1980 to 1993 was a rise in the scores at the low end of the range. More than half (51 percent) of the gain occurred because the proportion of black students scoring in the 200s dropped from 42 percent to 30 percent.66 In contrast, less than 1 percent (0.4 percent) of the gain occurred because of the change in the proportion of black students scoring in the 700s. For the math test, 22 percent of the gain from 1980 to 1993 was accounted for by a drop in students scoring in the 200s; 4 percent of it was accounted for by an increase in students scoring in the 700s. Pessimists reading these data may think of an analogy with the increases in height that follow from better nutrition: Better nutrition helps raise the height of children whose diets would otherwise have been inadequate, but it does not add anything to the height of those who have been receiving a good diet already.67 Optimists may use the opposite sort of nutritional analogy: the experience of trying to lose weight. Even a successful diet has its plateaus, when the weight stubbornly stops coming off for a while. A plateau is all that we are seeing</em></p>
<ul>
<li>Page 351 (location ~ 5379-5388)</li>
</ul>
<p><em>The real source of the black increase of twenty-three points in the average verbal test score from 1980 to 1993 was a rise in the scores at the low end of the range. More than half (51 percent) of the gain occurred because the proportion of black students scoring in the 200s dropped from 42 percent to 30 percent.66 In contrast, less than 1 percent (0.4 percent) of the gain occurred because of the change in the proportion of black students scoring in the 700s. For the math test, 22 percent of the gain from 1980 to 1993 was accounted for by a drop in students scoring in the 200s; 4 percent of it was accounted for by an increase in students scoring in the 700s. Pessimists reading these data may think of an analogy with the increases in height that follow from better nutrition: Better nutrition helps raise the height of children whose diets would otherwise have been inadequate, but it does not add anything to the height of those who have been receiving a good diet already.67 Optimists may use the opposite sort of nutritional analogy: the experience of trying to lose weight. Even a successful diet has its plateaus, when the weight stubbornly stops coming off for a while. A plateau is all that we are seeing in recent test data. Perhaps convergence will resume or even accelerate in the near future.</em></p>
<ul>
<li>Page 351 (location ~ 5379-5389)</li>
</ul>
<p><em>Expert opinion, when it is expressed at all, diverges widely. In the 1980s, Mark Snyderman and Stanley Rothman, a psychologist and a political scientist, respectively, sent a questionnaire to a broad sample of 1,020 scholars, mostly academicians, whose specialties give them reason to be knowledgeable about IQ.68 Among the other questions, they asked, “Which of the following best characterizes your opinion of the heritability of the black-white difference in IQ?” (emphasis in the questionnaire item). The answers were divided as follows: • The difference is entirely due to environmental variation: 15 percent. • The difference is entirely due to genetic variation: 1 percent. • The difference is a product of both genetic and environmental variation: 45 percent. • The data are insufficient to support any reasonable opinion: 24 percent. • No response: 14 percent. The responses reveal the degree of uncertainty within the scientific community about where the truth lies. We have considered leaving the genetics issue at that, on grounds that no useful purpose is served by talking about a subject that is so inflammatory, so painful, and so far from resolution. We could have cited any number of expert reassurances that genetic differences among ethnic groups are not worth worrying about.</em></p>
<ul>
<li>Page 352 (location ~ 5396-5407)</li>
</ul>
<p><em>He goes on to make three arguments. First, the very concept of race is illegitimate, given the extensiveness of interbreeding and the imprecise nature of most of the traits that people think of as being “racial.” Second, the division of races is recent, occurring only in the last tens or perhaps hundreds of thousands of years, limiting the amount of time that groups of humans could have taken separate evolutionary paths. Third, developments in genetics demonstrate that the genetic differences among human beings are minor. “We now know that our usual metaphor of superficiality—skin deep—is literally accurate,” Gould writes.71 He concludes: “Say it five times before breakfast tomorrow; more important, understand it as the center of a network of implication: ‘Human equality [i.e., equality among the races] is a contingent fact of history.’”72 Our difficulty with this position is not that Gould (or others who make similar arguments) is wrong about the blurred lines between the races, or about how long the races have been separated, or about the number of genes that are racially distinctive. All his facts can be true, and yet people who call themselves Japanese or Xhosa or Caucasians or Maori can still differ intellectually for genetic reasons. We may call them “ethnic groups” instead of races if we wish—we too are more comfortable with ethnic, because of the blurred lines—but some ethnic groups nonetheless differ genetically for sure, otherwise they would not have differing skin colors or hair textures or muscle mass. They also differ intellectually on the average. The question remaining is whether the intellectual differences overlap the genetic differences to any extent.</em></p>
<ul>
<li>Page 354 (location ~ 5414-5427)</li>
</ul>
<p><em>We further stipulate that one standard deviation (fifteen IQ points) separates American blacks and whites and that a fifth of a standard deviation (three IQ points) separates East Asians and whites. Finally, we assume that IQ is 60 percent heritable (a middle-ground estimate). Given these parameters, how different would the environments for the three groups have to be in order to explain the observed difference in these scores? The observed ethnic differences in IQ could be explained solely by the environment if the mean environment of whites is 1.58 standard deviations better than the mean environment of blacks and .32 standard deviation worse than the mean environment for East Asians, when environments are measured along the continuum of their capacity to nurture intelligence.76 Let’s state these conclusions in percentile terms: The average environment of blacks would have to be at the 6th percentile of the distribution of environments among whites, and the average environment of East Asians would have to be at the 63rd percentile of environments among whites, for the racial differences to be entirely environmental. Environmental differences of this magnitude and pattern are implausible. Recall further that the B/W difference (in standardized units) is smallest at the lowest socioeconomic levels. Why, if the B/W difference is entirely environmental, should the advantage of the “white” environment compared to the “black” be greater among the better-off and better-educated blacks and whites? We have not been able to think of a plausible reason. An appeal to the effects of racism to explain ethnic differences also requires explaining why environments poisoned by discrimination and racism for some other groups—against the Chinese or the Jews in some regions of America, for example—have left them with higher scores than the national average.</em></p>
<ul>
<li>Page 356 (location ~ 5457-5471)</li>
</ul>
<p><em>East Asians living overseas score about the same or slightly lower than whites on verbal IQ and substantially higher on visuospatial IQ. Even in the rare studies that have found overall Japanese or Chinese IQs no higher than white IQs (e.g., the Stevenson study of Japanese, Taiwanese, and Minnesotans mentioned earlier),77 the discrepancy between verbal and visuospatial IQ persists. For Japanese living in Asia, a 1987 review of the literature demonstrated without much question that the verbal-visuospatial difference persists even in examinations that have been thoroughly adapted to the Japanese language and, indeed, in tests developed by the Japanese themselves.78 A study of a small sample of Korean infants adopted into white families in Belgium found the familiar elevated visuospatial scores.79 This finding has an echo in the United States, where Asian-American students abound in engineering, in medical schools, and in graduate programs in the sciences, but are scarce in law schools and graduate programs in the humanities and social sciences. Most people reflexively assume that this can be explained by language differences. People who did not speak English as their first language or who grew up in households where English was not the language of choice choose professions that are not so dependent on fluent English, we often hear. But the explanation becomes less credible with every passing year. Philip Vernon, after reviewing the evidence on Asian-Americans, concluded that unfamiliarity with the English language and American culture is a plausible explanation only for the results of the early studies. Contemporary studies of Asian-Americans who are thoroughly acculturated also show the typical discrepancy in verbal and visuospatial abilities.</em></p>
<ul>
<li>Page 358 (location ~ 5487-5501)</li>
</ul>
<p><em>On average, low-SES whites get lower test scores than high-SES whites. But suppose you were to go through a large set of white test scores from a low-SES and a high-SES group and pull out everyone with an overall IQ score of, say, 105. Now you have identical scores but very different SES groups. The question becomes, What does the pattern of subtest scores look like? The answer is, The same. Once you equalize the overall IQ scores, low-SES and high-SES whites also had close-to-identical mean scores on the individual subtests. Now do the same exercise with blacks and whites. Again, let us say that you pull all the tests with a full-scale IQ score of exactly 105. Again, you examine the scores on the subtests. But this time the pattern of subtest scores is not the same for blacks and whites, even though the subtests add up to the identical overall score.87 Despite identical overall scores, whites are characteristically stronger than blacks on the subtests involving spatial-perceptual ability, and blacks are characteristically stronger than whites in subtests such as arithmetic and immediate memory, both of which involve retention and retrieval of information.88 As Jensen and Reynolds note, the pattern of subtest differences between whites and blacks differs sharply from the “no differences” result associated with SES. This directly contradicts the hypothesis that the B/W difference reflects primarily SES differences.89 What accounts for the different subtest profiles? Jensen and Reynolds proceeded to demonstrate that the results are consistent with Spearman’s hypothesis. Whites and blacks differ more on the subtests most highly correlated with g, less on those least correlated with g.</em></p>
<ul>
<li>Page 361 (location ~ 5527-5541)</li>
</ul>
<p><em>Jensen’s most recent work on Spearman’s hypothesis uses reaction time tests instead of traditional mental tests, bypassing many of the usual objections to intelligence test questions. Once again, the more g-loaded the activity is, the larger the B/W difference is, on average.93 Critics can argue that the entire enterprise is meaningless because g is meaningless, but the hypothesis of a correlation between the magnitude of the g-loading of a test and the magnitude of the black-white difference on that test has been confirmed.94 How does the confirmation of Spearman’s hypothesis bear on the genetic explanation of ethnic differences? In plain though somewhat imprecise language: The broadest conception of intelligence is embodied in g. Anything other than g is either a narrower cognitive capacity or measurement error. Spearman’s hypothesis says in effect that as mental measurement focuses most specifically and reliably on g, the observed black-white mean difference in cognitive ability gets larger.95 At the same time, g or other broad measures of intelligence typically have relatively high levels of heritability.96 This does not in itself demand a genetic explanation of the ethnic difference, but by asserting that “the better the test, the greater the ethnic difference,” Spearman’s hypothesis undercuts many of the environmental explanations of the difference that rely on the proposition (again, simplifying) that the apparent black-white difference is the result of bad tests, not good ones.</em></p>
<ul>
<li>Page 362 (location ~ 5548-5561)</li>
</ul>
<p><em>In some countries, the upward drift since World War II has been as much as a point a year for some spans of years. The national averages have in fact changed by amounts that are comparable to the fifteen or so IQ points separating whites and blacks in America. To put it another way, on the average, whites today may differ in IQ from whites, say, two generations ago as much as whites today differ from blacks today. Given their size and speed, the shifts in time necessarily have been due more to changes in the environment than to changes in the genes.</em></p>
<ul>
<li>Page 369 (location ~ 5656-5660)</li>
</ul>
<p><em>RACIAL ANCESTRY. Just over 100 families with adopted children of white, black, and mixed racial ancestry are being studied in an ongoing analysis of the effects of being raised by white adopting parents of middle or higher social status.123 This famous transracial adoption study by psychologists Sandra Scarr and Richard Weinberg is the most comprehensive attempt yet to separate the effects of genes and of family environment on the cognitive development of American blacks and whites. The first reports (when the children were about 7 years old) indicated that the black and interracial children had IQs of about 106, well above the national black average or the black average in Minnesota, where the samples were drawn. This result pointed to a considerable impact of the home setting on intelligence. However, a racial and adoptive ordering on IQ existed even in the first follow-up: The mean IQs were 117 for the biological children of white parents, 112 for the white adoptive children, 109 for the adopted children with one black and one white or Asian parent, and 97 for the adopted children with two black parents.124 Altogether, the data were important and interesting but not decisive regarding the source of the B/W difference. They could most easily have been squared with a theory that the B/W difference has both genetic and environmental elements in it, but, with considerable straining, could perhaps have been stretched to argue for no genetic influence at all.</em></p>
<ul>
<li>Page 371 (location ~ 5685-5697)</li>
</ul>
<p><em>But dissenting voices can be heard in the academic world. For example, a well-known book, Not in Our Genes, by geneticist Richard Lewontin and psychologists Steven Rose and Leon Kamin, criticizes anyone who even suggests that there may be a genetic component to the B/W difference or who reads the data as we do, as tipping toward a mixture of genetic and environmental influences.131 How can they do this? Mostly by emphasizing those aspects of the data that suggest environmental influences, such as the correlations between the adopting parents’ IQs or educational levels and the IQs of their black adopted children in the Minnesota study from the first follow-up (the book was published before the second follow-up). But they have nothing to say about the aspects that are consistent with genetic influence, such as the even larger correlations between the educational level of either the biological mothers or fathers and the IQs of their adopted-away black children.132 Although Lewontin, Rose, and Kamin do not say it in so many words, their argument makes sense if it is directed at the claim that the B/W difference is entirely genetic. It does little to elucidate the ongoing scientific inquiry into whether the difference has a genetic component.</em></p>
<ul>
<li>Page 373 (location ~ 5718-5728)</li>
</ul>
<p><em>It seems highly likely to us that both genes and the environment have something to do with racial differences. What might the mix be? We are resolutely agnostic on that issue; as far as we can determine, the evidence does not yet justify an estimate. We are not so naive to think that making such statements will do much good. People find it next to impossible to treat ethnic differences with detachment. That there are understandable reasons for this only increases the need for thinking clearly and with precision about what is and is not important. In particular, we have found that the genetic aspect of ethnic differences has assumed an overwhelming importance. One symptom of this is that while this book was in preparation and regardless of how we described it to anyone who asked, it was assumed that the book’s real subject had to be not only ethnic differences in cognitive ability but the genetic source of those differences. It is as if people assumed that we are faced with two alternatives: either (1) the cognitive difference between blacks and whites is genetic, which entails unspoken but dreadful consequences, or (2) the cognitive difference between blacks and whites is environmental, fuzzily equated with some sort of cultural bias in IQ tests, and the difference is therefore temporary and unimportant. But those are not the only alternatives. They are not even alternatives at all. The major ethnic differences in the United States are not the result of biased tests in the ordinary sense of the term. They may well include some (as yet unknown) genetic component, but nothing suggests that they are</em></p>
<ul>
<li>Page 374 (location ~ 5734-5746)</li>
</ul>
<p><em>It seems highly likely to us that both genes and the environment have something to do with racial differences. What might the mix be? We are resolutely agnostic on that issue; as far as we can determine, the evidence does not yet justify an estimate. We are not so naive to think that making such statements will do much good. People find it next to impossible to treat ethnic differences with detachment. That there are understandable reasons for this only increases the need for thinking clearly and with precision about what is and is not important. In particular, we have found that the genetic aspect of ethnic differences has assumed an overwhelming importance. One symptom of this is that while this book was in preparation and regardless of how we described it to anyone who asked, it was assumed that the book’s real subject had to be not only ethnic differences in cognitive ability but the genetic source of those differences. It is as if people assumed that we are faced with two alternatives: either (1) the cognitive difference between blacks and whites is genetic, which entails unspoken but dreadful consequences, or (2) the cognitive difference between blacks and whites is environmental, fuzzily equated with some sort of cultural bias in IQ tests, and the difference is therefore temporary and unimportant. But those are not the only alternatives. They are not even alternatives at all. The major ethnic differences in the United States are not the result of biased tests in the ordinary sense of the term. They may well include some (as yet unknown) genetic component, but nothing suggests that they are entirely genetic. And, most important, it matters little whether the genes are involved at all.</em></p>
<ul>
<li>Page 374 (location ~ 5734-5746)</li>
</ul>
<p><em>If it were known that the B/W difference is genetic, would I treat individual blacks differently from the way I would treat them if the differences were environmental? Probably, human nature being what it is, some people would interpret the news as a license for treating all whites as intellectually superior to all blacks. But we hope that putting this possibility down in words makes it obvious how illogical—besides utterly unfounded—such reactions would be. Many blacks would continue to be smarter than many whites. Ethnic differences would continue to be differences in means and distributions; they would continue to be useless, for all practical purposes, when assessing individuals. If you were an employer looking for intellectual talent, an IQ of 120 is an IQ of 120, whether the face is black or white, let alone whether the mean difference in ethnic groups were genetic or environmental. If you were a teacher looking at a classroom of black and white faces, you would have exactly the same information you have now about the probabilities that they would do well or poorly.</em></p>
<ul>
<li>Page 376 (location ~ 5752-5759)</li>
</ul>
<p><em>We cannot think of a legitimate argument why any encounter between individual whites and blacks need be affected by the knowledge that an aggregate ethnic difference in measured intelligence is genetic instead of environmental.</em></p>
<ul>
<li>Page 376 (location ~ 5764-5765)</li>
</ul>
<p><em>the differences are genetic, aren’t they harder to change than if they are environmental? Another common reaction, this one relies on false assumptions about intelligence. The underlying error is to assume that an environmentally caused deficit is somehow less hard-wired, that it has less impact on “real” capabilities, than does a genetically caused deficit. We have made this point before, but it bears repeating. Some kinds of environmentally induced conditions can be changed (lack of familiarity with television shows for a person without a television set will probably be reduced by purchasing him a television set), but there is no reason to think that intelligence is one of them. To preview a conclusion we will document at length in Chapter 17, an individual’s realized intelligence, no matter whether realized through genes or the environment, is not very malleable.</em></p>
<ul>
<li>Page 377 (location ~ 5770-5776)</li>
</ul>
<p><em>Aren’t genetic differences passed down through the generations, while environmental differences are not? Yes and no. Environmentally caused characteristics are by definition not heritable in the narrow technical sense that they do not involve genetic transmission. But nongenetic characteristics can nonetheless run in families. For practical purposes, environments are heritable too. The child who grows up in a punishing environment and thereby is intellectually stunted takes that deficit to the parenting of his children. The learning environment he encountered and the learning environment he provides for his children tend to be similar. The correlation between parents and children is just that: a statistical tendency for these things to be passed down, despite society’s attempts to change them, without any necessary genetic component. In trying to break these intergenerational links, even adoption at birth has its limits. Poor prenatal nutrition can stunt cognitive potential in ways that cannot be remedied after birth. Prenatal drug and alcohol abuse can stunt cognitive potential. These traits also run in families and communities and persist for generations, for reasons that have proved difficult to affect.</em></p>
<ul>
<li>Page 378 (location ~ 5783-5791)</li>
</ul>
<p><em>America’s pressing social problems are often portrayed in ethnic terms. Does the nation have an unemployment problem? It depends. Among whites in the recession year of 1992, unemployment was under seven percent, but it was fourteen percent among blacks.1 Poverty? The poverty rate in 1992 for whites was less than twelve percent but thirty-three percent for blacks.2 Such numbers, and the debate over what they should mean for policy, have been at the center of American social policy since the early 1960s. As Latinos have become a larger portion of the population, the debate has begun to include similar disparities between Latinos and whites. Such disparities are indisputable. The question is why. Surely history plays a role. Open racism and institutional discrimination of less obvious sorts have been an important part of the historical story for blacks and are relevant to the historical experience of Latinos and Asian-Americans as well. Cultural differences may also be involved. An ethnic group with a strong Roman Catholic heritage, such as Latinos, may behave differently regarding birth control and illegitimacy than one without that background. The tradition of filial respect in the Confucian countries may bear on the behavior of American teenagers of East Asian ancestry when one looks at, for example, delinquency.</em></p>
<ul>
<li>Page 380 (location ~ 5826-5836)</li>
</ul>
<p><em>The lower set of bars also presents the probabilities by ethnic group, but with one big difference: Now, the equation used to compute the probability assumes that each of these young adults has a certain IQ level. In this case, the computation assumes that everybody has the average IQ of all college graduates in the NLSY—a little over 114. We find that a 29-year-old (in 1990) with an IQ of 114 had a 50 percent chance of having graduated from college if white, 68 percent if black, and 49 percent if Latino. After taking IQ into account, blacks have a better record of earning college degrees than either whites or Latinos. We discuss this black advantage in Chapter 19, when we turn to the effects of affirmative action.</em></p>
<ul>
<li>Page 383 (location ~ 5868-5873)</li>
</ul>
<p><em>We confirm Gottfredson’s conclusions with data from the NLSY by going back to the high-IQ occupations we discussed in Chapter 2: lawyers, physicians, dentists, engineers, college teachers, accountants, architects, chemists, computer scientists, mathematicians, natural scientists, and social scientists. Grouping all of these occupations together, what chance did whites, blacks, and Latinos in the NLSY have of entering them? The figure below shows the results. Before controlling for IQ and using unrounded figures, whites were almost twice as likely to be in high-IQ occupations as blacks and more than half again as likely as Latinos.10 But after controlling for IQ, the picture reverses. The chance of entering a high-IQ occupation for a black with an IQ of 117 (which was the average IQ of all the people in these occupations in the NLSY sample) was over twice the proportion of whites with the same IQ. Latinos with an IQ of 117 had more than a 50 percent higher chance of entering a high-IQ occupation than whites with the same IQ.11 This phenomenon applies across a wide range of occupations, as discussed in more detail in Chapter 20.</em></p>
<ul>
<li>Page 385 (location ~ 5892-5901)</li>
</ul>
<p><em>The table contains a number of noteworthy particulars, but the most interesting result, which generalizes to every occupational category, is how little difference education makes. A common complaint about wages is that they are artificially affected by credentialism. If credentials are important, then educational differences between blacks and whites should account for much of their income differences. The table, however, shows that knowing the educational level of blacks and whites does little to explain the difference in their wages. Socioeconomic background also fails to explain much of the wage gaps in one occupation after another. That brings us to the final column, in which IQs are controlled while education and socioeconomic background are left to vary as they will. The black-white income differences in most of the occupations shrink considerably. Altogether, the table says that an IQ score is more important—in most cases, much more important—in explaining black-white wage differences than are education and socioeconomic background for every occupational category in</em></p>
<ul>
<li>Page 388 (location ~ 5936-5943)</li>
</ul>
<p><em>The table contains a number of noteworthy particulars, but the most interesting result, which generalizes to every occupational category, is how little difference education makes. A common complaint about wages is that they are artificially affected by credentialism. If credentials are important, then educational differences between blacks and whites should account for much of their income differences. The table, however, shows that knowing the educational level of blacks and whites does little to explain the difference in their wages. Socioeconomic background also fails to explain much of the wage gaps in one occupation after another. That brings us to the final column, in which IQs are controlled while education and socioeconomic background are left to vary as they will. The black-white income differences in most of the occupations shrink considerably. Altogether, the table says that an IQ score is more important—in most cases, much more important—in explaining black-white wage differences than are education and socioeconomic background for every occupational category in it.</em></p>
<ul>
<li>Page 388 (location ~ 5936-5943)</li>
</ul>
<p><em>Although we do not attempt the many analyses that might enrich this basic conclusion, one other factor—gender—is so obvious that we must mention it. When gender is added to the analysis, the black-white differences narrow by one or two additional percentage points for each of the comparisons. In the case of IQ, this means that the racial difference disappears altogether. Controlling for age, IQ, and gender (ignoring education and parental SES), the average wage for year-round black workers in the NLSY sample was 101 percent of the average white wage.</em></p>
<ul>
<li>Page 389 (location ~ 5950-5954)</li>
</ul>
<p><em>If commentators and public policy specialists were looking at a 6 percent poverty rate for whites against 11 percent for blacks—the rates for whites and blacks with IQs of 100 in the lower portion of the graphic—their conclusions might differ from what they are when they see the unadjusted rates of 7 percent and 26 percent in the upper portion. At the least, the ethnic disparities would look less grave. But even after controlling for IQ, the black poverty rate remains almost twice as high as the white rate—still a significant difference.16 Why does this gap persist, like the gap in total family income, while the gaps in educational attainment, occupations, and wages did not? The search for an answer takes us successively further from the things that IQ can explain into ethnic differences with less well understood roots.</em></p>
<ul>
<li>Page 389 (location ~ 5963-5969)</li>
</ul>
<p><em>Scholars are discussing many possible explanations of the poorer job outcomes for black males, some of which draw on the historical experience of slavery, others on the nature of the urbanizing process following slavery, and still others on the structural shifts in the economy in the 1970s, but ethnic differences in IQ are not often included among the possibilities.20 Racism and other historical legacies may explain why controlling for IQ does not eliminate differences in unemployment and dropping out of the labor force, but, if so, we would be left with no evident explanation of why such factors are not similarly impeding the equalization of education, occupational selection, or wages, once IQ is taken into account. With the facts in hand, we cannot distinguish between the role of the usual historical factors that people discuss and the possibility of ethnic differences in whatever other personal attributes besides IQ determine a person’s ability to do well in the job market. We do not know whether ethnic groups differ on the average in these other ways, let alone why they do so if they do. But to the extent that there are such differences, controlling for IQ will not completely wash out the disparities in unemployment and labor force participation. We will not speculate further along these lines here.</em></p>
<ul>
<li>Page 391 (location ~ 5986-5995)</li>
</ul>
<p><em>Historically, the black-white difference in marriage rates was small until the early 1960s and then widened. By 1991, only 38 percent of black women ages 15 to 44 were married, compared to 58 percent of white women.21 In using the NLSY, we will limit the analysis to people who had turned 30 by the time of the 1990 interview. Among this group, 78 percent of whites had married before turning 30 compared to only 54 percent of blacks. The white and Latino marriage rates were only a few percentage points apart. When we add cognitive ability to the picture, not much changes. According to the figure below, only 8 percent of the black-white gap disappears after controlling for IQ, leaving a black with an IQ of 100 with a 58 percent chance of having married by his or her thirtieth birthday, compared to a 79 percent chance for a white with the same IQ. The reasons for this large difference in black and white marriage have been the subject of intense debate that continues as we write. One school of thought argues that structural unemployment has reduced the number of marriageable men for black women, but a growing body of information indicates that neither a shortage of black males nor socioeconomic deprivation explains the bulk of the black-white disparity in marriage.22 As we have just demonstrated, neither does IQ explain much. For reasons that are yet to be fully understood, black America has taken a markedly different stance toward marriage than white and Latino America.</em></p>
<ul>
<li>Page 392 (location ~ 5996-6007)</li>
</ul>
<p><em>Controlling for IQ reduced the Latino-white difference by 44 percent but the black-white difference by only 20 percent. Nor does it change much when we add the other factors discussed in Chapter 8: socioeconomic background, poverty, coming from a broken home, or education. No matter how the data are sliced, black women in the NLSY (and in every other representative database that we know of) have a much higher proportion of children out of wedlock than either whites or Latinos. As we write, the debate over the ethnic disparity in illegitimacy remains as intense and as far from resolution as ever.24 We can only add that ethnic differences in cognitive ability do not explain much of it either.</em></p>
<ul>
<li>Page 393 (location ~ 6021-6026)</li>
</ul>
<p><em>In the national data, blacks are about 3.8 times more likely to be arrested relative to their numbers in the general population than whites (Latino and non-Latino whites are combined in this comparison).36 Blacks are also disproportionately the victims of crime, especially violent crime. The ratio of black homicide victims to white as of 1990 was 7.7 to 1 for men and 4.8 to 1 for women.37 Sociologist Robert Gordon has analyzed black-white differences in crime and concluded that virtually all of the difference in the prevalence of black and white juvenile delinquents is explained by the IQ difference, independent of the effect of socioeconomic status.38 The only reliable indicator from the NLSY that lets us compare criminal behavior across ethnic groups is the percentage of young men who were ever interviewed while incarcerated.39 The figure below shows the standard comparison, before and after controlling for cognitive ability. Among white men, the proportion interviewed in a correctional facility after controlling for age was 2.4 percent; among black men, it was 13.1 percent.</em></p>
<ul>
<li>Page 398 (location ~ 6099-6109)</li>
</ul>
<p><em>We concluded Part II with the Middle Class Values (MCV) Index, which scores a “yes” for those young adults in the NLSY who were still married to their first spouse, in the labor force if they were men, bearing their children within marriage if they were women, and staying out of jail, and scores a “no” for those who failed any of those criteria. Never-married people who met all the other criteria were excluded. The MCV Index, as unsophisticated as it is, has a serious purpose: It captures a set of behaviors that together typify (though obviously do not define) “solid citizens.” Having many such citizens is important for the creation of peaceful and prosperous communities. The figure below shows what happens when the MCV Index is applied to different ethnic groups, first adjusting only for age and then controlling for IQ as well. (In interpreting these data, bear in mind that large numbers of people of all ethnicities who did not score “yes” are leading virtuous and productive lives.) The ethnic disparities remain instructive. Before controlling for IQ, large disparities separate both Latinos and blacks from whites. But given average IQ, the Latino-white difference shrank to three percentage points. The difference between blacks and whites and Latinos remains substantial, though only about half as large as it was before controlling for IQ. This outcome is not surprising, given what we have already shown about ethnic differences on the indicators that go into the MCV Index, but it nonetheless points in a summary fashion to a continuing divergence between blacks and the rest of the American population in some basic social and economic behaviors.</em></p>
<ul>
<li>Page 399 (location ~ 6115-6126)</li>
</ul>
<p><em>A MORE REALISTIC VIEW OF ETHNIC DISPARITIES IN SOCIAL AND ECONOMIC INDICATORS If one of America’s goals is to rid itself of racism and institutional discrimination, then we should welcome the finding that a Latino and white of similar cognitive ability have the same chances of getting a bachelor’s degree and working in a white-collar job. A black with the same cognitive ability has an even higher chance than either the Latino or white of having those good things happen. A Latino, black, and white of similar cognitive ability earn annual wages within a few hundred dollars of one another. Some ethnic differences are not washed away by controlling either for intelligence or for any other variables that we examined. We leave those remaining differences unexplained and look forward to learning from our colleagues where the explanations lie. We urge only that they explore those explanations after they have extracted the role—often the large role—that cognitive ability plays. Similarly, the evidence presented here should give everyone who writes and talks about ethnic inequalities reason to avoid flamboyant rhetoric about ethnic oppression. Racial and ethnic differences in this country are seen in a new light when cognitive ability is added to the picture. Awareness</em></p>
<ul>
<li>Page 400 (location ~ 6128-6138)</li>
</ul>
<p><em>A MORE REALISTIC VIEW OF ETHNIC DISPARITIES IN SOCIAL AND ECONOMIC INDICATORS If one of America’s goals is to rid itself of racism and institutional discrimination, then we should welcome the finding that a Latino and white of similar cognitive ability have the same chances of getting a bachelor’s degree and working in a white-collar job. A black with the same cognitive ability has an even higher chance than either the Latino or white of having those good things happen. A Latino, black, and white of similar cognitive ability earn annual wages within a few hundred dollars of one another. Some ethnic differences are not washed away by controlling either for intelligence or for any other variables that we examined. We leave those remaining differences unexplained and look forward to learning from our colleagues where the explanations lie. We urge only that they explore those explanations after they have extracted the role—often the large role—that cognitive ability plays. Similarly, the evidence presented here should give everyone who writes and talks about ethnic inequalities reason to avoid flamboyant rhetoric about ethnic oppression. Racial and ethnic differences in this country are seen in a new light when cognitive ability is added to the picture. Awareness of these relationships is an essential first step in trying to construct an equitable America.</em></p>
<ul>
<li>Page 400 (location ~ 6128-6138)</li>
</ul>
<p><em>We will refer to this downward pressure as dysgenesis, borrowing a term from population biology. However, it is important once again not to be sidetracked by the role of genes versus the role of environment. Children resemble their parents in IQ, for whatever reason, and immigrants and their descendants may not duplicate the distribution of America’s resident cognitive ability distribution. If women with low scores are reproducing more rapidly than women with high scores, the distribution of scores will, other things equal, decline, no matter whether the women with the low scores came by them through nature or nurture.1 More generally, if population growth varies across the range of IQ scores, the next generation will have a different distribution of scores.2 In trying to foresee changes in American life, what matters is how the distribution of intelligence is changing, more than why.</em></p>
<ul>
<li>Page 402 (location ~ 6163-6170)</li>
</ul>
<p><em>THE EVOLVING UNDERSTANDING OF DYSGENESIS The understanding of dysgenesis has been a contest between pessimists and optimists. For many decades when people first began to think systematically about intelligence and reproduction in the late nineteenth century, all was pessimism. The fertility rate in England began to fall in the 1870s, and it did not take long for early students of demography to notice that fertility was declining most markedly at the upper levels of social status, where the people were presumed to be smarter.3 The larger families were turning up disproportionately in the lower classes. Darwin himself had noted that even within the lower classes, the smaller families had the brighter, the more “prudent,” people in them. All that was needed to conclude that this pattern of reproduction was bad news for the genetic legacy was arithmetic, argued the British scholars around the turn of the twentieth century who wanted to raise the intelligence of the population through a new science that they called eugenics.4 Their influence crossed the ocean to the United States, where the flood of immigrants from Russia, eastern Europe, and the Mediterranean raised a similar concern. Were those huddled masses bringing to our shores a biological inheritance inconsistent with the American way of life? Some American eugenicists thought so, and they said as much to the Congress when it enacted the Immigration Act of 1924, as we described in the Introduction.5 Then came scientific enlightenment—the immigrants did not seem to be harming America’s genetic legacy a bit—followed by the terrors of nazism and its perversion of eugenics that effectively wiped the idea from public discourse in the West.</em></p>
<ul>
<li>Page 403 (location ~ 6174-6188)</li>
</ul>
<p><em>The falling birth rate is a well known and widely studied feature of the demographic transition. What is less well known, but seems to be true among Western cultures that have passed through the demographic transition, is that declines in lifetime fertility occur disproportionately among educated women and women of higher social status (we will refer to such women as “privileged”), just as the Victorians thought.7 Why? One reason is that privileged women lose their reproductive advantage. In premodern times, privileged young women were better nourished, better rested, and had better medical care than the unprivileged. They married earlier and suffered fewer marital disruptions.8 The net result was that, on average, they ended up with more surviving children than did unprivileged women. As modernization proceeds, these advantages narrow. Another reason is that modern societies provide greater opportunities for privileged women to be something other than full-time mothers.</em></p>
<ul>
<li>Page 405 (location ~ 6196-6204)</li>
</ul>
<p><em>The generalizations in the text may be stated with confidence about most communities in the West. Elsewhere, there is still much to be learned. Japan has passed through the demographic transition in that overall fertility has dropped, but reproduction has not shifted as markedly toward the lower end of the scale of privilege as in the Western democracies.11 The reason may be that in Japan, as in other East Asian societies, social obligations that encourage childbearing among the educated may take precedence over the individualistic motives that might otherwise compete with parenthood. Similar considerations may apply to Islamic communities as well, where the demographic transition has been weak. The Mormons offer an American example of a weak demographic transition.12 An account of the patterns of reproduction must consider cultural, personal, religious, and familial factors, as well as the more obvious social variables, such as the rising levels of education, women’s employment, and public health.13</em></p>
<ul>
<li>Page 406 (location ~ 6219-6227)</li>
</ul>
<p><em>If reproductive rates are correlated with income and educational levels, which are themselves correlated with intelligence, people with lower intelligence would presumably be outreproducing people with higher intelligence and thereby producing a dysgenic effect.14 Can we find evidence that dysgenesis is actually happening? The early studies from the United States, England, France, and Greece all seemed to confirm the reality of dysgenesis.15 In the 1930s, the eminent psychometrician Raymond Cattell was predicting a loss of 1.0 to 1.5 IQ points per decade,16 while others were publishing estimated losses of 2 to 4 IQ points per generation.17</em></p>
<ul>
<li>Page 407 (location ~ 6229-6235)</li>
</ul>
<p><em>The optimism proved to be ephemeral. As scholars examined new data and reexamined the original analyses, they found that the optimistic results turned on factors that were ill understood or ignored at the time the studies were published. First, comparisons between successive generations tested with the same instrument (as in the Scottish studies) were contaminated by the Flynn effect, whereby IQ scores (though not necessarily cognitive ability itself) rise secularly over time (see Chapter 13). Second, the samples used in the most-cited optimistic studies published in the 1960s and 1970s were unrepresentative of the national population. Most of them came from nearly all-white populations of states in the upper Midwest.24 Two of the important studies published during this period were difficult to interpret because they were based not only on whites but on males (estimating fertility among males poses numerous problems, and male fertility can be quite different from female fertility) and on samples that were restricted to the upper half of the ability distribution, thereby missing what was going on in the lower half.</em></p>
<ul>
<li>Page 408 (location ~ 6252-6260)</li>
</ul>
<p><em>Demographers often take a lifetime fertility of about 2.1 births as the dividing line between having enough children to replenish the parent generation and having too few.33 Bear that in mind while examining the figure below showing the “completed fertility”—all the babies they have ever had—of American women who had virtually completed their childbearing years in 1992, broken down by their educational attainment. Overall, college graduates had 1.56 children, one child less than the average for women without a high school diploma. Let us consider the ratio of the two fertilities as a rough index of the degree to which fertility is tipped one way or the other with regard to education. A ratio greater than 1.0 says the tip is toward the lower educational levels. The actual ratio is 1.71, which can be read as 71 percent more births among high school dropouts than among women who graduated from college. At least since the 1950s, the ratio in the United States has been between 1.5 and 1.85.34</em></p>
<ul>
<li>Page 412 (location ~ 6303-6311)</li>
</ul>
<p><em>The most recent data available as we write, for 1991, provide modestly good news: The proportions of children born to better-educated women—and therefore higher-IQ women, on average—have been going up in the last decade. The proportion of babies born to women with sixteen or more years of school (usually indicating a college degree or better) rose from 4.8 percent in 1982 to 5.9 percent in 1991. The proportion of babies born to women with something more than a high school diploma rose from 34.2 percent to 38.2 percent—small changes but in the right direction. The bad news is that the proportion of children born to women with less than a high school education has risen slightly over the last decade, from 22 percent to 24 percent, attributable to an especially steep rise among white women since 1986.</em></p>
<ul>
<li>Page 413 (location ~ 6320-6325)</li>
</ul>
<p><em>What of evidence about dysgenesis in the NLSY itself? As of 1990, the women of the NLSY, ages 25 to 33, still had many childbearing years ahead. Presumably the new births will be weighted toward more highly educated women with higher IQs. Therefore the current mean IQ of the mothers of the NLSY children will rise. Currently, however, it stands at less than 96.37</em></p>
<ul>
<li>Page 413 (location ~ 6331-6334)</li>
</ul>
<p><em>The average age at first birth was a few months past the 23d birthday. This varied widely, however, by cognitive class. Combining all the ethnic groups in the NLSY, women in the bottom 5 percent of intelligence have their first baby more than seven years younger than women in the top 5 percent. When these figures are computed for the average age for all births (not just the first birth, as in the table), women in the bottom 5 percent have their babies (or all of the ones they have had by their early thirties) at an average of five and a half years earlier. This gap will grow, not shrink, as the NLSY women complete their childbearing years. Even using the current figures, women in the bottom 5 percent of the IQ distribution will have about five generations for every four generations of the top 5 percent. A large and often ignored dysgenic pressure from differences in age at birth is at work.</em></p>
<ul>
<li>Page 415 (location ~ 6349-6355)</li>
</ul>
<p><em>Fertility Rates by Ethnicity In the 1992 analysis of American fertility using the Current Population Survey (CPS) to which we referred for a national estimate of dysgenesis, women ages 35 to 44 had given birth to an average of 1.94 children: 1.89 for white women, 2.23 for black women, and 2.47 for Latino women.41 Similar or larger ethnic differences have characterized fertility data for as long as such data have been available, and they have led to a widespread belief that something in black and Latino culture leads them to have larger numbers of children than whites do. We do not dispute that culture can influence family size—the Catholic tradition among Latinos may foster high overall birth rates, for example—but the trends for the three groups are similar once the role of educational level is held constant. Consider the figure below, based on the 1992 CPS study of fertility, again using women in the 35 to 44 age group who have nearly completed their childbearing years.</em></p>
<ul>
<li>Page 416 (location ~ 6368-6376)</li>
</ul>
<p><em>May we then conclude that whites, blacks, and Latinos are on a downhill slope together, neither converging nor diverging in IQ? No, for two reasons. The first is that each ethnic group has different proportions of women at different IQ levels. For example, black women with IQs of 90 and below probably have a fertility rate no higher than that of white women with the same IQs. But even so, only 15 percent of white women in the NLSY fall in the 90-and-below range, compared with 52 percent of black women. The relatively higher fertility rates of women with low IQs therefore have a larger impact on the black population as a whole than on the white. Even if two ethnic groups have equal birth rates at a given IQ, one group may have a larger proportion of its babies than the other at that IQ. This is illustrated by the next table, which uses the NLSY to see what the next generation looks like so far, when the women of the NLSY had reached the ages of 25 to 33.</em></p>
<ul>
<li>Page 417 (location ~ 6384-6391)</li>
</ul>
<p><em>The evidence suggests that better-educated women of all ethnic groups postpone childbearing, to similar degrees.43 Based on this experience, the differentials as they exist among ethnic groups in the 25-33 age cohort will probably remain about the same through the rest of the NLSY women’s childbearing years, though the means for each group will probably rise somewhat. Insofar as an artifact exists, it presumably acts to understate the eventual mean for whites, since whites have the largest proportion of women with college and advanced degrees, and therefore presumably the largest group of high-IQ women delaying childbirth.</em></p>
<ul>
<li>Page 419 (location ~ 6411-6416)</li>
</ul>
<p><em>Calculated in this way and shown in the table above, the gap between white and Latino children has shrunk somewhat compared to the gap separating their mothers. The gap between white and black children has at least grown no larger.48 Why can we obtain this result and still show a growing gap in IQ points between the ethnic groups? The answer is that “mean” referred to in “regression to the mean” is the population’s own mean. White children of dull white women will, on average, be closer to the mean for whites in their generation than their mothers were in their generation. A parallel statement applies to black children of dull black women. But this does not necessarily imply that the IQ scores of black and white children must be closer to each other than their mothers’ IQ scores were. It is a slippery concept. Some people find it is helpful to remember that regression to the mean works both ways: If you start with a population of dull children and then find the IQs of their parents, you will find that the parents were closer to the mean (on average) than their children. Regression to the mean is a statistical phenomenon, not a biological one.</em></p>
<ul>
<li>Page 423 (location ~ 6473-6481)</li>
</ul>
<p><em>Applying the assigned IQ means to this breakdown, the mean IQ of immigrants in the 1980s works out to about 95—essentially unchanged from the 1960s and the 1970s (when the same procedure yields estimates of 96 and 95 respectively). As the proportion of non-Latino whites dropped from 46 percent of immigrants in the 1960s to 11 percent in the 1990s, the percentage of East and Southeast Asians rose from 6 percent to 21 percent, two counterbalancing trends regarding IQ. Modifying the estimates of ethnic IQs does not make much difference. Some would argue that the East Asian mean is too high. Suppose we drop it to 100. Some would argue that the Latino mean is too low. Suppose we increase it to 94. We could shift the black estimate up or down by large amounts without affecting the overall mean very far. Fiddling with the numbers moves the overall estimated mean by only about a point or two for defensible sets of values. The basic statement is that about 57 percent of legal immigrants in the 1980s came from ethnic groups that have scores significantly below the white average, and in consequence the IQ mean for all immigrants is likely to be below 100. How about the idea that people who are willing to pack up and move to a strange place in search of a better life are self-selected for desirable qualities such as initiative, determination, energy, and perhaps intelligence as well? Given this plausible expectation, why not assume that the mean for immigrants is significantly higher than average for their ethnic groups? Here, the NLSY provides a snapshot of the effects on the distribution of intelligence of the people coming across our borders, insofar as we may compare the IQs of those who were born abroad with those who were born in the United States. Overall, the IQ of NLSY members who were born abroad was .4 standard deviation lower than the mean of those who were born in the United States, putting the average immigrant for this cohort at about the 34th centile of the native-born population.</em></p>
<ul>
<li>Page 426 (location ~ 6519-6534)</li>
</ul>
<p><em>White immigrants have scores that put them a bit above the mean for the native-born American population (though somewhat lower than the mean for native-born American whites). Foreign-born blacks score about five IQ points higher than native-born blacks, for reasons we do not know. Latino immigrants have mean scores more than seven points lower than native-born Latinos and more than a standard deviation below the overall national native-born mean. The NLSY gives no information on the large immigrant population from the countries of East Asia and Vietnam, who might be significantly boosting the immigrant mean. Even considered simply as cognitive test scores, these results must be interpreted very cautiously. Immigrants typically earn higher scores on tests as they become acculturated, even on tests designed to be “culture fair.”58 The extremely large gap between native-born and foreign-born Latino students seems likely to reflect additional effects of poor English. We do not know if this rise with acculturation is enough to counterbalance the overall .4 standard deviation disadvantage of a sample born elsewhere. Nonetheless, keeping all of these qualifications in mind, the kernel of evidence that must also be acknowledged is that Latino and black immigrants are, at least in the short run, putting some downward pressure on the distribution of intelligence.</em></p>
<ul>
<li>Page 427 (location ~ 6535-6545)</li>
</ul>
<p><em>Think back to the immigrant at the turn of the century. America was the Land of Opportunity—but that was all. There were no guarantees, no safety nets. One way or another, an immigrant had to make it on his own. Add to that the wrench of tearing himself and family away from a place where his people might have lived for centuries, the terrors of having to learn a new language and culture, often the prospect of working at jobs he had never tried before, a dozen other reasons for apprehension, and the United States had going for it a crackerjack self-selection mechanism for attracting immigrants who were brave, hard-working, imaginative, self-starting—and probably smart. Immigration can still select for those qualities, but it does not have to. Someone who comes here because his cousin offers him a job, a free airplane ticket, and a place to stay is not necessarily self-selected for those qualities. On the contrary, immigrating to America can be for that person a much easier option than staying where he is. Economists have made considerable progress in understanding how the different types of immigration (and all the ones in between) have played out in practice. To begin with, it has been demonstrated beyond much doubt that immigrants as a whole have more steeply rising earnings than American natives of equal age and measured skills and that, after a relatively short adaptation period of ten to fifteen years, immigrants of equal age and education earn as much as natives.60 Here is empirical support for the proposition that immigrants taken as a whole are indeed self-selected for qualities that lead to economic success, and one might expect cognitive ability to be among them.</em></p>
<ul>
<li>Page 428 (location ~ 6548-6561)</li>
</ul>
<p><em>In the 1960s and 1970s, America became much more of a welfare state. Consistent with that, the earnings potential of the Latino immigrant group fell substantially from 1955 through 1980. Among the non-European countries, three of the four steepest declines in earnings potential were among immigrant groups from Colombia, the Dominican Republic, and Mexico, all large contributors to the Latin American immigrant population. Many of the other countries were not included in Borjas’s forty-one countries, so we do not know whether they followed the same pattern. Among the Latin American and Latino-Caribbean nations, only the immigrant groups from Cuba, Brazil, and Panama had improving potential by Borjas’s measures. The 1980 Mexican wave of immigrants had an earnings potential about 15 percent lower than the wave that arrived in 1955. For the Dominican Republic and Colombia, the earnings potential of the 1980 wave was more than 30 percent lower than those who came in 1955, a decline that remains after holding education, marital status, age, and location constant.62</em></p>
<ul>
<li>Page 429 (location ~ 6578-6585)</li>
</ul>
<p><em>The Borjas data include three of the major contributors of black immigrants from that region: Jamaica, Haiti, and Trinidad/Tobago. The earnings potential of the immigrant cohorts from these countries in 1970 ranged from 31 to 34 percent less than American natives (after holding education, marital status, age, and location constant).64 In 1980, the earnings potential from the most recent immigrant waves from these three countries ranged from 26 to 52 percent less than American natives. Immigrants from all three countries are on an extremely slow route to income equality, with Jamaicans and Haitians lagging behind everyone except the lowest-ranking Latin American countries. Borjas’s study did not include immigrants from any countries in sub-Saharan Africa. The results for European immigrants were also consistent with the theory. Borjas’s overall appraisal of the data is worth quoting in full: The empirical analysis of the earnings of immigrants from 41 different countries using the 1970 and 1980 censuses shows that there are strong country-specific fixed effects in the (labor market) quality of foreign-born persons. In particular, persons from Western European countries do quite well in the United States, and their cohorts have exhibited a general increase in earnings (relative to their measured skills) over the postwar period. On the other hand, persons from less developed countries do not perform well in the U.S. labor market and their cohorts have exhibited a general decrease in earnings (relative to their measured skills) over the postwar period.</em></p>
<ul>
<li>Page 430 (location ~ 6590-6602)</li>
</ul>
<p><em>Even if an estimate is realistic regarding the current situation, it is impossible to predict how long it may be correct or when and how it may change. It may shrink or grow or remain stable. Demographers disagree about many things, but not that the further into the future we try to look, the more likely our forecasts are to be wrong. This leads to the last issue that must be considered before it is fruitful to talk about specific demographic policies. So what if the mean IQ is dropping by a point or two per generation? One reason to worry is that the drop may be enlarging ethnic differences in cognitive ability at a time when the nation badly needs narrowing differences. Another reason to worry is that when the mean shifts a little, the size of the tails of the distribution changes a lot. For example, assuming a normal distribution, a three-point drop at the average would reduce the proportion of the population with IQs above 120 (currently the top decile) by 31 percent and the proportion with IQs above 135 (currently the top 1 percent) by 42 percent. The proportion of the population with IQs below 80 (currently the bottom decile) would rise by 41 percent and the proportion with IQs below 65 (currently the bottom 1 percent) would rise by 68 percent. Given the predictive power of IQ scores, particularly in the extremes of the distribution, changes this large would profoundly alter many aspects of American life, none that we can think of to the good.</em></p>
<ul>
<li>Page 432 (location ~ 6611-6621)</li>
</ul>
<p><em>In education, Cattell predicted that academic standards would fall and the curriculum would shift toward less abstract subjects. He foresaw an increase in “delinquency against society”—crime and willful dependency (for example, having a child without being able to care for it) would be in this category. He was not sure whether this would lead to a slackening of moral codes or attempts at tighter government control over individual behavior. The response could go either way, he wrote. He predicted that a complex modern society with a falling IQ would have to compensate people at the low end of IQ by a “systematized relaxation of moral standards, permitting more direct instinctive satisfactions.”68 In particular, he saw an expanding role for what he called “fantasy compensations.” He saw the novel and the cinema as the contemporary means for satisfying it, but he added that “we have probably not seen the end of its development or begun to appreciate its damaging effects on ‘reality thinking’ habits concerned in other spheres of life”—a prediction hard to fault as one watches the use of TV in today’s world and imagines the use of virtual reality helmets in tomorrow’s.</em></p>
<ul>
<li>Page 434 (location ~ 6645-6654)</li>
</ul>
<p><em>This chapter brings together the social behaviors we covered in Part II from a new vantage point. The earlier chapters showed that low cognitive ability raises the risk of living in conditions or behaving in ways that society hopes to change. Now the question concerns prevalence: To what extent does low cognitive ability describe the people thus afflicted? The distinction is more familiar in the medical context. High cholesterol may be a risk factor for heart disease, but most people with heart disease may or may not have high cholesterol. If most people who have heart attacks do not have high cholesterol, then lowering the cholesterol of those with high levels will not do much to reduce the frequency of heart attacks in the population at large. Similarly, to the extent that low cognitive ability is prevalent among people who have the problems we hope to solve, policies that are effective for people with low scores should be sought.</em></p>
<ul>
<li>Page 437 (location ~ 6692-6698)</li>
</ul>
<p><em>HIGH SCHOOL DROPOUTS It will come as no surprise to find that most high school dropouts have low intelligence. The figure below shows the results for persons who dropped out of school and did not subsequently obtain a GED. Overall, 94 percent of those who permanently dropped out of school were below average in IQ. As we noted in Chapter 6, this disproportion is not materially affected by analyses limited to persons who took the intelligence test before they dropped out, so it cannot be explained by the effects of a lack of schooling on their IQs.</em></p>
<ul>
<li>Page 440 (location ~ 6738-6742)</li>
</ul>
<p><em>The prototypical member of the underclass in the public imagination is a young male hanging out on the streets, never working. This amounted to very few men. Only 2.2 percent of NLSY men not in school and not prevented from working because of health problems failed to work at least a week in 1989. But among these 2.2 percent, low cognitive ability predominated. The figure below, limited to civilian men out of school and not physically prevented from working, combines those who said they were unemployed and those who said they had dropped out of the labor force; their common denominator is that they reported zero weeks of working for 1989. The mean IQ of men who did not work at all was 84. Fifty percent were in the bottom decile. Eighty-four percent were below average. Sixty-four percent of able-bodied men who did not work in 1989 were in the bottom 20 percent of intelligence</em></p>
<ul>
<li>Page 441 (location ~ 6756-6763)</li>
</ul>
<p><em>MEN AND CRIME The next figure contains the breakdown of the IQs of men in the NLSY who were interviewed in a correctional facility, showing that they had committed at least one offense serious enough to get them locked up. The mean IQ of men who were ever interviewed in a correctional facility was 84. Forty-five percent were concentrated in the bottom decile of cognitive ability. Ninety-three percent of the men were somewhere in the bottom half of the cognitive ability distribution. This high prevalence of low IQ among</em></p>
<ul>
<li>Page 442 (location ~ 6773-6777)</li>
</ul>
<p><em>MEN AND CRIME The next figure contains the breakdown of the IQs of men in the NLSY who were interviewed in a correctional facility, showing that they had committed at least one offense serious enough to get them locked up. The mean IQ of men who were ever interviewed in a correctional facility was 84. Forty-five percent were concentrated in the bottom decile of cognitive ability. Ninety-three percent of the men were somewhere in the bottom half of the cognitive ability distribution. This high prevalence of low IQ among offenders is consistent with other estimates in the literature, as summarized in Chapter 11.</em></p>
<ul>
<li>Page 442 (location ~ 6773-6777)</li>
</ul>
<p><em>As the figure shows, 57 percent of chronic welfare mothers were in the bottom two deciles of IQ, 88 percent were in the bottom half of the distribution, and their mean IQ was 86. Just as low IQ was increasingly prevalent as the level of male unemployment increased, so also is low IQ more prevalent among mothers as their dependency on welfare rises. Forty-five percent of women who ever received welfare are in the bottom 20 percent of intelligence</em></p>
<ul>
<li>Page 443 (location ~ 6784-6787)</li>
</ul>
<p><em>Illegitimacy We start with the children who are born to unmarried women (see the figure below). The mean IQ of mothers of children born out of wedlock was 87.3 Of all illegitimate children in the NLSY sample, almost one out of three was born to a mother in the bottom 10 percent of the intelligence distribution, with an IQ under 81, and 85 percent were born to women in the bottom half of the cognitive ability distribution.</em></p>
<ul>
<li>Page 444 (location ~ 6799-6803)</li>
</ul>
<p><em>Other Forms of Single Parenthood The figure below shows the proportion of NLSY children born to a married couple but living (in 1990) with just their mothers because of divorce or separation. First, a caution: The profile we are about to present may change in the future because so many of the expected divorces among the NLSY sample have not yet occurred. For women who had ever been married in the 25 to 33 age range as of 1990, we may, however, ask: Among their children who were living in mother-only families as of 1990, what is the distribution of the mother’s intelligence? Thirty-one percent of children living with divorced or separated mothers had mothers with IQs in the bottom 20 percent of intelligence</em></p>
<ul>
<li>Page 445 (location ~ 6809-6814)</li>
</ul>
<p><em>Deprived Home Environments Chapter 10 discussed the HOME inventory, a measure combining many indicators of both emotional support (for example, disciplinary style) and cognitive stimulation (for example, reading to the child). Here, we examine children whose HOME scores put them in the bottom 10 percent of environments (using national norms for the HOME inventory). The mean IQ of mothers of children in the worst home environments was 86. Three out of eight had IQs below 81; 86 percent had IQs below 100. The figure below combines the results for children in all age groups. There were some age differences, however: Generally, the concentration of the worst environments among mothers with low cognitive ability got worse as the children got older. For children ages 3 to 5 who were in the worst home environments, 59 percent had mothers with IQs in the bottom two deciles. For children 6 and older, the figure was 65 percent.</em></p>
<ul>
<li>Page 446 (location ~ 6835-6842)</li>
</ul>
<p><em>The mean IQ of mothers of children who scored in the bottom decile of a childhood intelligence test was 81.5 Overall, 94 percent of these children had mothers with IQs under 100. The extreme concentration of low IQ among the children of low-IQ mothers is no surprise. That it is predictable does not make the future any brighter for these children.</em></p>
<ul>
<li>Page 449 (location ~ 6876-6879)</li>
</ul>
<p><em>The mean IQ of those who scored “yes” was 104. Those in the bottom two deciles contributed only about 10 percent, half of their proportional share. Those in the bottom half of the cognitive distribution contributed 37 percent. As in the case of year-round employment, the skew toward those in the upper half of the cognitive ability distribution is not extreme. This reminds us again more generally that most people in the lower half of the cognitive distribution are employed, out of poverty, not on welfare, married when they have their babies, providing a nurturing environment for their children, and obeying the law. We must add another reminder, however. There is a natural tendency to review these figures and conclude that we are really looking at the consequences of social and economic disadvantage, not intelligence. But in Part II, we showed that for virtually all of the indicators reviewed in this chapter, controlling for socioeconomic status does not get rid of the independent impact of IQ. On the contrary, controlling for IQ often gets rid of the independent impact of socioeconomic status. We have not tried to present the replications of those analyses for all ethnic groups combined, but they tell the same story.</em></p>
<ul>
<li>Page 450 (location ~ 6885-6894)</li>
</ul>
<p><em>usually are. The final two chapters look to the future. In Chapter 21, we sound a tocsin.</em></p>
<ul>
<li>Page 452 (location ~ 6916-6917)</li>
</ul>
<p><em>Raising intelligence significantly, consistently, and affordably would circumvent many of the problems that we have described. Furthermore, the needed environmental improvements—better nutrition, stimulating environments for preschool children, good schools thereafter—seem obvious. But raising intelligence is not easy. Nutrition may offer one of the more promising approaches. Height and weight have increased markedly with better nutrition. The rising IQs in many countries suggest that better nutrition may be increasing intelligence too. Controlled studies have made some progress in uncovering a link between improved nutrition and elevated cognitive ability as well, but it remains unproved and not well understood. Formal schooling offers little hope of narrowing cognitive inequality on a large scale in developed countries, because so much of its potential contribution has already been realized with the advent of universal twelve-year systems. Special programs to improve intelligence within the school have had minor and probably temporary effects on intelligence. There is more to be gained from educational research to find new methods of instruction than from more interventions of the type already tried. Preschool has borne many of the recent hopes for improving intelligence. However, Head Start, the largest program, does not improve cognitive functioning. More intensive, hence more costly, preschool programs may raise intelligence, but both the size and the reality of the improvements are in dispute.</em></p>
<ul>
<li>Page 452 (location ~ 6921-6933)</li>
</ul>
<p><em>Upon first consideration, the ways to eliminate those disadvantages seem obvious. Many children of low-income parents grow up in terrible home environments, with little stimulation or nurturing. Surely, it would seem, intelligence would rise if these children were placed in day care environments where professionals provided that stimulation and nurturing. Schools in poor neighborhoods are often run down and chaotic. Isn’t it clear that increasing the investment in schools would pay off in higher scores? Limitless possibilities for improving intelligence environmentally wait to be uncovered by science: improved educational methods, diets, treatments for disease, prenatal care, educational media, and even medicines to make one smarter. In principle, intelligence can be raised environmentally to unknown limits.</em></p>
<ul>
<li>Page 453 (location ~ 6944-6950)</li>
</ul>
<p><em>In the twentieth century, the plausibility of a connection has been reinforced by the fact that people in affluent countries are larger than their ancestors were, presumably in part because they are eating better. IQ scores, too, have been rising during approximately the same period—the Flynn effect described in Chapter 13. These coincident changes do not prove that better eating makes for smarter people, but count as circumstantial evidence. For a while, however, scientific research seemed to have weakened the case for any link between nutrition and IQ. The most damaging blow was a study of over 100,000 Dutch men who were born around a time of intense famine in several Dutch cities near the end of World War II.3 Nineteen years later, the men took intelligence tests as part of the qualification for national military service, and it occurred to scholars to compare the ones who were born in the depths of the famine to those born just before and just after it. Many pregnant women miscarried during the famine, but their surviving sons scored no lower in intelligence than the men born to mothers who had little or no exposure to famine. But as important as this study was, some scientists were not entirely convinced by its negative findings. The Dutch famine was relatively brief—three months or so—and limited to the pre- and perinatal period of the men’s lives. And while the mothers were indeed starving for calories, their deficiencies in vitamins, minerals, and other dietary elements were perhaps too brief to take a toll.</em></p>
<ul>
<li>Page 455 (location ~ 6964-6976)</li>
</ul>
<p><em>Another environmental and possibly physiological influence on IQ is suggested by data from twins. Among identical twins, the one with the higher IQ is likely to have been heavier at birth.13 This is part of a more general finding that higher weights at birth are associated with higher IQs in childhood, but the identical twin data decisively prove that the correlation between birth weight and later intelligence has an environmental element, since identical twins are genetic clones.14 It is less certain that there are no social factors here: People may treat twin babies differently if one is plumper than the other. Training mothers in how to be more attentive to their low-birth-weight babies seems, in fact, to raise later IQ, at least up to the age of 7.15</em></p>
<ul>
<li>Page 457 (location ~ 7005-7011)</li>
</ul>
<p><em>One basic error is to assume that new educational opportunities that successfully raise the average will also reduce differences in cognitive ability. Consider trying to raise the cognitive level by putting a public library in a community that does not have one. Adding the library could increase the average intellectual level, but it may also spread out the range of scores by adding points to the IQs of the library users, who are likely to have been at the upper end of the distribution to begin with. The literature on such “aptitude-treatment interactions” is large and complex.16 For example, providing computer assistance to a group of elementary school children learning arithmetic increased the gap between good and bad students;17 a similar effect was observed when computers were used to teach reading;18 the educational television program, “Sesame Street” increased the gap in academic performances between children from high- and low-status homes.</em></p>
<ul>
<li>Page 458 (location ~ 7019-7027)</li>
</ul>
<p><em>Tell parents that the quality of the schools doesn’t matter, and they will unanimously, and rightly, ignore you, for differences in schools do matter in many important ways. But in affecting IQ, they do not matter nearly as much as most people think. This conclusion was first and most famously reached by a study that was expected to demonstrate just the opposite. The study arose out of a mandate of the Civil Rights Act of 1964 to examine how minority groups are affected by educational inequalities. The result was a huge national survey, with a sample that eventually numbered 645,000 students, led by the eminent sociologist James S. Coleman. His researchers measured school quality by such objective variables as credentials of the teachers, educational expenditures per pupil, and the age and quality of school facilities. Because the schools that most minority children attended were measurably subpar in facilities and staff, it was assumed that the minority children fortunate enough to attend better schools would also show improved cognitive functioning. But the report, issued in July 1966, announced that it had failed to find any benefit to the cognitive abilities of children in public primary or secondary schools that could be credited to better school quality.20 The usual ways in which schools tried to improve their effectiveness were not likely to reduce the cognitive differences among individual children or those between ethnic groups. The Coleman report’s gloomy conclusions were moderated in subsequent analyses that found some evidence for marginal benefits of school quality on intellectual development.21 Coleman himself later concluded that parochial schools generally do a better job of developing the cognitive abilities of their students than public schools, which pointed to at least some factor in schooling that might be exploited to improve intelligence.22 Yet the basic conclusion of the report has stood the test of time and criticism: Variations in teacher credentials, per pupil expenditures, and the other objective factors in public schools do not account for much of the variation in the cognitive abilities of American school children.</em></p>
<ul>
<li>Page 459 (location ~ 7034-7051)</li>
</ul>
<p><em>The Coleman report did not prove that educational reform is always futile, but that, on the whole, America had already achieved enough objective equalization in its schools by 1964 so that it was hard to pick up any effects of unequal school quality. The Coleman report tells us that the cognitive ability differences among individuals and groups alike on a national scale cannot be reduced much by further attempts to equalize the kinds of bricks-and-mortar factors and teacher credentials that school boards and taxpayers most often concern themselves with. Aside from the issue of school quality is the question of whether simply going to school makes any difference to one’s intelligence. The answer is self-evidently yes. Going to school and learning how to read and write, manipulate numbers, find out about one’s culture and about the discoveries of science are going to raise scores on IQ tests compared to not going to school. But although it is obvious that schooling itself fosters intelligence, it is far less obvious how much of the intellectual variation around us can be attributed to differences in the amount of schooling people get.</em></p>
<ul>
<li>Page 461 (location ~ 7061-7069)</li>
</ul>
<p><em>School differences can nonetheless be important. If a child is near the top of the intelligence distribution to begin with, the school can make a major difference in whether that intellectual talent is actually realized, a topic we consider in the next chapter. Or if a child has specific learning disabilities, access to the latest pedagogical techniques and technology may make a major difference. There doubtless are, in addition, pockets in America’s vast educational realm where schools are uncommonly good or uncommonly poor, in which the children are benefiting or suffering cognitively. By definition, however,</em></p>
<ul>
<li>Page 463 (location ~ 7093-7097)</li>
</ul>
<p><em>School differences can nonetheless be important. If a child is near the top of the intelligence distribution to begin with, the school can make a major difference in whether that intellectual talent is actually realized, a topic we consider in the next chapter. Or if a child has specific learning disabilities, access to the latest pedagogical techniques and technology may make a major difference. There doubtless are, in addition, pockets in America’s vast educational realm where schools are uncommonly good or uncommonly poor, in which the children are benefiting or suffering cognitively. By definition, however, these are unusual cases, not likely to show up in national data on intelligence.</em></p>
<ul>
<li>Page 463 (location ~ 7093-7098)</li>
</ul>
<p><em>Raising IQ Among the School-Aged: Converging Results from Two Divergent Tries The question remains: Is there any evidence that cognitive ability as measured by IQ tests can be increased by special interventions after children reach school age? We have some reason for thinking the answer is a highly qualified yes, and some basis for estimating how much, from two sources of evidence drawn from strikingly different contexts. The first is one of the largest controlled experiments attempting explicitly to raise the intelligence of school-age children. It occurred in Venezuela, where in 1979 the incoming president named to his cabinet a Minister of State for the Development of Human Intelligence.40 The new minister was convinced that a nation’s average intellectual level was fundamental to its well-being, and he set out to see what could be done to raise the IQ of Venezuelan school children. The result was Project Intelligence, designed over four years by a team of Venezuelan and American psychologists, educators, and other specialists. In the fifth year, 900 youngsters in seventh grade in a poor district of a Venezuelan provincial city were randomly divided into experimental and control groups.41 Those in the experimental group were taught approximately sixty forty-five-minute lessons in addition to their regular curriculum during the year and were cognitively tested before, during, and after the year. The students in the control group were tested at the same intervals, without receiving any of the additional instruction. The special lessons involved instruction in the kinds of intellectual activities that turn up on intelligence tests—visuospatial and verbal reasoning, vocabulary and word analogies—in addition to lessons in inventive thinking.42 At the end of the year, the youngsters in the experimental group, compared to the controls, had gained a net of more than 0.4 standard deviation on a conventional intelligence test and a net gain of just over 0.1 standard deviation on a culture-fair intelligence test—in other words, a net gain in the range between 1.6 and 6.5 IQ points. There was no chance to see if the gain faded out or was reflected in the rest of the students’ academic performance, nor can we even guess how much a second or third year of lessons would have accomplished.</em></p>
<ul>
<li>Page 466 (location ~ 7141-7159)</li>
</ul>
<p><em>The second source of evidence comes from the unsystematic but massive attempt to raise intelligence that goes on in the innumerable commercial coaching services promising to raise SAT scores. Few people think of the prep courses in that way. On the surface, it is all about getting into the college of your choice. But raising an SAT is just like raising an IQ if the SAT is an intelligence test and, however adroitly the current officials of the College Board and the admissions officers in universities try to avoid saying so, the SAT is partly an intelligence test.43 Can the SAT be coached? Yes, but it is not easy. Everyone who looks into this topic immediately hears about students who gained 100, 150, or 200 points on the SAT after a few hours of coaching. The tales may even be true, but they need to be averaged with the tales that don’t get told about the scores that improve by only a few points—and the scores that drop—after spending a few dozen hours and hundreds of dollars on a coaching course. Scholars have by now largely sorted out the reality behind the sales pitches. After a furious debate about the issue in the late 1970s and early 1980s, the best evidence indicates that the coaching programs which can offer convincing scientific backing for their claims consist not of a few hours of practice but of lengthy training, comparable to going to school full time.44 In the best of these analyses, Samuel Messick and Ann Jungeblut reviewed the published studies on coaching for the SAT, eliminated the ones that were methodologically unsound, and estimated in a regression analysis the point gain for a given number of hours spent studying for the test.45</em></p>
<ul>
<li>Page 467 (location ~ 7160-7173)</li>
</ul>
<p><em>Although intended for utterly different purposes, the benefits of the Venezuelan program and of SAT coaching schools are remarkably similar. The sixty lessons of the Venezuelan course, representing forty-five hours of study, added between .1 and .4 standard deviation on various intelligence tests. From the figure on SAT coaching, we estimate that 45 hours of studying adds about .16 standard deviation to the Verbal score and about .23 standard deviation to the Math score.46 These increases in test scores</em></p>
<ul>
<li>Page 469 (location ~ 7184-7188)</li>
</ul>
<p><em>Although intended for utterly different purposes, the benefits of the Venezuelan program and of SAT coaching schools are remarkably similar. The sixty lessons of the Venezuelan course, representing forty-five hours of study, added between .1 and .4 standard deviation on various intelligence tests. From the figure on SAT coaching, we estimate that 45 hours of studying adds about .16 standard deviation to the Verbal score and about .23 standard deviation to the Math score.46</em></p>
<ul>
<li>Page 469 (location ~ 7184-7187)</li>
</ul>
<p><em>During the 1970s when scholars were getting used to the disappointing results of programs for school-age children, they were also coming to a consensus that IQ becomes hard to budge at about the time children go to school. Longitudinal studies found that individual differences in IQ stabilized at approximately age 6.47 Meanwhile, developmental psychologists found that the year-to-year correlations in mental test performance were close to zero in the first few years of life and then rose to asymptotic levels by age 6.48 These findings conformed with the intuitive notion that, in the poet’s words, “as the twig is bent the tree’s inclined.”49 Any intervention designed to increase intelligence (or</em></p>
<ul>
<li>Page 470 (location ~ 7196-7202)</li>
</ul>
<p><em>During the 1970s when scholars were getting used to the disappointing results of programs for school-age children, they were also coming to a consensus that IQ becomes hard to budge at about the time children go to school. Longitudinal studies found that individual differences in IQ stabilized at approximately age 6.47 Meanwhile, developmental psychologists found that the year-to-year correlations in mental test performance were close to zero in the first few years of life and then rose to asymptotic levels by age 6.48 These findings conformed with the intuitive notion that, in the poet’s words, “as the twig is bent the tree’s inclined.”49 Any intervention designed to increase intelligence (or change any other basic characteristics of the child) must start early, and the earlier the better.</em></p>
<ul>
<li>Page 470 (location ~ 7196-7203)</li>
</ul>
<p><em>PERRY PRESCHOOL. The study invoked most often as evidence that Head Start works is known as the Perry Preschool Program. David Weikart and his associates have drawn enormous media attention for their study of 123 black children (divided into experimental and control groups) from the inner city in Ypsilanti, Michigan, whose IQs measured between 70 and 85 when they were recruited in the early 1960s at the age of 3 or 4.61 Fifty-eight children in the program received cognitive instruction five half-days62 a week in a highly enriched preschool setting for one or two years, and their homes were visited by teachers weekly for further instruction of parents and children. The teacher-to-child ratio was high (about one to five), and most of the teachers had a master’s degree in appropriate child development and social work fields. Perry Preschool resembled the average Head Start program as a Ferrari resembles the family sedan. The fifty-eight children in the experimental group were compared with another sixty-five who served as the control group. By the end of their one or two years in the program, the children who went to preschool were scoring eleven points higher in IQ than the control group. But by the end of the second grade, they were just marginally ahead of the control group. By the end of the fourth grade, no significant difference in IQ remained.63 Fadeout again. Although this intensive attempt to raise intelligence failed to produce lasting IQ gains, the Ypsilanti group believes it has found evidence for a higher likelihood of high school graduation and some post-high school education, higher employment rates and literacy scores, lower arrest rates and fewer years spent in special education classes as a result of the year or two in preschool. The effects are small and some of them fall short of statistical significance.</em></p>
<ul>
<li>Page 472 (location ~ 7233-7248)</li>
</ul>
<p><em>Source: Lazar and Darlington 1982, Table 15. A case can be made for expecting interventions to be especially effective for these children, since their environments are so poor that they are unlikely to have had any of the benefits that a good program would provide. Moreover, if the studies have control groups and are reasonably well documented, there is at least a hope of deciding whether the programs succeeded in forestalling the emergence of retardation. We will briefly characterize the two studies approximating these conditions that have received the most scientific and media attention.</em></p>
<ul>
<li>Page 474 (location ~ 7268-7273)</li>
</ul>
<p><em>The program started when the babies were just over a month old, and it provided care for six to eight hours a day, five days a week, fifty weeks a year, emphasizing cognitive enrichment activities with teacher-to-child ratios of one to three for infants and one to four to one to six in later years, until the children reached the age of 5. It also included enriched nutrition and medical attention until the infants were 18 months old.69 The Abecedarian Project is the apotheosis of the day care approach. This is extremely useful from a methodological perspective: Even if the nation cannot afford to supply the same services to the entire national population of children who qualified for the Abecedarian Project, it serves as a way of defining the outer limit of what day care can accomplish given the current state of the art. At the end of the fifth year, the children receiving the day care outscored those who did not by half a standard deviation on an intelligence test. At last report, the children were 12 years old and were still doing better intellectually than the controls. Combining all the cohorts, only 28 percent of the experimental children had repeated a grade, compared to 55 percent of the control children. Only 13 percent of the experimental children had IQs of less than 85, compared to 44 percent of the control children.70</em></p>
<ul>
<li>Page 475 (location ~ 7279-7289)</li>
</ul>
<p><em>Ignoring the more technical issues, the major stumbling block to deciding what the Abecedarian Project has accomplished is that the experimental children had already outscored the controls on cognitive performance tests by at least as large a margin (in standard score units) by the age of 1 or 2 years, and perhaps even by 6 months, as they had after nearly five years of intensive day care.71 There are two main explanations for this anomaly. Perhaps the intervention had achieved all its effects in the first months or the first year of the project (which, if true, would have important policy implications). Or perhaps the experimental and control groups were different to begin with (the sample sizes for any of the experimental or control groups was no larger than fifteen and as small as nine, so random selection with such small numbers gives no guarantee that the experimental and control groups will be equivalent). To make things still more uncertain, test scores for children younger than 3 years are poor predictors of later intelligence test scores, and test results for infants at the age of 3 or 6 months are extremely unreliable. It would therefore be difficult in any case to assess the random placement from early test scores. The debate over the results is ongoing and unresolved as we write.</em></p>
<ul>
<li>Page 476 (location ~ 7291-7300)</li>
</ul>
<p><em>The famous Milwaukee Project started in 1966 under the supervision of Richard Heber, a professor at the University of Wisconsin (Madison) who had been research director of President John F. Kennedy’s panel on mental retardation at the beginning of the decade. Healthy babies of poor black mothers with IQs below 75 were almost, but not quite, randomly assigned to no day care at all or day care starting at 3 months and continuing until they went to school. The day care lasted all day, five days a week, all year. The families of the babies selected for day care received a variety of additional services and health care. The mothers were paid for participation, received training in parenting and job skills, and their other young children received free child care. Only thirty-five children are considered to have completed the study, seventeen receiving the special attention and the remainder serving as controls. Soon after the Milwaukee project began, reports of enormous net gains in IQ (more than 25 points) started appearing in the popular media and in psychology textbooks.72 However, there was a dearth of publication that allowed experts to evaluate the project. The few technical items that appeared raised more questions than they answered.73 It was not until 1988 that another Wisconsin professor associated with the work, Howard Garber, published an interpretable analysis of what had been done in the Milwaukee Project and what was found.74 By the age of 12 to 14 years, the children who had been in the program were scoring about ten points higher in IQ than the controls.</em></p>
<ul>
<li>Page 477 (location ~ 7302-7315)</li>
</ul>
<p><em>In summary, the two experiments contain some promising leads. But it is not obvious where to go from here, for they differed in possibly important ways. The Abecedarian Project evaluated day care; the Milwaukee Project provided numerous interventions besides day care, including parental payment and training. It is hard to tell whether the former found enduring IQ benefits, given the very early divergence in test scores for experimental and control groups, but it found some academic benefits; the latter found an enduring IQ gain, but has not yet shown comparable intellectual gains in school work. It may be relevant that the Abecedarian mothers had higher IQs than the Milwaukee mothers, so the children may not have been at equal risk for retardation. Reading this history of interventions, you may have noticed a curious parallelism: In the media, the good news is trumpeted as if there were no ambiguity; in the technical journals, the good news is viewed with deep suspicion and discounted. Are the scholars as excessively nitpicking as the journalists are credulous? Here is the difficult-to-discuss problem that overhangs the interpretation of these results: The people who run these programs want them to succeed. This is hardly a criticism. People who are spending their lives trying to help disadvantaged children ought to be passionately committed to their success. But it is hard for them to turn around and be dispassionate about the question, “How well are we doing?” Often the raw data from these programs are not easily accessible to outside scholars. Not infrequently, when such data finally are made available, they reveal a different and less positive way of viewing the successful results than the one that had previously been published.</em></p>
<ul>
<li>Page 478 (location ~ 7321-7333)</li>
</ul>
<p><em>Children are not put up for adoption for the edification of social theorists. There are no controlled experiments on the effects of adoption. Adoption usually means trouble in the biological family; trouble usually lands on families nonrandomly and unaccountably, making it hard to extract clear, generalizable data. The most famous studies were mostly done decades ago, when the social and financial incentives for adoption were different from today’s. Legalized contraception and abortion, too, have altered the pool of subjects for adoption studies. Both the environmental and genetic legacies of children put up for adoption have surely changed over the years, but it is impossible to know exactly in what ways and how much. In short, although data are abundant and we will draw some broad conclusions, this is an area in which solid estimates are unlikely to be found.</em></p>
<ul>
<li>Page 479 (location ~ 7343-7349)</li>
</ul>
<p><em>At the same time, researchers think it very likely that adopted children earn higher scores than they would have had if they been raised by their biological parents, because the adopting home environment is likely to be better than the one their biological parents would have provided. If so, this would be a genuine effect of the home environment. How large is the effect? Charles Locurto, reviewing the evidence and striking an average, concludes that it is about six points.80 As a consensus figure, that seems about right to us. However, a consensus figure is not what we want, as Locurto recognizes. It does not identify how wide a gap separates the environments provided by adopting homes and the homes in which the children would have been reared had they not been adopted. We seek a comparison of the IQs of children growing up in homes of a known low socioeconomic status and genetically comparable children reared in homes of a known high socioeconomic status. What would the increment in IQ look like then?</em></p>
<ul>
<li>Page 481 (location ~ 7366-7374)</li>
</ul>
<p><em>Two approximations to an ideal adoption study, albeit with very small samples, have recently been done in France.81 In one, Michel Schiff and his colleagues searched French records for children abandoned in infancy, born to working-class (unskilled) parents, who were adopted into upper-class homes. Only thirty-two children met the study’s criteria. In childhood, their average IQ was 107. To understand what this means, two further comparisons are in order. First, the adopted children scored eight points lower on average than their schoolmates, presumably from comparable upper-class homes. This confirms the usual finding with adopted children. But, second, they scored twelve points higher than twenty of their full or half-siblings who were reared at least for a time by a biological parent or grandparent in lower-class surroundings.82 This study provides a rare chance to estimate roughly where the adoptees would have been had they remained in their original homes. A second French study compared four small groups of adopted children, reared in either high- or low-SES homes, and the biological offspring of high- or low-SES parents. Thus one could ask, albeit with only a handful of children,83 what happens when children born to low-SES parents are adopted into a high-SES home or when children born to high-SES parents are adopted into low-SES homes; and so on. In this study as well, the switch from low to high status in the home environment produced a twelve-point benefit in IQ.84 Such findings, of course, implicate the home environment as a factor in the development of cognitive ability. We cannot be sure how much, because we do not know exactly how far down the SES ladder the children came from, or how far up the ladder they were moved into their adoptive homes.</em></p>
<ul>
<li>Page 481 (location ~ 7374-7388)</li>
</ul>
<p><em>To see what the policy implications might be, let us suppose that low-and high-SES homes in the French studies represented the 10th and 90th centiles in the quality of the home environment, respectively. If that were the case, what might be accomplished by moving children from very deprived homes (at the 2d centile, to make the example concrete) to very advantaged ones (98th centile)? The results of the French study imply that such a shift in home environment would produce a benefit of almost twenty IQ points.85 A swing of twenty points is considerable and seems to open up the possibility of large gains in intelligence to be had by equalizing homes “upward,” by appropriating for more families whatever nurturing things go on in the homes of the top 1 or 2 percent in socioeconomic status.86 The problem, obviously, is that no one knows how to equalize environments upward on so grand a scale, particularly since so much of what goes on in the nurturing of children is associated with the personality and behavior of the parent, not material wealth. This brings us to a variety of policy issues that it is now time to discuss more explicitly.</em></p>
<ul>
<li>Page 483 (location ~ 7392-7401)</li>
</ul>
<p><em>Certain kinds of research are not needed. Next to nothing is to be learned about how to raise IQ by more evaluations of Head Start, or even by replicating much better programs such as Perry Preschool or Abecedarian. The main lesson to be learned from these better programs has already been learned: It is tough to alter the environment for the development of general intellectual ability by anything short of adoption at birth. By now, researchers know enough to be confident that the next demonstration program is not going to be the magic bullet, because they have already demonstrated beyond dispute that the “environment” is an unimaginably complex melange of influences and inputs for all the child’s waking hours (and perhaps some sleeping hours too). No meaningful proportion of that melange can reasonably be expected to be shaped by any outside intervention into the child’s social environment, even one that lasts eight hours a day, using the repertoire of techniques now available. To have a large effect, we need new knowledge about cognitive development.</em></p>
<ul>
<li>Page 483 (location ~ 7404-7411)</li>
</ul>
<p><em>Long-term funding, buffers against bureaucratic meddling, readiness to fund research on the hardest questions, if they are brought forward by the inner logic of the science, and not just the politically correct questions: This is what is needed, and what today’s research programs seldom provide. With that set of caveats on the table, more research is indeed at the top of our policy agenda. Because intelligence is less than completely heritable, we can assume that, some day, it will be possible to raise the intelligence of children through environmental interventions. But new knowledge is required.</em></p>
<ul>
<li>Page 484 (location ~ 7415-7419)</li>
</ul>
<p><em>Adoption at birth from bad environments into good environments raises cognitive functioning, especially in childhood and by amounts that are not well established. In general, the worse the home that would have been provided by the biological parents and the better the adoptive home, the greater is the cognitive benefit of adoption. Adoption at birth seems to produce positive noncognitive effects as well. In terms of government budgets, adoption is cheap; the new parents bear all the costs of twenty-four-hour-a-day care for eighteen years or so. The supply of eager and qualified adoptive parents for infants is large, even for infants with special needs. If adoption is one of the only affordable and successful ways known to improve the life chances of disadvantaged children appreciably, why has it been so ignored in congressional debate and presidential proposals? Why do current adoption practices make it so difficult for would-be parents and needy infants to match up? Why are cross-racial adoptions so often restricted or even banned? All these questions have political and social answers that would take us far outside our territory. But let it be said plainly: Anyone seeking an inexpensive way to do some good for an expandable number of the most disadvantaged infants should look at adoption. The tough question about adoption involves the way the adoption decision is made. Governments should not be able to force parents to give up their children for any except the most compelling of reasons. Right now, the government already has the power (varying by state), based on evidence of neglect and abuse, which we do not advocate expanding.</em></p>
<ul>
<li>Page 486 (location ~ 7452-7464)</li>
</ul>
<p><em>Realism An inexpensive, reliable method of raising IQ is not available. The wish that it were is understandable, and to pursue the development of such methods is worthwhile. But to think that the available repertoire of social interventions can do the job if only the nation spends more money on them is illusory. No one yet knows how to raise low IQs substantially on a national level. We need to look elsewhere for solutions to the problems that the earlier chapters have described.</em></p>
<ul>
<li>Page 487 (location ~ 7467-7470)</li>
</ul>
<p><em>One reason is that disadvantaged students have been “in” and gifted students “out” for thirty years. Even in the 1990s, only one-tenth of 1 percent of all the federal funds spent on elementary and secondary education go to programs for the gifted. Because success was measured in terms of how well the average and below-average children performed, American education was dumbed down: Textbooks were made easier, and requirements for courses, homework, and graduation were relaxed. These measures may have worked as intended for the average and below-average students, but they let the gifted get away without ever developing their potential.</em></p>
<ul>
<li>Page 488 (location ~ 7477-7481)</li>
</ul>
<p><em>In trying to build on this natural improvement, the federal government should support greater flexibility for parents to send their children to schools of their choosing, whether through vouchers, tax credits, or choice within the public schools. Federal scholarships should reward academic performance. Some federal funds now so exclusively focused on the disadvantaged should be reallocated to programs for the gifted. We urge primarily not a set of new laws but a change of heart within the ranks of educators. Until the latter half of this century, it was taken for granted that one of the chief purposes of education was to educate the gifted—not because they deserved it through their own merit but because, for better or worse, the future of society was so dependent on them. It was further understood that this education must aim for more than technical facility. It must be an education that fosters wisdom and virtue through the ideal of the “educated man.” Little will change until educators once again embrace this aspect of their vocation.</em></p>
<ul>
<li>Page 489 (location ~ 7486-7494)</li>
</ul>
<p><em>It seems self-evident: Education is what intelligence is most obviously good for. One ideal of American education is to educate everyone to his or her potential. The students with the most capacity to absorb education should get the most of it—most in years, breadth, depth, and challenge. But what should be self-evident is not. For thirty years, IQ has been out of fashion among American educators, and the idea that people with the most capacity to be educated should become the most educated sounds dangerously elitest. It needs to be said openly: The people who run the United States—create its jobs, expand its technologies, cure its sick, teach in its universities, administer its cultural and political and legal institutions—are drawn mainly from a thin layer of cognitive ability at the top. (Remember—just the top 1 percent of the American population consists of 2.5 million people.) It matters enormously not just that the people in the top few centiles of ability get to college (almost all of them do, as we described in Chapter 1) or even that many of them go to elite colleges but that they are educated well. One theme of this chapter is that since the 1960s, while a cognitive elite has become increasingly segregated from the rest of the country, the quality of the education they receive has been degraded. They continue to win positions, money, prestige, and success in competition with their less gifted fellow citizens, but they are less well educated in the ways that make smart children into wise adults.</em></p>
<ul>
<li>Page 489 (location ~ 7497-7507)</li>
</ul>
<p><em>A few years ago, the Wall Street Journal devoted its op-ed page to a reproduction of an examination administered by Jersey City High School in 1885.1 It consisted of questions such as the following: Find the product of 3 + 4x + 5x2 - 6x3 and 4 - 5x - 6x2. Write a sentence containing a noun used as an attribute, a verb in the perfect tense potential mood, and a proper adjective. Name three events of 1777. Which was the most important and why? The test was not for high school graduation (which would be impressive enough) but for admission to Jersey City High School. Fifteen-year-olds were supposed to know the answers to these questions. Of course, not many people went to high school in 1885. But could even the cream of the 15-year-olds in Jersey City’s middle schools pass that exam today? It seems unlikely. Bits of national memorabilia like this reinforce an impression that is nearly universal in this country: American elementary and secondary education used to be better. The 1983 report by the Department of Education, A Nation at Risk, said so most famously, concluding that “we have, in effect, been committing an act of unthinking, unilateral educational disarmament.”2 Its chairman concluded flatly that “for the first time in the history of our country, the educational skills of one</em></p>
<ul>
<li>Page 491 (location ~ 7516-7529)</li>
</ul>
<p><em>A few years ago, the Wall Street Journal devoted its op-ed page to a reproduction of an examination administered by Jersey City High School in 1885.1 It consisted of questions such as the following: Find the product of 3 + 4x + 5x2 - 6x3 and 4 - 5x - 6x2. Write a sentence containing a noun used as an attribute, a verb in the perfect tense potential mood, and a proper adjective. Name three events of 1777. Which was the most important and why? The test was not for high school graduation (which would be impressive enough) but for admission to Jersey City High School. Fifteen-year-olds were supposed to know the answers to these questions. Of course, not many people went to high school in 1885. But could even the cream of the 15-year-olds in Jersey City’s middle schools pass that exam today? It seems unlikely. Bits of national memorabilia like this reinforce an impression that is nearly universal in this country: American elementary and secondary education used to be better. The 1983 report by the Department of Education, A Nation at Risk, said so most famously, concluding that “we have, in effect, been committing an act of unthinking, unilateral educational disarmament.”2 Its chairman concluded flatly that “for the first time in the history of our country, the educational skills of one generation will not surpass, will not equal, will not even approach, those of their parents.”3</em></p>
<ul>
<li>Page 491 (location ~ 7516-7530)</li>
</ul>
<p><em>Fewer than 60 percent of American 17-year-olds could correctly answer the item, “A hockey team won five of its 20 games. What percent of the games did it win?”8 More than 60 percent of adults in their early twenties cannot synthesize the main argument of a newspaper article.9 Forty-four percent of adult Americans cannot understand “help wanted” ads well enough to match their qualifications with the job requirements. Twenty-two percent cannot address a letter well enough to make sure the post office can deliver it.10</em></p>
<ul>
<li>Page 492 (location ~ 7541-7545)</li>
</ul>
<p><em>With qualifications that the chapter will explain, we associate ourselves with their findings. According to every longitudinal measure that we have been able to find, there is no evidence that the preparation of the average American youth is worse in the 1990s than it has ever been. Considerable evidence suggests that, on the contrary, education for the average youth has improved steadily throughout the twentieth century except for a period of decline in the late 1960s and early 1970s (which justified to some degree the alarming conclusions of the early 1980s) but from which the educational system has already fully recovered.</em></p>
<ul>
<li>Page 494 (location ~ 7561-7566)</li>
</ul>
<p><em>A third source is the Iowa Test of Educational Development (ITED), a well-validated test, equated for stability from year to year, that has been administered to virtually a 100 percent sample of Iowa’s high school students for fifty years. What may one learn from rural, white Iowa? For examining trends in educational outcomes over time, quite a bit. Iowa’s sample of students provides socioeconomic variance—even Iowa has single-parent families and welfare recipients. Paradoxically, Iowa’s atypical racial homogeneity (the population was more than 97 percent non-Latino white throughout the period we are discussing) is an advantage for a longitudinal analysis by sidestepping the difficulties of analyzing trends for populations that are changing in their ethnic composition. In examining Iowa’s test scores over time, we may not be able to make judgments about how the education of minorities has changed but we have a good view of what happened over the last several decades for the white population. Test scores for high school students in Iowa increased from the early 1940s to the mid-1960s, dropped sharply from 1966 to 1978, but then rebounded, as shown in the figure below. We show the ninth-grade scores, which have been least affected by changes in dropout rates during the last fifty years. They show a steep rise through 1965 and an equally steep rise after 1977, reaching new heights from 1983 onward.22 The improvement has been substantial—on the order of half a standard deviation since the mid-1970s, and about .2 standard deviation above the previous high in 1965. The increase of 5.3 points from 1942 to 1992 may be interpreted as approaching one standard deviation. Evidence from other, independent sources is consistent with</em></p>
<ul>
<li>Page 496 (location ~ 7604-7617)</li>
</ul>
<p><em>A third source is the Iowa Test of Educational Development (ITED), a well-validated test, equated for stability from year to year, that has been administered to virtually a 100 percent sample of Iowa’s high school students for fifty years. What may one learn from rural, white Iowa? For examining trends in educational outcomes over time, quite a bit. Iowa’s sample of students provides socioeconomic variance—even Iowa has single-parent families and welfare recipients. Paradoxically, Iowa’s atypical racial homogeneity (the population was more than 97 percent non-Latino white throughout the period we are discussing) is an advantage for a longitudinal analysis by sidestepping the difficulties of analyzing trends for populations that are changing in their ethnic composition. In examining Iowa’s test scores over time, we may not be able to make judgments about how the education of minorities has changed but we have a good view of what happened over the last several decades for the white population. Test scores for high school students in Iowa increased from the early 1940s to the mid-1960s, dropped sharply from 1966 to 1978, but then rebounded, as shown in the figure below. We show the ninth-grade scores, which have been least affected by changes in dropout rates during the last fifty years. They show a steep rise through 1965 and an equally steep rise after 1977, reaching new heights from 1983 onward.22 The improvement has been substantial—on the order of half a standard deviation since the mid-1970s, and about .2 standard deviation above the previous high in 1965. The increase of 5.3 points from 1942 to 1992 may be interpreted as approaching one standard deviation.</em></p>
<ul>
<li>Page 496 (location ~ 7604-7616)</li>
</ul>
<p><em>Having questioned the widespread belief that high school education today is worse on average than it used to be, we now reverse course and offer some reasons for thinking that it has gotten worse for one specific group of students: the pool of youths in the top 10 to 20 percent of the cognitive ability distribution who are prime college material. To make this case, we will focus on the best-known educational trend, the decline in SAT scores. Visually, the story is told by what must be the most frequently published trendlines in American educational circles, as shown below.25 The steep drop from 1963 to 1980 is no minor statistical fluctuation. Taken at face value, it tells of an extraordinarily large downward shift in academic aptitude—almost half a standard deviation on the Verbal, almost a third of a standard deviation on the Math.</em></p>
<ul>
<li>Page 498 (location ~ 7634-7641)</li>
</ul>
<p><em>From 1976 to 1993, the real white losses were no more than a few additional points on the Verbal. On the Math, white scores improved about three or four points in real terms after changes in the pool are taken into account. Or in other words, when everything is considered, there is reason to conclude that the size of the drop in the SAT as shown in that familiar, unsophisticated graphic with which we opened the discussion is for practical purposes the same size and shape as the real change in the academic preparation of white college-bound SAT test takers. Neither race, class, parental education, composition of the pool, nor gender can explain this decline of forty-odd points on the Verbal score and twenty-odd points on the Math for the white SAT-taking population during the 1960s and 1970s. For whatever reasons, during the 1960s America stopped doing as well intellectually by the core of students who go to college. Rather than democratization, the decline was more probably due to leveling down, or mediocritization: a downward trend of the educational skills of America’s academically most promising youngsters toward those of the average student. The net drop in verbal skills was especially large, much larger than net drop in math skills. It affected even those students with the highest levels of cognitive ability.</em></p>
<ul>
<li>Page 500 (location ~ 7665-7674)</li>
</ul>
<p><em>The SAT score decline does underscore a frustrating, perverse reality: However hard it may be to raise IQ among the less talented with discrete interventions, as described in Chapter 17, it may be within the capability of an educational system—probably with the complicity of broader social trends—to put a ceiling on, or actually dampen, the realized intelligence of those with high potential.</em></p>
<ul>
<li>Page 501 (location ~ 7676-7679)</li>
</ul>
<p><em>The case for a drop in the Verbal scores among the brightest can be made without subtle analysis. In 1972, 17,560 college-bound seniors scored 700 or higher on the SAT-Verbal. In 1993, only 10,407 scored 700 or higher on the Verbal—a drop of 41 percent in the raw number of students scoring 700 and over, despite the larger raw number of students taking the test in 1993 compared to 1972.31 Dilution of the pool (even if it were as real as legend has it) could not account for smaller raw numbers of high-scoring students. But we may make the case more systematically. The higher the ability level, the higher the proportion of students who take the SAT. At the 700 level and beyond, the proportion approaches 100 percent and has probably been so since the early 1960s (see Chapter 1). That is, almost all 17-year-olds who would score above 700 if they took the SAT do in fact take the SAT at some point in their high school career, either because of their own ambitions, their parents’, or the urging of their teachers and guidance counselors.</em></p>
<ul>
<li>Page 502 (location ~ 7684-7692)</li>
</ul>
<p><em>The good news is that the mathematics score of the top echelon of American students has risen steeply since hitting its low point in 1981. Given all the attention devoted to problems in American education, this finding is worth lingering over for a moment. In a period of just twelve years, from 1981 to 1993, the proportion of 17-year-olds scoring over 700 on the SAT-Math test increased by 143 percent. This dramatic improvement during the 1980s is not explainable by any artifact that we can identify, such as having easier Math SAT questions.33 Nor is it due to the superior math performance of Asian-American students and their increase as a proportion of the SAT population. Asian-Americans are still such a small minority (only 8 percent of test takers in 1992) that their accomplishments cannot account for much of the national improvement. The upward bounce in the Math SAT from 1981 through 1992 was a robust 104 percent among whites.34 Now let us turn to the less happy</em></p>
<ul>
<li>Page 502 (location ~ 7695-7703)</li>
</ul>
<p><em>Our explanation is consistent with the facts as we understand them, but we should emphasize that our explanation is interpretive as well. It goes like this: Since the late 1970s, the public dissatisfaction about the state of American elementary and secondary education has produced some changes. From 1982 to 1987, for example, the proportion of high school graduates who completed a solid program of four years of English, three of social sciences, three of the hard sciences, and three of math more than doubled.</em></p>
<ul>
<li>Page 506 (location ~ 7749-7753)</li>
</ul>
<p><em>The same dynamics provide a hypothesis for explaining why the rebound was more complete for the nation’s overall student population than for the SAT population. A textbook that is dumbed down is in fact helpful to the mediocre student. A recent study of six textbooks over a twelve-year period demonstrated that they had indeed been simplified, and students performed significantly better on the current, dumbed-down texts.46 Subjects that were traditionally not included in the curriculum for the lower end of the distribution—for example, exposure to serious literature—have now been so simplified as to be accessible to almost all. The same dumbed-down textbook can quite easily have a depressing effect on the talented student’s development. And while the textbooks were being simplified, subjects that would push the best students to their limits, such as the classical languages, were all but dropped.</em></p>
<ul>
<li>Page 508 (location ~ 7785-7792)</li>
</ul>
<p><em>The Neglect of the Gifted Another factor in the declining capabilities of America’s brightest students is that the decline occurred when, in policy circles, disadvantaged students were “in” and gifted students were “out.” When the first significant aid went to secondary education at the end of the Eisenhower years, it was for the brightest students who might become scientists or engineers. In 1965, with the passage of the Elementary and Secondary Education Act of 1965 (ESEA), the funding priority turned 180 degrees, and it has remained anchored in the new position ever since. As of 1993, the ESEA authorized forty-six programs with budgets that added up to $8.6 billion. Most of these programs are specifically designated for students in low-income areas and students with special educational needs. Even the programs that might apply to any sort of student (improvements in science and mathematics education, for example) often are worded in ways that give preference to students from low-income areas. Another set of programs are for support services. And, finally, there are programs designated for the gifted and talented. This is the way that the $8.6 billion budget broke out for fiscal 1993:47 Programs for the disadvantaged 92.2% Programs that might benefit any student 5.6% Support and administration of ESEA programs 2.1% Programs for the gifted 0.1% This breakdown omits other federal programs with large budgets aimed at the education of the disadvantaged—more than $2 billion for Head Start (funded by the Department of Health and Human Services, not the Department of Education), more than $3 billion for job training programs, plus a scattering of others.48</em></p>
<ul>
<li>Page 509 (location ~ 7795-7812)</li>
</ul>
<p><em>Disadvantaged as used by three decades of administrators and school boards using ESEA funds has consistently meant not just students who are poor or living in an inner-city neighborhood but students who exhibit learning problems. Programs for the intellectually gifted but otherwise disadvantaged attract little support and, occasionally, hostility. A case in point is Banneker High School in Washington, D.C., a special academic high school in the middle of the black northeast section of the city, established by a former superintendent of schools with the school board’s reluctant permission in 1981. The establishment of Banneker High followed a proud tradition in Washington, where once-elite Dunbar High had turned out many of the nation’s black leaders. But throughout the 1980s, Banneker was under-funded and repeatedly threatened with closure. Banneker was “elitest,” said an influential school board member, a luxury for parents who “had their children in private school and can no longer afford it and bring them back to essentially a private school at the public expense.”49 Banneker’s “elitest” admissions policy? Applicants had to write an essay, be interviewed, be in the top 18 percent of their class, and read and compute at grade level—a broad conception of “elitist” indeed. Throughout it all, teachers competed to teach at Banneker and students competed to attend. Banneker placed large proportions of its graduates in college and had no significant problems with discipline, drugs, crime, or the other ills of contemporary urban schools.50 And yet, as we write, Banneker continues to be barely tolerated by the school system. Banneker’s story has numerous counterparts in other urban centers. Funds for the economically and socially disadvantaged have meant, for practical purposes, funds concentrated on the cognitively disadvantaged as well.</em></p>
<ul>
<li>Page 510 (location ~ 7814-7828)</li>
</ul>
<p><em>The United States has not yet completed the first half-century of human history in which universal secondary education became a goal. It was not until 1963 that the dropout rate fell below 30 percent of all 17-year-olds. Already we have seen improving performance in academic tests for the average student as educational opportunities have spread across the population. At about the same time, educators—and educational critics—stopped thinking hard or openly about variation in intellectual abilities. It is time to reopen the issue. What constitutes educational success for persons at various points along the cognitive ability distribution? The aspirations of educational reformers should be accompanied by a realistic and systematic assessment of where the room for improvement lies, taking the cognitive distribution into account.</em></p>
<ul>
<li>Page 512 (location ~ 7845-7850)</li>
</ul>
<p><em>A second point is that the average American student has little incentive to work harder than he already does in high school. Economist John Bishop has taken the lead in making this case, emphasizing two points.56 Bishop first observes that a demanding high school curriculum is not necessary for admission to most colleges. For most college-bound students, finding the money is harder than amassing the necessary high school record. And it’s their parents who typically need to find the money. Why bother to take tough courses? This is true even of talented students applying to selective schools; only a handful of schools at the summit routinely turn away students with SATs in the 1200s and up (see Chapter 1). A student who tests reasonably well (he knows this by the time he gets to high school) and doesn’t have his sights set on the likes of Yale does not have to be too careful about which courses to take as long as his grades are decent. Only youngsters who aspire to colleges that usually take students with higher scores than their own have a strong incentive to study hard—and however common this situation may seem at the school attended by the children of most of our readers, it describes a minuscule proportion of the national high school population.</em></p>
<ul>
<li>Page 514 (location ~ 7871-7880)</li>
</ul>
<p><em>Many employers assume that the high school diploma no longer means much more than that the student warmed a seat for twelve years. Others are willing to look at high school transcripts as part of the hiring process, but though schools are legally obligated to respond to requests for transcripts, hardly any transcripts ever reach the employer, and those that do usually arrive so late</em></p>
<ul>
<li>Page 514 (location ~ 7881-7884)</li>
</ul>
<p><em>Educational reformers in the 1960s and 1970s were confident that their ideas were good things to do. They were impatient with the conservatism of local school districts. They turned to a responsive White House, Congress, and Supreme Court, achieved many of their objectives, and thereby contributed to a historic shift in American education. On balance, the turn was for the worse as far as academic excellence was concerned, but that doesn’t mean the ideas were bad in themselves. Ideas such as more racial integration in the schools, more attention to the needs of disadvantaged students, and more equitable treatment of students in disciplinary matters do not seem less obviously “good” to us than ideals such as more homework and a longer school year. It was not the core ideas that were at fault (in most instances) but some basic problems that go with reforming American education at a national level. We characterize the situation as follows: Slow improvement seems to have been a natural part of twentieth-century American education until the 1960s. This slow improvement had great inertia, in the sense that a slow-moving freight train has inertia. It is very difficult for an outside force to accelerate the freight train but comparatively easy for an outside force to derail it. In the United States, the federal government tends to be an outside force, more often derailing than pushing along, for reasons that are peculiarly American. In countries such as France and Germany, with more homogeneous populations and more authoritarian and unapologetically elitest educational traditions, the national government can get away with centralized school systems that educate their brightest youth well. In the United States, it cannot. Federal standards, federal rules, and federal curricula, were they to be established, would inevitably be watered down and educational goals would be compromised with social and political ones. The federal government responds to pushes from all sides and gets equally nervous about affirming the genius of either Huck Finn or Charles Darwin. Powerful teachers’ organizations will not tolerate certification tests that flunk large numbers of teachers. Organizations that represent minority groups will not tolerate national educational standards that cause large numbers of minority children to flunk. These are political facts of life that will not change soon, no matter who is in the White House.</em></p>
<ul>
<li>Page 516 (location ~ 7910-7927)</li>
</ul>
<p><em>A federal prize scholarship program. This is one instance in which a specific, federal program could do some good in restoring educational excellence. As the law stands, federal scholarships and loan assistance are awarded almost exclusively on the basis of financial need, leaving the administration of standards to the colleges that admit and teach the students. That program may continue as is, but Congress should add a second program, not contingent on financial need but awarded competitively—for example, a flat one-time award of $20,000 to the 25,000 students in the country earning the top scores on standardized tests of academic achievement, over and above whatever scholarship assistance the student was receiving from other sources. How much would such “American Scholars” (the Congress might call them) cost? Five hundred million dollars a year—an amount equivalent to a rounding error in the national budget but one that would dramatically transform the signal that the federal government sends about the value it places on academic excellence.</em></p>
<ul>
<li>Page 519 (location ~ 7945-7952)</li>
</ul>
<p><em>Why should the federal government shift money from programs for the disadvantaged to programs for the gifted, when we know that a large portion of the gifted come from privileged families? Why not just support programs for the gifted who happen to come from poor families as well? In Part I, we went to some lengths to describe the dangers of a cognitive elite. And yet here we call for steps that could easily increase the segregation of the gifted from everyone else. Won’t programs for the gifted further isolate them? The answers to such questions have nothing to do with social justice but much to do with the welfare of the nation, including the ultimate welfare of the disadvantaged. The first point echoes a continuing theme of this book: To be intellectually gifted is indeed a gift. Nobody “deserves” it. The monetary and social rewards that accrue to being intellectually gifted are growing all the time, for reasons that are easily condemned as being unfair. Never mind, we are saying. These gifted youngsters are important not because they are more virtuous or deserving but because our society’s future depends on them. The one clear and enduring failure of contemporary American education is at the high end of the cognitive ability distribution. Ideally we would like to see the most gifted children receive a demanding education and attend school side by side with a wide range of children, learning firsthand how the rest of the world lives. But that option is no more available now than it was during the attempts to force the racial integration of urban schools in the 1960s and 1970s. The nation’s elementary and secondary schools are highly segregated by socioeconomic status, they will tend to become more so in the future, and the forces pushing these trends are so powerful, stemming from the deeply rooted causes that we described in Part I, that they can</em></p>
<ul>
<li>Page 520 (location ~ 7959-7973)</li>
</ul>
<p><em>Why should the federal government shift money from programs for the disadvantaged to programs for the gifted, when we know that a large portion of the gifted come from privileged families? Why not just support programs for the gifted who happen to come from poor families as well? In Part I, we went to some lengths to describe the dangers of a cognitive elite. And yet here we call for steps that could easily increase the segregation of the gifted from everyone else. Won’t programs for the gifted further isolate them? The answers to such questions have nothing to do with social justice but much to do with the welfare of the nation, including the ultimate welfare of the disadvantaged. The first point echoes a continuing theme of this book: To be intellectually gifted is indeed a gift. Nobody “deserves” it. The monetary and social rewards that accrue to being intellectually gifted are growing all the time, for reasons that are easily condemned as being unfair. Never mind, we are saying. These gifted youngsters are important not because they are more virtuous or deserving but because our society’s future depends on them. The one clear and enduring failure of contemporary American education is at the high end of the cognitive ability distribution. Ideally we would like to see the most gifted children receive a demanding education and attend school side by side with a wide range of children, learning firsthand how the rest of the world lives. But that option is no more available now than it was during the attempts to force the racial integration of urban schools in the 1960s and 1970s. The nation’s elementary and secondary schools are highly segregated by socioeconomic status, they will tend to become more so in the future, and the forces pushing these trends are so powerful, stemming from the deeply rooted causes that we described in Part I, that they can be reversed only by a level of state coercion that would be a cure far deadlier than the disease.</em></p>
<ul>
<li>Page 520 (location ~ 7959-7973)</li>
</ul>
<p><em>The educational deficit that worries us is symbolized by the drop in verbal skills on the SAT. What we call verbal skills encompass, among other things, the ability to think about difficult problems: to analyze, pick apart, disaggregate, synthesize, and ultimately to understand. It has seldom been more apparent how important it is that the people who count in business, law, politics, and our universities know how to think about their problems in complex, rigorous modes and how important it is that they bring to their thinking depth of judgment and, in the language of Aristotle, the habit of virtue. This kind of wisdom—for wisdom is what we need more of—does not come naturally with a high IQ. It has to be added through education, and education of a particular kind. We are not talking about generalized higher standards. Rather, we are thinking of the classical idea of the “educated man”—which we will amend to “educated person”—in which to be educated meant first of all to master a core body of material and skills. The idea is not wedded to the specific curriculum that made an educated man in the nineteenth-century British public school or in the Greek lyceum. But it is wedded to the idea of certain high intellectual goals. For example, to be an educated person meant being able to write competently and argue logically. Therefore, children were taught the inner logic of grammar and syntax because that kind of attention to detail was believed to carry over to greater precision of thinking. They were expected to learn Aristotle’s catalog of fallacies, because educators understood that the ability to assess an argument in everyday life was honed by mastering the formal elements of logic.</em></p>
<ul>
<li>Page 521 (location ~ 7978-7990)</li>
</ul>
<p><em>Educated, Not Credentialed If we have not already made it plain, let us state explicitly that we are proposing a traditional ideal of education, not glorifying academic credentials. To he an educated person as we use the term will ordinarily entail getting a degree, but that is incidental. Credentialism—unnecessarily limiting access to jobs to people with certain licenses and degrees—is part of the problem, not a solution. Because academic credentials are so overvalued, America shies away from accepting that many people have academic limitations—hence, the dumbing down that holds back the brightest youngsters.</em></p>
<ul>
<li>Page 523 (location ~ 8011-8016)</li>
</ul>
<p><em>There is no question that affirmative action has “worked,” in the sense that it has put more blacks and Latinos on college campuses than would otherwise have been there. But this success must be measured against costs. When students look around them, they see that blacks and Latinos constitute small proportions of the student population but high proportions of the students doing poorly in school. The psychological consequences of this disparity may be part of the explanation for the increasing racial animosity and the high black dropout rates that have troubled American campuses. In society at large, a college degree does not have the same meaning for a minority graduate and a white one, with consequences that reverberate in the workplace and continue throughout life. It is time to return to the original intentions of affirmative action: to cast a wider net, to give preference to members of disadvantaged groups, whatever their skin color, when qualifications are similar. Such a change would accord more closely with the logic underlying affirmative action, with the needs of today’s students of all ethnic groups, and with progress toward a healthy multiracial society.</em></p>
<ul>
<li>Page 525 (location ~ 8040-8048)</li>
</ul>
<p><em>Affirmative action is part of this book because it has been based on the explicit assumption that ethnic groups do not differ in the abilities that contribute to success in school and the workplace—or, at any rate, there are no differences that cannot be made up with a few remedial courses or a few months on the job. Much of this book has been given over to the many ways in which that assumption is wrong. The implications have to be discussed, and that is the purpose of this chapter and the next, augmented by an appendix on the evolution of affirmative action regulations (Appendix 7). Together, these materials constitute a longer discussion than we devote to any other policy issue, for two reasons. First, we are making a case that contradicts a received wisdom embedded in an intellectual consensus, federal legislation, and Supreme Court jurisprudence. If the task is to be attempted at all, it must be done thoroughly. Second, we believe affirmative action to be one of the most far-reaching domestic issues of our time—not measured in its immediate effects, but in its deep and pervasive impact on America’s understanding of what is just and unjust, how a pluralist society should be organized, and what America is supposed to stand for. In this chapter, the topic is the college campus. In Chapter 20, we discuss affirmative action in the workplace. In both chapters, we provide data as available on Asians and Latinos, but the analysis centers on blacks, as has the debate over affirmative action.</em></p>
<ul>
<li>Page 526 (location ~ 8061-8072)</li>
</ul>
<p><em>This ignorance about practice was revealed in 1991 by a law student at Georgetown University, Timothy Maguire, who had been hired to file student records.2 He surreptitiously compiled the entrance statistics for a sample of applicants to Georgetown’s law school and then published the results of his research in the law school’s student newspaper. He revealed that the mean on the Law School Aptitude Test (LSAT) differed by a large margin for accepted black and white students. In the storm that ensued, an official at the law school sent a letter to Maguire’s fellow students condemning his article. Black student groups called for Maguire’s expulsion. Hardly anyone would acknowledge that Maguire’s numbers even raised a legitimate issue. “Incomplete and distorted information about minority qualifications for admission into the Law Center renew the long-standing and intellectually dishonest myth that they are less qualified than their white counterparts to compete in school, perform on the job or receive a promotion,” wrote the authors of an op-ed article in the Washington Post,3 and that seemed to be the prevailing attitude. The numerical magnitude of the edge given to members of certain groups—the value assigned to the state of being black, Latino, female, or physically disabled—was not considered relevant.</em></p>
<ul>
<li>Page 527 (location ~ 8079-8089)</li>
</ul>
<p><em>The difference between black and white scores was less than 100 points at only one school, Harvard. It exceeded 200 points at nine schools, reaching its highest at Berkeley (288 points). Overall, the median difference between the white mean and the black mean was 180 SAT points, or, conservatively estimated, about 1.3 standard deviations.7 This would put the average black at about the 10th percentile of white students. In all but four schools, Asians were within 6 points of the white mean or above it, with a median SAT 30 points above the local white average, working out to about .2 standard deviations. Or in other words, the average Asian was at about the 60th percentile of the white distribution. This combination means that blacks and Asians have even less overlap than blacks and whites at most schools, with the median black at the 5th to 7th percentile of the distribution of Asian students. Data for Latinos (not shown in the figure) put them between blacks and whites, with a median of 129 points below the white mean, or about .9 standard deviation below the white mean in the typical case. The average Latino is therefore at about the 20th percentile of the distribution of white students.</em></p>
<ul>
<li>Page 530 (location ~ 8112-8121)</li>
</ul>
<p><em>We would prefer to have a sample of nonelite state universities represented in our data, but such numbers are closely guarded.9 The only data we have obtained come from the University of California at Davis, for 1979. The black-white difference then was 271 SAT points, and the Latino-white difference 211 points.10 The Asian mean at Davis was, atypically, 54 points below the white mean, the largest such difference we have found. The data from the University of Virginia and the two University of California campuses suggest that the gap between minorities and whites among freshmen at state universities may be larger than at the elite private schools. It is only a suggestion, given the limited data, but it also makes sense: Places like Harvard, Stanford, Yale, and MIT get first pick. Because the raw numbers of high-scoring black and Latino students are so small, the</em></p>
<ul>
<li>Page 531 (location ~ 8129-8136)</li>
</ul>
<p><em>We would prefer to have a sample of nonelite state universities represented in our data, but such numbers are closely guarded.9 The only data we have obtained come from the University of California at Davis, for 1979. The black-white difference then was 271 SAT points, and the Latino-white difference 211 points.10 The Asian mean at Davis was, atypically, 54 points below the white mean, the largest such difference we have found. The data from the University of Virginia and the two University of California campuses suggest that the gap between minorities and whites among freshmen at state universities may be larger than at the elite private schools. It is only a suggestion, given the limited data, but it also makes sense: Places like Harvard, Stanford, Yale, and MIT get first pick. Because the raw numbers of high-scoring black and Latino students are so small, the top schools dig deep into the thin layer of minority students at the top of the SAT distribution.</em></p>
<ul>
<li>Page 531 (location ~ 8129-8137)</li>
</ul>
<p><em>Complaints that Asian-American applicants were being subjected to reverse discrimination led eventually to a full-scale inquiry in the late 1980s by the federal Office for Civil Rights. Harvard, which was examined closely, was able to show that the SAT penalty of their Asian admitted students was accounted for by the smaller number of alumni children and athletes in the pool, and eventually got a clean bill of health, but the controversy remains at many other institutions.11 Brown responded to a report from its Asian-American Students Association by admitting the existence of “an extremely serious situation” and called for “immediate remedial measures.”12 At Berkeley, Stanford, Princeton, and other elite schools, special committees have investigated the issue, issuing reports that tend to exonerate their colleges of actual reverse discrimination but acknowledge shortcomings in keeping up with the revolution in Asian applicants.13 The underlying source of tension remains: Asians are an ethnic minority, many of whom, or whose parents, came to the United States under circumstances of extreme deprivation. Many suffered from racial prejudice. Whether or not they are treated differently from whites by elite universities, Asians are indisputably treated differently from every other nonwhite ethnic minority. University officials everywhere have been reluctant to confront this issue forthrightly.</em></p>
<ul>
<li>Page 531 (location ~ 8142-8154)</li>
</ul>
<p><em>Affirmative action has produced intense competition for the top black and Latino students. In the spring of 1992, Harvard reported that its “yield” of black students abruptly declined from the year before. The Harvard report suggested that the decline was due at least in part to the large financial incentives being offered to blacks by other colleges. One such black student, it was reported, received a straight grant of $85,000, plus $10,000 in annual travel budgets, from one of Harvard’s competitors in minority recruiting.14 An article in the New York Times provided more instances of a practice that increasingly includes the kind of enticements—full scholarships even for families with ample financial resources, free trips to visit the campus, recruiting visits, and promotional activities—that used to be reserved for star high school athletes. “As a result, a number of college officials privately accuse each other of ‘stealing’ black students,” the Times reporter noted.</em></p>
<ul>
<li>Page 532 (location ~ 8155-8163)</li>
</ul>
<p><em>The summary statement about affirmative action in undergraduate institutions is that being either a black or a Latino is worth a great deal in the admissions process at every undergraduate school for which we have data. Even the smallest known black-white difference (95 points at Harvard) represents close to a standard deviation for Harvard undergraduates. The gap in most colleges is so large that the black and white student bodies have little overlap. The situation is less extreme for Latino students but still severe. Asian students appear to suffer a penalty for being Asian, albeit a small one on the average. We have seen no data that would dispute this picture. If such data exist, perhaps this presentation will encourage their publication.</em></p>
<ul>
<li>Page 533 (location ~ 8171-8176)</li>
</ul>
<p><em>The overall Asian mean corresponds to the 38th percentile on the white distribution, evidence of modest affirmative action on behalf of Asian applicants in the law schools. Affirmative Action Weights: The Law School Aptitude Test Ethnic Group Difference from White Mean, in SDs Asian/Pacific -.32 Blacks -1.49 Latinos -1.01 Source: Barnes and Carr 1993. The table above is for the national population of first-year law students. To assess the effects of affirmative action, it would be preferable to have data from individual law schools. At upper reaches of the LSAT distribution, from which the elite law schools drew most of their students, there was even less overlap between whites and blacks than in the SAT pool. More than 1,100 registered white law students had scores of 170 or higher on a scale going from 120 to 180, compared to three blacks.</em></p>
<ul>
<li>Page 534 (location ~ 8181-8194)</li>
</ul>
<p><em>As in the case of law schools, the black medical student pool is even more severely depleted at the top end of the range than it is in undergraduate schools, with important implications for the gap in the elite schools. In none of the three subtests did more than 19 blacks score in the 12 to 15 range (on a scale that goes from 1 to 15), compared to 1,146, 1,469, and 853 whites (for the biological sciences, physical sciences, and verbal reasoning tests, respectively).18 In practical terms, several of the elite schools can fill their entire class with white students in the top range, but only the one or two most elite schools can hope to have a significant number of black students without producing extremely large black-white differences, comparable to those reported for elite law schools. Other studies have published data on medical school admissions, expressed in terms of the odds of being accepted to medical school for different minorities. All tell similar stories to ours.19</em></p>
<ul>
<li>Page 537 (location ~ 8226-8234)</li>
</ul>
<p><em>Applicants to Graduate Schools   Difference from the White Mean, in SDs Ethnic Group Verbal Quantitative Analytical Asian/Pacific -.37 +.52 -.15 Black -1.20 -1.19 -1.29 Latino -.74 -.46 -.54 Source: Wah and Robinson, 1990, Table 2.2 The summary statement is that the ethnic gaps in objective test scores observed in undergraduate institutions are matched, and perhaps exceeded, in graduate and professional schools. If data become available from individual schools, this question can be answered definitively.</em></p>
<ul>
<li>Page 538 (location ~ 8243-8257)</li>
</ul>
<p><em>The institution also has interests beyond daily campus life. Admitting the children of its faculty and of its most generous alumni may add little that is distinctive to the student body, for example, but their parents make a big difference to the health and quality of the institution, and keeping them happy is important. Beyond the college gates is society at large. Universities cannot disregard what the broader community thinks of them, and so they must be sensitive to the currents of their time. The political pressure (let alone the legal requirement) for some level of affirmative action in the universities has been irresistible.</em></p>
<ul>
<li>Page 540 (location ~ 8274-8278)</li>
</ul>
<p><em>If it is admissible to augment the presence of some racial or ethnic minorities solely because they serve the interests of the university, is it not also appropriate to limit the presence of minorities for the same reason? It is a relevant question, for, while limits for Jews may be largely behind us, limits for Asians may be upon us. Furthermore, one cannot avoid the problem by arguing that it is appropriate to have floors for certain groups but inappropriate to have ceilings for others. Making more room for one group must reduce the room for others. Instinctively, one wishes for morally stronger justifications for affirmative action than institutional interests. Two are available.</em></p>
<ul>
<li>Page 540 (location ~ 8280-8285)</li>
</ul>
<p><em>The social utility criterion may say yes, for this young man is eventually going to influence the lives of the millions of people in his own country. He may be drawn into issues that could affect international peace and prosperity. Princeton makes a contribution to human happiness if it can help the crown prince develop into a thoughtful and humane adult. The same kind of calculation bedevils professional schools in choosing among men and women. For example, if it is empirically true that women are more likely than men to leave a profession, there is an authentic question of resources to be considered when selecting who shall be trained in that profession. Given that the good called a medical education is severely limited, how important is the ethical nudge in the direction of using scarce resources efficiently? Conversely, how important is it to get women into these professions so that, in the future, it will be easier for more of them to pursue such careers? Suppose now that it is again Princeton choosing between two candidates, one black and one white. Both are from affluent professional families, so socioeconomic disadvantage is not an issue. The white has higher test scores and (just to make the case still plainer) more glowing references than the black candidate. Both plan to become attorneys. In some sense, the white candidate “deserves” admission more. But who is going to provide more social “value-added”? Adding one more white attorney to the ranks of prominent attorneys, or adding one more black one? Princeton could reasonably choose the black candidate on grounds that only by expanding the size of the next generation of minority lawyers, physicians, businessmen, and professors can society attain racial equality at the higher socioeconomic and professional levels. Only when equality is reached at those higher levels will minority youths routinely aspire to such careers. And, the argument continues, only when the aspirations for success and their fulfillment are thus equalized will we reach the kind of real racial equality that will eventually show up in test scores as well as everything else.</em></p>
<ul>
<li>Page 541 (location ~ 8288-8303)</li>
</ul>
<p><em>We have reviewed the rationales for affirmative action without even mentioning the two most commonly made points: first, that the real difference in academic ability between minority and white candidates is much smaller than the difference as measured by test scores, and, second, that gradations in ability do not count for much after a certain threshold of ability has been met. This first point is based on allegations of cultural bias in the tests, covered in Chapter 13 and Appendix 5. As readers will by now be aware, much research argues strongly against: it. The second point, often expressed by university officials with the words “everyone we admit can do the work,” is true in the limited sense that students with comparatively low levels of ability can get passing grades. It is not correct in any broader sense. Higher scores predict better academic performance throughout the range of scores. There is no reason to think that a threshold exists above which differences in tested ability have little effect on the quality of the student body, student performance, and the nature of student interactions.</em></p>
<ul>
<li>Page 544 (location ~ 8328-8336)</li>
</ul>
<p><em>“Scarsdale” denotes any applicant from an upscale family. “South Bronx” denotes a disadvantaged minority youth, and “Appalachia” denotes a disadvantaged white youth. Each cell in the table corresponds to a pair of applicants—a white and a minority—from either high or low socioeconomic and cultural circumstances. Starting at the lower right and going clockwise around the table, the categories are: (1) a minority applicant from a disadvantaged background and a white from a privileged background; (2) a minority and a white applicant, both from disadvantaged backgrounds; (3) a minority applicant from a privileged background and a white from a disadvantaged background, and (4) a minority and a white applicant, both from privileged backgrounds.</em></p>
<ul>
<li>Page 545 (location ~ 8347-8352)</li>
</ul>
<p><em>The main purpose of the exercise we have just conducted is to suggest that admissions committees should be permitted to behave a little more like our imaginary one than they are at present, given the pressures from higher levels in the university. If university officials think that these data are not adequate for the purposes we have used them, or if they think that we have misrepresented the affirmative action process, there is an easy remedy. Universities across the country have in their admissions files all the data needed for definitive analyses of the relationship of ethnicity, socioeconomic disadvantage, and academic ability—test data, grade data, parental background data in profusion—for students who were accepted and students who were rejected, students who enrolled and students who did not. At many schools, the data are already in computer files, ready for analysis. They may readily be made available to scholars without compromising confidentiality. Our proposition is that affirmative action as it is currently practiced in America’s universities has lost touch with any reasonable understanding of the logic and purposes of affirmative action.</em></p>
<ul>
<li>Page 550 (location ~ 8430-8438)</li>
</ul>
<p><em>In 1967, black enrollment of 20-24-year-olds suddenly shot up, and continued to rise steeply through the mid-1970s. White enrollment experienced no comparable surge during that period. The most plausible cause of the surge is the aggressive affirmative action that began in the mid-1960s. On the other hand, this figure previews a problem we will discuss at more length in the next chapter: Whatever initial impetus was provided by affirmative action, it soon lost momentum. Black enrollment in the early 1990s was higher than the trendline from 1950 to 1966 would have predicted, but some sort of evening-out process seems to have set in as well. Black enrollment dropped during the late 1970s, recovered modestly during the early and mid-1980s, then increased sharply at the end of the decade. The level of black college enrollment as of the early 1990s is higher than at any other time in history.</em></p>
<ul>
<li>Page 551 (location ~ 8446-8452)</li>
</ul>
<p><em>The costs of affirmative action have been measured in different ways.31 Relatively little of this commentary has involved the costs to whites. There are such costs—some number of white students are denied places at universities they could otherwise have won, because of affirmative action.32 But most of the concern about affirmative action comes down to this question: How much harm is done to minority self-esteem, to white perceptions of minorities, and ultimately to ethnic relations by a system that puts academically less able minority students side by side with students who are more able? There are no hard-and-fast answers, but at least we can discuss the magnitude of the problem from the student’s eye view and from the vantage point of the general population.</em></p>
<ul>
<li>Page 552 (location ~ 8460-8467)</li>
</ul>
<p><em>The answer seems as if it is self-evidently no. But now we switch to the view from ground level: from the vantage point of the college student who attends classes, listens to fellow students talk in class, observes what is going on in the library and the labs, and gossips with friends about other students. Let us imagine three observations of the kind that students commonly make in the normal course of campus life: the racial mix of the entire student population, the students who stand out because they seem to be especially out of place in a university, and the students who stand out because they seem to be especially smart.</em></p>
<ul>
<li>Page 553 (location ~ 8479-8483)</li>
</ul>
<p><em>RACIAL ANIMOSITY. Racial clashes on campuses began to surface in the early 1980s and apparently have been growing since then, with the great bulk of the difficulties between whites and blacks.35 A plausible explanation is that whites resent blacks, who are in fact getting a large edge in the admissions process and often in scholarship assistance and many of whom, as whites look around their own campus and others, “don’t belong there” academically. Some whites begin to act out these resentments. Blacks perceive the same disproportions and resentments, then conclude that the college environment is hostile to them. We will not pursue this line of argument. Rather, we refer our readers to a growing literature by black scholars who have couched it in the context of their own experience.36 It is plain that affirmative action fosters differences in the distribution of academic ability across races in the communities on college campuses. Students are not imagining these differences.</em></p>
<ul>
<li>Page 555 (location ~ 8501-8510)</li>
</ul>
<p><em>In 1985, the average SAT-Math score for a black male accepted at MIT was 659, a score that put him above the 90th percentile of all students taking the SAT but below the 25th centile of all students at MIT.39 The dropout rate for black students at MIT in the mid-1980s was 24 percent, compared to 14 percent for whites.40 Even if the average MIT black freshman in 1985 could indeed do the work there in some objective sense, getting discouraged about one’s capacity to compete in an environment may be another cost of affirmative action, a phenomenon that has been described anecdotally by a number of observers, black and white alike.</em></p>
<ul>
<li>Page 556 (location ~ 8520-8526)</li>
</ul>
<p><em>One may lament this (people ought to be judged on their own merits, not by where they went to school), but it also has a positive side. Historically, that little sentence, “I have a [solid degree] from [a well-regarded university],” jolted you loose from any number of stereotypes that the person you encountered might have had of you. The reason it did so was that a well-regarded college had a certain set of standards, and its graduates presumably met those standards. No matter what one’s view is of “credentialing” in theory, the greatest beneficiaries of credentialing are those who are subject to negative stereotypes. One of the great losses of preferential affirmative action has been to dilute the effects of the university credential for some minorities. Today the same degree from the same university is perceived differently if you have a black face or a white one. This is not a misguided prejudice that will be changed if only people are given more accurate information about how affirmative action really works. On the contrary, more accurate information about how affirmative action really works confirms such perceptions.</em></p>
<ul>
<li>Page 557 (location ~ 8529-8537)</li>
</ul>
<p><em>We urge that affirmative action in the universities be radically modified, returning to the original conception. Universities should cast a wide net in seeking applicants, making special efforts to seek talent wherever it lives—in the black South Bronx, Latino Los Angeles, and white Appalachia alike. In the case of two candidates who are fairly closely matched otherwise, universities should give the nod to the applicant from the disadvantaged background. This original sense of affirmative action seems to us to have been not only reasonable and fair but wise. What does “closely matched” mean in terms of test scores? We have no firm rules, but as a guideline, admissions officers might aim for an admissions policy such that no identifiable group (such as a racial minority) has a mean that is more than half a standard deviation below the rest of the student body.42 This guideline is by no means demanding. In effect, it asks only that the average minority student is at the 30th centile of the white distribution. Perhaps experience would prove that this is not closely matched enough. But at least let us move toward that standard and see how it works. The present situation, with black students averaging well over a full standard deviation below the white mean, sometimes approaching two standard deviations, is so far out of line with any plausible rationale that universities today cannot publish the data on their admitted students and hope to persuade the public (or specialists in education) that their policies are reasonable.</em></p>
<ul>
<li>Page 558 (location ~ 8554-8566)</li>
</ul>
<p><em>We must put such topics as questions because that era has been ignored. We suggest this possibility: American universities once approached the ideal in their handling of race on the campus, and there is no reason why they could not do so again. Fewer blacks would be at Berkeley or Yale if there were no affirmative action. But admitting half as many black students to Yale does not mean that the rejected ones will not go to college; it just means that they will not go to Yale. For some individuals who are not chosen, this will be a loss, for others a blessing, but it is a far different choice from “college” versus “no college.” It is not even clear how much the goals of diversity would be adversely affected for the system as a whole. If affirmative action in its present form were ended, the schools at the very top would have smaller numbers of blacks and some other minorities on their campuses, but many other schools in the next echelons would add those students, even as they lost some of their former students to schools further down the line. And at every level of school, the gap in cognitive ability between minorities and whites would shrink. Ending affirmative action as it is currently practiced will surely have other effects. Affirmative action does in fact bring a significant number of minority students onto campuses who would not otherwise</em></p>
<ul>
<li>Page 560 (location ~ 8577-8587)</li>
</ul>
<p><em>Have the job discrimination regulations worked? The scholarly consensus is that they had some impact, on some kinds of jobs, in some settings, during the 1960s and into the 1970s, but have not had the decisive impact that is commonly asserted in political rhetoric. It also appears, however, that since the early 1960s blacks have been overrepresented in white collar and professional occupations relative to the number of candidates in the IQ range from which these jobs are usually filled, suggesting that the effects of affirmative action policy may be greater than usually thought. The successes of affirmative action have been much more extensively studied than the costs. One of the most understudied areas of this topic is job performance. The scattered data suggest that aggressive affirmative action does produce large racial discrepancies in job performance in a given workplace. It is time that this important area be explored systematically. In coming to grips with policy, a few hard truths have to be accepted. First, there are no good ways to implement current job discrimination law without incurring costs in economic efficiency and fairness to both employers and employees. Second, after controlling for IQ, it is hard to demonstrate that the United States still suffers from a major problem of racial discrimination in occupations and pay.</em></p>
<ul>
<li>Page 561 (location ~ 8599-8609)</li>
</ul>
<p><em>If an employer uses a test in the employment process and the results of that test lead to different results for different protected groups (mainly blacks, Latinos, and women) that employer faces the prospect of lawsuits, fines, and damages that could cost the company millions—perhaps tens of millions—of dollars. Employers can protect themselves in three ways. First, they may decline to use tests. Nevertheless, they will still be vulnerable if their alternative hiring process has disparate impact (the legal phrase) on the hiring of different groups. Second, they can try to construct a test that has an urgent economic justification and a manifest, direct relationship with the skills required by the job. A general ability test is always unacceptable. Usually off-the-shelf tests of any kind will also be found unacceptable until they are validated for the particular job in question Third, an employer may meet the 80 percent rule. Created as part of federal guidelines issued in 1978, the 80 percent rule says in effect that people in the protected groups have to be hired or promoted at 80 percent or more of the rate enjoyed by the group with the highest rate of success in being hired or promoted. Here is how it works in practice: Suppose that the Acme Corporation uses a test for all its job applicants. Let us say that 225 white males apply and 90 are hired. This hiring rate of 40 percent is the benchmark against which the hiring of other groups is measured. All other groups must be hired at a rate no lower than 80 percent of the 40 percent hiring rate of white males, which comes to 32 percent. If 150 white women apply and 50 are hired—33 percent—Acme meets the hiring rate for women. Suppose that 100 Latinos apply and 25 are hired. Now Acme is vulnerable to discrimination suits by the rejected Latino applicants because its hiring rate for Latinos is 25 percent, not 32 percent. It should hire at least seven more Latinos, bringing the Latino percentage up to the needed 32.1 Note that we have said nothing about how the test was used or even what the comparative scores were. With the 80 percent rule, those considerations are irrelevant. It makes no difference if the rejected male applicants had scores that were twice those of the successful women applicants: All that matters is the bottom line: the 80 percent criterion. Less than 80 percent, and Acme is in trouble; more than 80 percent, and the government will probably leave Acme alone. Just “probably,” however. The 80 percent rule is a guideline, not a law, and there is no guarantee that meeting it will head off litigation.</em></p>
<ul>
<li>Page 564 (location ~ 8645-8665)</li>
</ul>
<p><em>Version I: Ignoring Cognitive Ability According to official statistics, wages for blacks have risen since the 1960s and more blacks have entered prestigious occupations. Most people take for granted that these changes have happened to some important degree because of antidiscrimination laws. But what may seem obvious at first glance is not obvious upon further inspection. “Two decades of research have failed to produce professional consensus on the contribution of federal government civil rights activity to the economic progress of black Americans,” wrote economists James Heckman and Brook Payner in 1989,5 and the situation has clarified only marginally since then. The nature of the problem facing the analysts is illustrated by the figure below for two categories of white-collar jobs that affirmative action was supposed to open up for blacks.6</em></p>
<ul>
<li>Page 568 (location ~ 8700-8707)</li>
</ul>
<p><em>Affirmative action policies had the expected effect in public bureaucracies. Police and firefighters are the most conspicuous examples, but affirmative action also has demonstrably increased the proportion of minorities throughout government bureaucracies, from the federal level on down.9 At the federal level, the strongest effects are at the clerical level and below. In cities with large minority populations, the effects are spread across a broader range of government positions, with de facto quotas up to the highest levels. • Among private companies, affirmative action has had some effects, particularly in the South and among companies that do business with the federal government. Some unknown fraction of the increase in black employment by companies with government contracts is balanced off by compensating declines in companies without them. • In private industry in the South (where much of the most demonstrable progress in private industry has been made), a complicated mix of forces seems to have been at work: partly the Civil Rights Act of 1964 and its aftermath, partly the repeal of Jim Crow laws restricting job entry into certain industries, partly a broader breakdown of racial segregation, legal and otherwise.10 • Whatever effects affirmative action may have had during the 1960s and 1970s, they had become too small to measure by the 1980s and will probably continue to be small in the future, largely for economic reasons. • The behavior of employers has certainly been affected by job discrimination law. Every large company must maintain a bureaucracy to monitor compliance with federal regulations and to defend against (or, commonly, settle out of court) lawsuits alleging discrimination. The amounts of time, money, and resources devoted to compliance are substantial.</em></p>
<ul>
<li>Page 570 (location ~ 8729-8744)</li>
</ul>
<p><em>We may draw this conclusion without knowing whether an employer administers cognitive tests to job candidates or even thinks consciously about cognitive ability when hiring. The relationship of cognitive ability to job productivity exists independent of the existence of test scores, and all hiring practices that succeed in choosing productive workers will tend to select employees with only small group differences in intelligence for occupations in which IQ is most important. The table above shows no such narrowing for the cognitively demanding jobs. If anything the gap widens toward the top of the table. The most plausible explanation for the large gap toward the top of the table is that employers are using dual standards for black and white job applicants. Moreover, we venture the hypothesis that employers are using dual standards at least in part because someone or something (the government or an aversion to harmful publicity) is making them do so—hence our conclusion that affirmative action is probably having a more substantial impact on hiring practices than the standard analyses indicate.</em></p>
<ul>
<li>Page 573 (location ~ 8780-8788)</li>
</ul>
<p><em>The figure above uses broad guidelines about the IQ range from which certain jobs are held and applies them to national data about occupations. For a narrower focus, the NLSY supplies data about specific individuals, their occupations, and IQs.14 In 1990, using the same definition of “professional and technical occupations,” and after controlling for IQ (set at 113, the mean IQ for whites in such occupations), the proportion of blacks in the NLSY employed in professional and technical occupations was 1.5 times the proportion for whites, compared to the ratio of 1.7 shown for 1990 in the graph. For clerical jobs, after controlling for age and IQ (with IQ set at 103, the mean value for whites holding clerical jobs), a black in the NLSY was 1.9 times more likely than a white to be employed in a clerical job, compared to the figure of 1.6 for 1990 as shown in the graph.15 The conclusion drawn from national statistics is thus confirmed by the individual data in the NLSY. Several points may be drawn from this exercise. First, it highlights the reality and magnitude of the discrimination suffered by blacks prior to the civil rights movement. As recently as 1959, the employment of blacks in clerical and professional and technical jobs was only half the proportion that would have been expected from recruitment to those jobs based on IQ alone. Decennial census data (not to mention living memory) tell us that this underrepresentation was still more severe in the 1950s and 1940s.16 There was a clear and large racial deficit to be made up. Second, the exercise shows how rapidly changes were made in the 1960s and early 1970s. If cognitive ability is taken into account, the underrepresentation of blacks in professional and technical jobs was gone by 1964, prior to the Civil Rights Act. This closing of the occupational gap between blacks and whites, obscured by trendlines that do not compensate for IQ differences, argues that something besides antidiscrimination legislation was already afoot in America, making the job market less stacked against blacks. Third, by the end of the 1960s, the job market had pressed beyond the point of parity for blacks and whites, again after cognitive ability is taken into account. One might argue that this merely proves that IQ is not so important for job productivity after all—except that a large literature, already summarized, demonstrates beyond much doubt that IQ is as predictive of job performance for blacks as for whites.</em></p>
<ul>
<li>Page 575 (location ~ 8817-8836)</li>
</ul>
<p><em>The competency exams seem to have had some generally beneficial effects, though the cutoffs are low by the usual standards of what we expect teachers to know.20 The pass rates for whites typically exceed 80 percent and sometimes 90 percent. Whatever your profession may be, think about the meaning of a test that would “pass” aspirants to the profession who perform in the bottom 20 percent. But having so low a cutoff for whites sharpens the evidence of the disparity in black and white qualifications, as shown in the following table. Typical Results of State Teacher Competency Examinations   Pass Rate Implied Difference in SDsa   Whites Blacks   California, 1983-1991 80% 35% 1.2 Pennsylvania, 1989 93 68 1.0 New York, 1987 83 36 1.3 Georgia, 1978-1986 87 40 1.4</em></p>
<ul>
<li>Page 578 (location ~ 8850-8869)</li>
</ul>
<p><em>One of the most common arguments about the current practice of affirmative action might be called the compensating skills fallacy. It is commonly applied to any profession under discussion, but teachers provide an especially good example. The argument goes like this: There are many skills and qualities that go into being a good teacher besides test scores. The ability to inspire confidence, to create an eagerness to learn, to listen to children are all part of the wide repertoire of skills that go into being a good teacher that have nothing to do with the traits measured by a cognitive ability or academic skills test. The statement itself is correct. Most professions involve a number of important nonintellectual attributes. The fallacy lies in assuming that people who have lower cognitive test scores will, on average, be better endowed in these other areas than people with higher scores. Suppose that the teacher competency exams consisted of several parts, each of which measured one of these nonintellectual skills. It would be possible to defend hiring teachers with marginal grades on the intellectual skills if these teachers were hired from the top of the list on the tests of the other qualities. But the way affirmative action programs actually work, these other qualities are not tested or compared. The minority candidate with the best score on the test of intellectual qualities is selected. As for the other qualities, not measured by the test, there is no reason to assume that they are any higher than average.</em></p>
<ul>
<li>Page 580 (location ~ 8883-8895)</li>
</ul>
<p><em>In the mid-1970s, the Washington, D.C., Police Department installed a residency requirement for police. Washington’s white population is densely concentrated among white-collar and professional groups, with no significant white working-class neighborhoods. The residency requirement thereby severely restricted the pool of potential white applicants. By 1982, 40 percent of the candidates who took the police admissions test failed it, and the department was having a hard time filling positions. A new test was introduced in 1985, normed to favor minority applicants. Standards in the police academy were lowered to the point at which not one student flunked out of the training course in 1983 (despite the lower cognitive ability of the candidates being admitted). In 1988, the academy abolished its final comprehensive pencil-and-paper examination after 40 percent of graduating recruits failed it. The former head of the Fraternal Order of Police and a veteran of twenty-two years on the force reported that, at about that time, he began hearing “about people at the academy who could not read or write.”26 A former academy instructor says that “I saw people who were practically illiterate. I’ve seen people diagnosed as borderline retarded graduate from the police academy.”27 This degradation of intellectual requirements translates into police performance on the street. For example, the paperwork that follows an arrest has been a bane of police everywhere for many years, but when police can do the work, it is mainly an inconvenience, not a barrier. An officer who cannot do the paperwork or who finds that it pushes the limits of his abilities may forgo making arrests in marginal cases. The arrests that are made are often botched. Between 1986 and 1990, about a third of all the murder cases brought to the U.S. attorney’s office in the District were dismissed, historically an unusually high rate, often because the prosecutors were unable to make sense of the arrest reports. The basic features of Carlson’s account are confirmed by a variety of other journalistic accounts, most conspicuously a 1993 investigative series by the Washington Post on police performance.</em></p>
<ul>
<li>Page 581 (location ~ 8900-8917)</li>
</ul>
<p><em>Washington is not unique. In Miami in 1985, the police department was rocked by the discovery and seizure of hundreds of pounds of cocaine hidden by police officers working in cahoots with smugglers. We have the results of the intense self-examination that resulted. The main conclusion was that this crime, as well as the many others that were straining community-police relations at the time, could be traced in part to the relaxation of hiring standards mandated by affirmative action regulations. Almost 90 percent of the officers who were dismissed or suspended within a few years of the initiation of aggressive affirmative action policies at the beginning of the 1980s were officers with marginal qualifications, hired because of those policies.</em></p>
<ul>
<li>Page 582 (location ~ 8919-8924)</li>
</ul>
<p>*Silberberg assembled data on performance in apprentice school, on-the-job ratings, and educational background, then was given access to a variety of job performance measures over an eighteen-month follow-up period: hours worked, number of employees who quit, jobs turned down, failures to respond to a dispatch, and being listed by an employer as not eligible for rehire. The table below shows the combined differences, expressed in standard deviations, for the pipefitters and plumbers. Job Performance of Black Affirmative Action Plumbers and Pipefitters Compared to White Regular Hirees   Black-White Difference in SDs Job performance measures   Quits or no rehire +.6 Termination for cause +.5 Nonresponse to job call +.6 Hours worked -.9 IQ-related measures  *</p>
<ul>
<li>Page 583 (location ~ 8932-8946)</li>
</ul>
<p><em>Comparing the blacks admitted under the court order with whites admitted under the ordinary procedures at the same time, the blacks quit at more than six times the rate for whites, were terminated for cause at more than three times the rate for whites, and did not respond to a job dispatch at more than six times the rate for whites. Similar results were obtained for the electricians. The results track closely with the larger literature on IQ and job productivity. The differences in the job performance measures are what might be expected from the discussion in Chapter 3. Furthermore, the size of the difference in job performance is economically important. Silberberg discusses the possibility that the differences are themselves a result of bias among the dispatchers and supervisors. Given the procedures for assigning jobs in the Seattle unions, he concludes that it is extremely difficult to explain away the differences in such terms.</em></p>
<ul>
<li>Page 584 (location ~ 8952-8958)</li>
</ul>
<p><em>In thinking about affirmative action in the workplace, more than psychometric realities or efficiency in the workplace must be considered. To avoid misunderstanding, this is a good time to lay out our perspective on these other matters. • As of the 1950s, minorities, especially blacks, in many parts of the country were systematically and unjustly excluded from entering skilled and professional occupations of all kinds. • At least since the 1950s, changes in white attitudes, as expressed in the civil rights movement and in myriad other events in race relations, the removal of Jim Crow restrictions in the South, and affirmative action requirements opened up opportunities for minorities. Progress was made. • In the 1990s, racial hostility continues to be a significant problem in American life. • Affirmative action has an internally consistent rationale even if it is at odds with the maximum efficiency in hiring productive workers. This last remark calls for some elaboration. Suppose, for the sake of argument, that we are sure that a history of unfair discrimination has handicapped some people so that they fare less well in the job market than they otherwise would. Their handicaps may handicap their descendants, so that past unfairness is propagated indefinitely into the future, unless we do something about it. A properly constructed affirmative action policy may then be temporarily less efficient but more efficient in the long run. If it achieves long-run efficiency by breaking the cycle of past discrimination, it is arguably fair. And even if the long run is indefinitely far off, many people are willing to pay some price in lost productivity for a large enough gain in group equality.</em></p>
<ul>
<li>Page 586 (location ~ 8976-8990)</li>
</ul>
<p><em>Our dispute with the egalitarian position has to be carried out on ethical and philosophical grounds, for there is nothing much to argue about in the facts. Briefly, we differ with the contemporary advocates of continued quotalike hiring requirements on two counts. First, we adhere to the 1964 view of what constitutes fairness, exemplified by Hubert Humphrey, who, in fighting for passage of the Civil Rights Act of 1964, declared that it “does not limit the employer’s freedom to hire, fire, promote, or demote for any reason—or for no reasons—so long as his action is not based on race,” and then volunteered to eat the bill in public if he were wrong about what the new law would do.36 Like the senator, we reject equality of outcome as an appropriate goal. Equality of opportunity is the test most consistent with the vision of the Congress that enacted the law in 1964, and for that matter with the vision that animated the Constitution. The appropriate goal is a job market in which people are not favored or held back simply because of their race. Nothing in nature or knowledge, however, says that all groups should be equally successful in every walk of life. This may be “unfair” in the same sense that life is unfair, but it need not mean that human beings are treating one another unfairly.</em></p>
<ul>
<li>Page 588 (location ~ 9004-9014)</li>
</ul>
<p><em>If men and women players were ranked in a single list, would there be “too many” males among the top 100 tennis players in the world? Any particular disproportion may be unfair, but it may not. It may be less obvious why there are disproportions in other pursuits, hence harder to tell whether they are fair, but the principle is the same, and simple: If the quality of performance fairly differs among individuals, it may fairly differ among groups.37 If a disproportion is fair, then “correcting” it—making it proportional—may produce unfairness along with equal representation. We believe that is what has happened in the case of current forms of affirmative action. People who bring equal qualifications to a job should have an equal shot at being hired, and affirmative action regulations, originally intended to promote precisely that goal, now impede it. Second, the debate will be healthier if those who want private businesses to support social objectives openly acknowledge that such support does in fact entail costs in efficiency and productivity, hence the benefits that flow from greater efficiency and higher productivity—including a stronger economy for American society as a whole.38 Nor are the costs in productivity unique to private businesses. When a police department hires people who become less effective police officers than those it could have hired, the department loses some of its capability to provide law enforcement. Affirmative action can cost something in government services every bit as much as in the productivity of a private business.</em></p>
<ul>
<li>Page 589 (location ~ 9018-9030)</li>
</ul>
<p><em>Alternative I: Creating Tests That Are Legal Under the Current Requirements In theory, employers could construct job-specific tests that meet the Supreme Court’s (and now the Congress’s) definition of fairness. It would be expensive, and the tests would seldom (if ever) be more predictive than a general test of cognitive ability. But it is feasible. The difficulty is that predictiveness comes primarily from the tests’ measure of g. Therefore, although they cannot be faulted under the other legal requirements, they will nonetheless be thrown out because of disparate impact. This is what has happened most famously at New York City’s Police Department, which for more than a decade has been spending large amounts of money trying to create a sergeant’s examination. Each successive version has met strict standards of job specificity and freedom from demonstrable cultural bias, but large ethnic disparities have persisted.</em></p>
<ul>
<li>Page 590 (location ~ 9033-9040)</li>
</ul>
<p><em>Alternative II: Choosing Among Applicants with Equal Education Ordinarily a fair way to ease the existing affirmative action requirement would be to permit employers to narrow the pool of qualified applicants by using education as a screen. Thus, for example, the 80 percent rule (see the definition on page 482) could be calculated on the basis of applicants who met a minimum educational level, not all applicants. But affirmative action at the university level (Chapter 19) prevents this solution from working, because the same degree may not have the same meaning for blacks, Latinos, and whites in terms of cognitive ability. We showed this for the bachelor’s degree in the preceding chapter. But employers who try to make finer discriminations are no better off. In the NLSY, the black-white differences for every educational level, from high school diploma to Ph.D, are large, with the smallest being a difference of 1.2 standard deviations.41</em></p>
<ul>
<li>Page 590 (location ~ 9046-9053)</li>
</ul>
<p><em>Alternative III: Race Norming An employer who hires large numbers of people cannot very well get along without using a test, but at the same time probably cannot devise a test that will pass muster with the government. So it will have to test applicants knowing that the test will produce unacceptably large group differences between whites and blacks, then comply with the 80 percent rule by hiring additional applicants from the protected minorities. The simplest way to do this is to employ a pass-fail cutoff. Everyone above the cutoff is deemed qualified for the job, and then the employer uses other methods to choose among the candidates, making sure that the end result meets the 80 percent rule. This is a common solution and requires only that the cutoff be low enough that a sufficient number of protected candidates get into the final group of candidates.42 But the pass-fail cutoff throws away a great deal of valuable information. Suppose that after complying with the 80 percent rule, the employer ends up with six new white employees out of twenty whites who applied and two out of seven black applicants. Why just take any six whites who scored above the cutoff? Why not instead take the whites with the top six scores? Similarly, why not take the top-scoring two blacks? This is called top-down hiring. If the test has high validity, if the group differences are large, and if there are many applicants, it is much more efficient than a cutoff.</em></p>
<ul>
<li>Page 591 (location ~ 9062-9073)</li>
</ul>
<p><em>In 1986, the U.S. Department of Justice challenged race norming on the grounds that it was an unlawful and unconstitutional violation of the rights of people who were neither black nor Latino. In our example, a black with a score of 80 would indeed have a much better chance of being hired than a white with a score of 45, though both had the same score on an unbiased, valid test. The Departments of Justice and Labor adjudicated their differences, agreeing to study the method further. Race norming had few defenders in public, where its unfairness seemed palpable. In the Civil Rights Act of 1991, race norming was banned for any employer subject to federal regulation. For now, this experiment in affirmative action policy—ironically, by far the most efficient from a productivity standpoint and even the “fairest,” insofar as the highest scorers at least won out in competition with members of their own group—has been suspended.</em></p>
<ul>
<li>Page 593 (location ~ 9090-9096)</li>
</ul>
<p><em>Alternative IV: Returning to the Original Conception of Affirmative Action We are dissatisfied with all of the foregoing alternatives and are broadly critical of the way in which the well-intentioned effort to end employment discrimination has played out. We therefore close by urging consideration of this proposition: If tomorrow all job discrimination regulations based on group proportions were rescinded, the United States would have a job market that is ethically fairer, more conducive to racial harmony, and economically more productive, than the one we have now. We cannot prove that the proposition is true (just as no one can prove that it is not), but here are two reasons for taking it seriously.</em></p>
<ul>
<li>Page 594 (location ~ 9097-9102)</li>
</ul>
<p><em>Our fundamental recommendation for the workplace resembles the one we offered for higher education: get rid of preferential affirmative action and return to the original conception of casting a wider net and leaning over backward to make sure that all minority applicants have a fair shot at the job or the promotion. To the extent that the government has a role to play, it is to ensure equality of opportunity, not of outcome. Once again, we anticipate that the main objection will be that ending affirmative action as now practiced will take us back to the bad old days. As we come to the end of our long wrestle with the new American Dilemma known as affirmative action, let us expand on our reasons for our optimism that the United States can do without it very well. Try this thought experiment on yourself. If all antidiscrimination law were rescinded tomorrow, would you (if you are an employer) hire whites in preference to blacks or Latinos? Would you (if you are an employee) begin looking for workplaces where you did not have to work with blacks or Latinos? Would you (if you are a customer) seek out stores and services that did not have black or Latino personnel? We put the issue that way to expose a strange dissonance among Americans. We are confident that the answer to all of those questions by virtually all of the white readers of this book is an emphatic, deeply felt “no.” May we even suggest that many of you would feel much happier about what you were doing if, as an employer, you spent your time concentrating on whether a minority applicant was the right person for the job rather than worrying about whether the applicant was likely to sue you if you turned him down; that, as an employee, you would find it a blessed relief to work in an office with black or Latino colleagues where it could be taken for granted by everyone that the personnel office had hired all of you using the same yardstick; that, as a consumer of services, you wish you could choose a surgeon who happens to be an ethnic minority, because you could be confident that his degree meant the same thing for everyone who received it.</em></p>
<ul>
<li>Page 595 (location ~ 9109-9123)</li>
</ul>
<p><em>Much of the reshuffling that may be expected will not be bad even for those who are reshuffled. As matters stand, newly hired minority executives in corporations often enjoy short-term benefits (higher pay and status at the front end than new graduates could ordinarily expect) but a career dead end. Blacks in companies that do business with the federal government are routinely used in highly visible positions as evidence of affirmative action compliance and diverted from the more pedestrian but ultimately more beneficial apprenticeship positions that the white employees have no choice but to serve. Minority businesspeople are channeled into the minority set-aside game, learning how to serve as fronts for contracts that are actually carried out by whites, instead of running the business itself. Affirmative action has deformed many aspects of American life, not least in twisting the ways in which minorities must try to get ahead. We will not try to estimate what the effects of doing away with job discrimination legislation would be for business productivity. The effects would vary widely by industry and location in any case, from trivial to substantial. Nor will we spend much time talking about the benefits for whites, except to say that these benefits should be counted. It is easy for highly educated whites with many options to look benignly on affirmative action. It has little effect on their job prospects.</em></p>
<ul>
<li>Page 597 (location ~ 9143-9153)</li>
</ul>
<p><em>In this penultimate chapter we speculate about the impact of cognitive stratification on American life and government. Predicting the course of society is chancy, but certain tendencies seem strong enough to worry about: • An increasingly isolated cognitive elite. • A merging of the cognitive elite with the affluent. • A deteriorating quality of life for people at the bottom end of the cognitive ability distribution. Unchecked, these trends will lead the U.S. toward something resembling a caste society, with the underclass mired ever more firmly at the bottom and the cognitive elite ever more firmly anchored at the top, restructuring the rules of society so that it becomes harder and harder for them to lose.</em></p>
<ul>
<li>Page 598 (location ~ 9162-9169)</li>
</ul>
<p><em>At the beginning of the century, the great majority of people in the top 5 or 10 percent of the intelligence distribution were not college educated, often not even high school educated, and they lived their lives scattered almost indistinguishably among the rest of the population. Their interests were just as variegated. Many were small businessmen or farmers, sharing the political outlook of those groups. Many worked on assembly lines or as skilled craftsmen. The top of the cognitive ability distribution probably included leaders of the labor movement and of community organizations. Among the smart women, a few had professional careers of their own, but most of them kept house, reared children, and were often the organizing forces of their religious and social communities. People from the top of the cognitive ability distribution lived next door to people who were not so smart, with whose children their own children went to school. They socialized with, went to church with, and married people less bright than themselves as a matter of course. This was not an egalitarian utopia that we are trying to recall. On the contrary, communities were stratified by wealth, religion, class, ethnic background, and race. The stratifications may have been stark, even bitter, but people were not stratified by cognitive ability. As the century progressed, the historical mix of intellectual abilities at all levels of American society thinned as intelligence rose to the top. The upper end of the cognitive ability distribution has been increasingly channeled into higher education, especially the top colleges and professional schools, thence into high-IQ occupations and senior managerial positions, as Part I detailed. The upshot is that the scattered brightest of the early twentieth century have congregated, forming a new class.</em></p>
<ul>
<li>Page 599 (location ~ 9175-9188)</li>
</ul>
<p><em>Technology has not just created more jobs for the cognitive elite but revolutionized the way they may be done. Modern transportation has expanded the realm in which people work. Beyond that, physical separation is becoming irrelevant. A scientist passionately devoted to the study of a certain protein or an investment analyst following a market can be in daily electronic conversation with people throughout the world who share the same passion, passing drafts of work back and forth, calling up data files, doing analyses that would have required a mainframe computer and a covey of assistants only a few years ago—all while sitting alone at a computer, which need not be in an office, but can as easily be in a beach house overlooking the ocean. Across the occupational domain of those who work primarily with their minds, the explosion of computer and communications technologies has liberated and expanded creativity, productivity, and personal freedom. There may be some costs of this physical isolation, but many people are happier and more fulfilled as a result of the reach of modern technology. For the nation as a whole, the invisible migration has surely brought benefits as well. We cannot measure the gains precisely, but they are the inevitable side effect of greater efficiency in identifying intellectual talent and channeling it into high-IQ occupations. Compared to 1900 or even 1950, America in the 1990s is getting more productivity out of its stock of human capital, and this presumably translates into more jobs, gains in GNP, and other effects that produce more wealth for the society at large.</em></p>
<ul>
<li>Page 601 (location ~ 9208-9219)</li>
</ul>
<p><em>The end of the military draft, the social segregation of the school system, and the divisive effects of the underclass are among his suspects, and each has doubtless played an important role independent (to some degree) of the effects of the cognitive stratification that we described in Part I. Thinking about the way these forces had affected his own life, Kaus remarked: “I entered a good Ivy League college in 1969. I doubt I’ve had a friend or regular social acquaintance since who scored less than an 1100 on his or her SAT boards.”2 Kaus is probably right. The reason why this is a problem is captured by a remark attributed to the New Yorker’s one-time movie critic Pauline Kael following Richard Nixon’s landslide victory in the presidential election of 1972: “Nixon can’t have won; no one I know voted for him.”3 When the members of the cognitive elite (of whatever political convictions) hang out with each other, often exclusively with each other, they find it hard to understand what ordinary people think. The problem is not simply that smart people rise to the top more efficiently these days. If the only quality that CEOs of major corporations and movie directors and the White House inner circle had in common were their raw intelligence, things would not be so much different now than they have always been, for to some degree the most successful have always been drawn disproportionately from the most intelligent. But the invisible migration of the twentieth century has done much more than let the most intellectually able succeed more easily. It has also segregated them and socialized them. The members of the cognitive elite are likely to have gone to the same kinds of schools, live in similar neighborhoods, go to the same kinds of theaters and restaurants, read the same magazines and newspapers, watch the same television programs, even drive the same makes of cars.</em></p>
<ul>
<li>Page 602 (location ~ 9227-9241)</li>
</ul>
<p><em>The isolation of the cognitive elite is by no means complete, but the statistical tendencies are strong, and the same advances in transportation and communication that are so enhancing the professional lives of the cognitive elite will make their isolation from the rest of the public that much greater. As their common ground with the rest of society decreases, their coalescence as a new class increases. The traditional separations between the business world, the entertainment world, the university intellectuals, and government are being replaced by an axis of bright people that runs through society. They already sense their kinship across these spheres of interest. This too will increase with time.</em></p>
<ul>
<li>Page 603 (location ~ 9246-9251)</li>
</ul>
<p><em>For most of the century, intellectuals and the affluent have been antagonists. Intellectuals have been identified with the economic left and the cultural avant-garde, while the affluent have been identified with big business and cultural conservatism. These comfortable categories have become muddled in recent years, as faculty at the top universities put together salaries, consulting fees, speeches, and royalties that garner them six-figure incomes while the New York Review of Books shows up in the mailbox of young corporate lawyers. The very bright have become much more uniformly affluent than they used to be while, at the same time, the universe of affluent people has become more densely populated by the very bright, as Part I described. Not surprisingly, the interests of affluence and the cognitive elite have begun to blend. This melding has its limits, particularly when the affluent person is not part of the cognitive elite. The high-IQ Stanford professor with the best-selling book and the ordinary-IQ fellow who makes the same income with his small chain of shoe stores are hardly allies on everything. But in looking ahead to alliances and social trends, it is still useful to think in terms of their increasing commonalities because, as any good economist or politician will point out, there are theoretical interests and practical interests. The Stanford professor’s best-selling book may be a diatribe against the punitive criminal justice system, but that doesn’t mean that he doesn’t vote with his feet to move to a safe neighborhood.</em></p>
<ul>
<li>Page 605 (location ~ 9266-9277)</li>
</ul>
<p><em>Consider the sheer size of this emerging coalition and how quickly the affluent class as a whole (not just the cognitive elite) is growing. What is “affluence”? The median answer in 1992 when the Roper Organization asked people how much annual income they would need “to fulfill all your dreams” was $82,100, which indicates where affluence is thought to start by most Americans.4 For purposes of this exercise, we will define affluence as beginning at an annual family income of $100,000 in 1990 dollars, about three times the median family income. By that definition, more than one out of twenty American families is affluent, roughly double what it was a decade earlier.5 Furthermore, this growth has accompanied stagnant real income for the average family. Here is the last of the many graphs we have asked you to examine in this book. In some ways, it is more loaded with social implications than any that have come before.</em></p>
<ul>
<li>Page 606 (location ~ 9284-9291)</li>
</ul>
<p><em>Try to envision what will happen when 10 or 20 percent of the population has enough income to bypass the social institutions they don’t like in ways that only the top 1 percent used to be able to do. Robert Reich has called it the “secession of the successful.”7 The current symbol of this phenomenon is the gated community, secure behind its walls and guard posts, but many other signs are visible. The fax, modem, and Federal Express have already made the U.S. Postal Service nearly irrelevant to the way that the affluent communicate, for example. A more portentous development is the private court system that businesses are beginning to create. Or the mass exodus from public schools among those living in cities, if they can afford it. Or the proliferation of private security forces for companies, apartment houses, schools, malls, and anywhere else where people with money want to be safe.</em></p>
<ul>
<li>Page 608 (location ~ 9311-9318)</li>
</ul>
<p><em>Speaking in round numbers (for the precise definitions of both groups are arbitrary), a coalition of the cognitive elite and the affluent class now represents something well in excess of 5 percent of families and, because of their much higher than average voting rates, somewhere in the vicinity of 10 to 15 percent of the voters.8 The political clout of this group extends well beyond its mere voting size because of its financial contributions to campaigns and because this group contributes a large proportion of local political organizers. The combined weight of the cognitive elite and the affluent is already considerable. But we asked you to envision tomorrow, not today. Do you think that the rich in America already have too much power? Or do you think the intellectuals already have too much power? We are suggesting that a “yes” to both questions is probably right. And if you think the power of these groups is too great now, just watch what happens as their outlooks and interests converge. Cynical readers will be asking what else is new. The privileged have always used the law to their advantage. Our own analysis is hardly novel; it is taken straight from a book of essays written more than two centuries ago, The Federalist. People are not naturally angelic but self-interested—else, as Publius pointed out, governments would not be necessary in the first place.</em></p>
<ul>
<li>Page 608 (location ~ 9319-9330)</li>
</ul>
<p><em>The Fate of Children Statistically, it is not good for children to be born either to a single mother or a married couple of low cognitive ability. But the greatest problems afflict children unlucky enough to be born to and reared by unmarried mothers who are below average in intelligence—about 20 percent of children currently being born.9 They tend to do badly, socially and economically. They tend to have low cognitive ability themselves. They suffer disproportionately from behavioral problems. They will be disproportionately represented in prisons. They are less likely to marry than others and will themselves produce large proportions of the children born to single women of low intelligence. Attempts to compensate for cognitive disadvantage at birth have shown how extraordinarily hard it is to do. Many readers no doubt find the plight of children to be among the most compelling arguments for government activism, as we do. But inadequate nutrition, physical abuse, emotional neglect, lack of intellectual stimulation, a chaotic home environment—all the things that worry us when we think about the welfare of children—are very difficult to improve from outside the home when the single mother is incompetent.</em></p>
<ul>
<li>Page 610 (location ~ 9341-9350)</li>
</ul>
<p><em>What happens to the child of low intelligence who survives childhood and reaches adulthood trying to do his best to be a productive citizen? Out of the many problems we have just sketched, this is the one we choose to italicize: All of the problems that these children experience will become worse rather than better as they grow older, for the labor market they will confront a few decades down the road is going to be much harder for them to cope with than the labor market is now. There will still be jobs for low-skill labor, mostly with service businesses and private households, but the natural wage for those jobs will be low. Attempts to increase their wage artificially (by raising the minimum wage, for example, or mandating job benefits) may backfire by making alternatives to human labor more affordable and, in many cases, by making the jobs disappear altogether. People in the bottom quartile of intelligence are becoming not just increasingly expendable in economic terms; they will sometime in the not-too-distant future become a net drag. In economic terms and barring a profound change in direction for our society, many people will be unable to perform that function so basic to human dignity: putting more into the world than they take out.</em></p>
<ul>
<li>Page 610 (location ~ 9353-9362)</li>
</ul>
<p><em>In the past, whites have not had an “underclass” as such, because the whites who might qualify have been too scattered among the working class. Instead, white communities in America had a few streets on the outskirts of town inhabited by the people who couldn’t seem to cope and skid rows of unattached white men in large cities, but these scatterings were seldom large enough to make up a neighborhood. An underclass needs a critical mass, and white America has not had one. But if the overall white illegitimacy ratio is 22 percent—probably somewhere in the 40 percent range in low-income communities—and rising fast, the question arises: At what point is critical mass reached? How much illegitimacy can a community tolerate? Nobody knows, but the historical fact is that the trendlines on black crime, dropout from the labor force, and illegitimacy all shifted sharply upward as the overall black illegitimacy ratio passed 25 percent and the rate in low-income black communities moved past 50 percent. We need not rely on the analogy with the black experience. White illegitimacy is also overwhelmingly a lower-cognitive-class phenomenon, as we detailed in Chapter 8. Three-quarters of all white illegitimate births are to women below average in IQ, and 45 percent are to women with IQs under</em></p>
<ul>
<li>Page 612 (location ~ 9378-9387)</li>
</ul>
<p><em>In the past, whites have not had an “underclass” as such, because the whites who might qualify have been too scattered among the working class. Instead, white communities in America had a few streets on the outskirts of town inhabited by the people who couldn’t seem to cope and skid rows of unattached white men in large cities, but these scatterings were seldom large enough to make up a neighborhood. An underclass needs a critical mass, and white America has not had one. But if the overall white illegitimacy ratio is 22 percent—probably somewhere in the 40 percent range in low-income communities—and rising fast, the question arises: At what point is critical mass reached? How much illegitimacy can a community tolerate? Nobody knows, but the historical fact is that the trendlines on black crime, dropout from the labor force, and illegitimacy all shifted sharply upward as the overall black illegitimacy ratio passed 25 percent and the rate in low-income black communities moved past 50 percent. We need not rely on the analogy with the black experience. White illegitimacy is also overwhelmingly a lower-cognitive-class phenomenon, as we detailed in Chapter 8. Three-quarters of all white illegitimate births are to women below average in IQ, and 45 percent are to women with IQs under 90.</em></p>
<ul>
<li>Page 612 (location ~ 9378-9387)</li>
</ul>
<p><em>Meanwhile, as never-married mothers grow in numbers, the dynamics of the public housing market (where they will probably continue to be welcome) and the private housing market (where they will not) will foster increasing concentrations of whites with high unemployment, high crime, high illegitimacy, and low cognitive ability, creating communities that look very much like the inner-city neighborhoods that people now tend to associate with minorities. The white cognitive elite is unlikely to greet this development sympathetically. On the contrary, much of white resentment and fear of the black underclass has been softened by the complicated mixture of white guilt and paternalism that has often led white elites to excuse behavior in blacks that they would not excuse in whites. This does not mean that white elites will abandon the white underclass, but it does suggest that the means of dealing with their needs are likely to be brusque.</em></p>
<ul>
<li>Page 613 (location ~ 9389-9396)</li>
</ul>
<p><em>What is the minimum level of cognitive resources necessary to sustain a community at any given level of social and economic complexity? For sustaining a village of a few hundred people in a premodern society, the minimum average level is probably quite modest. What is it for sustaining a modern community? The question is of enormous practical significance yet remains innocent of any empirical investigation whatsoever. Perhaps the crucial feature is the average cognitive ability. Perhaps it is the size of the cadre of high-ability people. Perhaps it is the weight of the population at low end of the distribution. No one knows. Whatever the details, a prima facie case exists that the cognitive resources in the contemporary inner city have fallen below the minimum level. What looked like a rising tide of social problems a generation ago has come to look more like a fundamental breakdown in social organization.</em></p>
<ul>
<li>Page 614 (location ~ 9402-9408)</li>
</ul>
<p><em>One may look for signs that these communities are about to recover. The crack cocaine epidemic of the 1980s has ebbed, for example, although crack is cheaper than ever, as the savage effects of the drug became evident to younger brothers and sisters. Black grass-roots efforts to restore the family and combat crime have increased in recent years. But counterpoised against these forces working on behalf of regeneration within the inner city is a powerful force working against it:. A large majority of the next generation of blacks in the inner city is growing up without fathers and with limited cognitive ability. The numbers continue to increase. The outmigration of the able continues. While we can see how these trends might be reversed, which we describe in the next and final chapter, let us consider the prospect we face if they do not. This brings us to the denouement of our prognosis.</em></p>
<ul>
<li>Page 614 (location ~ 9409-9415)</li>
</ul>
<p><em>Thus dawns the welfare state—the attempt to raise the poor and the needy out of their plight. In what direction does the social welfare system evolve when a coalition of the cognitive elite and the affluent continues to accept the main tenets of the welfare state but are increasingly frightened of and hostile toward the recipients of help? When the coalition is prepared to spend money but has lost faith that remedial social programs work? The most likely consequence in our view is that the cognitive elite, with its commanding position, will implement an expanded welfare state for the underclass that also keeps it out from underfoot. Our label for this outcome is the custodial state.16 Should it come to pass, here is a scenario: Over the next decades, it will become broadly accepted by the cognitive elite that the people we now refer to as the underclass are in that condition through no fault of their own but because of inherent shortcomings about which little can be done. Politicians and intellectuals alike will become much more open about the role of dysfunctional behavior in the underclass, accepting that addiction, violence, unavailability for work, child abuse, and family disorganization will keep most members of the underclass from fending for themselves. It will be agreed that the underclass cannot be trusted to use cash wisely. Therefore policy will consist of greater benefits, but these will be primarily in the form of services rather than cash. Furthermore, there will be new restrictions. Specifically, these consequences are plausible: Child care in the inner city will become primarily the responsibility of the state. Infants will get better nutrition because they will be spending their days in day care centers from infancy. Children will get balanced diets because they will be eating breakfast, lunch, and perhaps supper at school. Day care centers and schools for elementary students will edge closer toward comprehensive care facilities, whose staff will try to provide not only education and medical care but to train children in hygiene, sexual socialization, socialization to the world of work, and other functions that the parents are deemed incapable of providing. The homeless will vanish. One of the safer predictions is that sometime in the near future, the cognitive elite will join the broad public sentiment in favor of reasserting control over public spaces. It will become easier to consign mentally incompetent adults to custodial care. Perhaps the clinically borderline cases that now constitute a high proportion of the homeless will be required to reside in shelters, more elaborately equipped and staffed than most homeless shelters are today. Police will be returned their authority to roust people and enforce laws prohibiting disorderly conduct. Strict policing and custodial responses to crime will become more acceptable and widespread. This issue could play out in several ways. The crime rate in affluent suburbs may be low enough to keep the pressure for reform low. But events in the early 1990s suggest that fear of crime is rising, and support for strict law enforcement is increasing.</em></p>
<ul>
<li>Page 615 (location ~ 9417-9440)</li>
</ul>
<p><em>The underclass will become even more concentrated spatially than it is today. The expanded network of day care centers, homeless shelters, public housing, and other services will always be located in the poorest part of the inner city, which means that anyone who wants access to them will have to live there. Political support for such measures as relocation of people from the inner city to the suburbs, never strong to begin with, will wither altogether. The gaping cultural gap between the habits of the underclass and the habits of the rest of society, far more impassable than a simple economic gap between poor and not poor or the racial gap of black and white, will make it increasingly difficult for children who have grown up in the inner city to function in the larger society even when they want to. The underclass will grow. During the 1980s, scholars found evidence that the size of the underclass was no longer expanding.17 But even as they wrote, the welfare rolls, which had moved within a narrow range since the late 1970s, began to surge again. The government will try yet another round of the customary social programs—sex education, job training, parenting training, and the like—and they will be as ineffectual this round as they were in the 1960s and 1970s.18 Meanwhile, many low-income parents who try to do all the right things and pass their values on to their children will be increasingly unable to do so. They cannot propagate their norms in the face of a local culture in which illegitimacy, welfare, crime, and drugs are commonplace, and there is nothing magically invulnerable about them or their children.</em></p>
<ul>
<li>Page 617 (location ~ 9448-9460)</li>
</ul>
<p><em>Racism will reemerge in a new and more virulent form. The tension between what the white elite is supposed to think and what it is actually thinking about race will reach something close to a breaking point. This pessimistic prognosis must be contemplated: When the break comes, the result, as so often happens when cognitive dissonance is resolved, will be an overreaction in the other direction. Instead of the candor and realism about race that is so urgently needed, the nation will be faced with racial divisiveness and hostility that is as great as, or greater, than America experienced before the civil rights movement. We realize how outlandish it seems to predict that educated and influential Americans, who have been so puritanical about racial conversation, will openly revert to racism. We would not go so far as to say it is probable. It is, however, more than just possible. If it were to happen, all the scenarios for the custodial state would be more unpleasant—more vicious—than anyone can now imagine. In short, by custodial state, we have in mind a high-tech and more lavish version of the Indian reservation for some substantial minority of the nation’s population, while the rest of America tries to go about its business. In its less benign forms, the solutions will become more and more totalitarian. Benign or otherwise, “going about its business” in the old sense will not be possible. It is difficult to imagine the United States preserving its heritage of individualism, equal rights before the law, free people running their own lives, once it is accepted that a significant part of the population must be made permanent wards of the state.</em></p>
<ul>
<li>Page 618 (location ~ 9471-9482)</li>
</ul>
<p><em>How should policy deal with the twin realities that people differ in intelligence for reasons that are not their fault, and that intelligence has a powerful bearing on how well people do in life? The answer of the twentieth century has been that government should create the equality of condition that society has neglected to produce on its own. The assumption that egalitarianism is the proper ideal, however difficult it may be to achieve in practice, suffuses contemporary political theory. Socialism, communism, social democracy, and America’s welfare state have been different ways of moving toward the egalitarian ideal. The phrase social justice has become virtually a synonym for economic and social equality. Until now, these political movements have focused on the evils of systems in producing inequality. Human beings are potentially pretty much the same, the dominant political doctrine has argued, except for the inequalities produced by society. These same thinkers have generally rejected, often vitriolically, arguments that individual differences such as intelligence are to blame. But there is no reason why they could not shift ground. In many ways, the material in this book is tailor-made for their case. If it’s not someone’s fault that he is less intelligent than others, why should he be penalized in his income and social status?</em></p>
<ul>
<li>Page 619 (location ~ 9491-9501)</li>
</ul>
<p><em>Society was to be ruled by the virtuous and wise few. The everyday business of the community fell to the less worthy multitude, with the most menial chores left to the slaves. Neither the Greek democrats nor the Roman republicans believed that “all men are created equal.” Nor did the great Hindu thinkers of the Asian subcontinent, where one’s work defined one’s caste, which in turn circumscribed every other aspect of life. The ancients accepted the basic premise that people differ fundamentally and importantly and searched for ways in which people could contentedly serve the community (or the monarch or the tyrant or the gods), rather than themselves, despite their differences.</em></p>
<ul>
<li>Page 621 (location ~ 9516-9521)</li>
</ul>
<p><em>In our historical era, political philosophers have argued instead about rights. They do so because they are trying to solve a different problem. The great transformation from a search for duties and obligations to a search for rights may be dated with Thomas Hobbes, writing in the mid-1600s about a principle whereby all people, not just the rich and well born, might have equal rights to liberty.2 Everyone, said Hobbes, is entitled to as much liberty in gratifying his desires as he is willing to allow others in gratifying theirs.3 People differ, acknowledged Hobbes, but they do not differ so much that they may justifiably be deprived of liberty by differing amounts. In the modern view that Hobbes helped shape, individuals freely accept constraints on their own behavior in exchange for ridding themselves of the dangers of living in perfect freedom, hence perfect anarchy.4 The constraints constitute lawful government. Hobbes believed that the only alternatives for human society are, in effect, anarchy or absolute monarchy. Given those alternatives, said Hobbes, a rational person would choose a monarch to ensure the equality of political rights, rather than take his chances with perfect freedom. His successor in English political thought, John Locke, did not accept the Hobbesian choice between despotism and anarchy. He conceived of people in a state of nature as being in “a State also of Equality, wherein all the Power and Jurisdiction is reciprocal, no one having more than another,”5 and sought to preserve that condition in actual societies through a strictly limited government.</em></p>
<ul>
<li>Page 621 (location ~ 9522-9535)</li>
</ul>
<p><em>But with Locke also arose a confusion, which has grown steadily with passing time. For most contemporary Americans who are aware of Locke at all, he is identified with the idea of man as tabula rasa, a blank slate on which experience writes. Without experience, Locke is often believed to have said, individuals are both equal and empty, a blank slate to be written upon by the environment. Many contemporary libertarians who draw their inspiration from Locke are hostile to the possibility of genetic differences in intelligence because of their conviction that equal rights apply only if in fact people at birth are tabulae rasae. With that in mind, consider these remarks about human intelligence from Locke’s An Essay on Human Understanding: Now that there is such a difference between men in respect of their understandings, I think nobody who has had any conversation with his neighbors will question . . . . Which great difference in men’s intellectuals, whether it rises from any defect in the organs of the body particularly adapted to thinking, or in the dullness or untractableness of those faculties for want of use, or, as some think, in the natural differences of men’s souls themselves; or some or all of these together, it matters not here to examine. Only this is evident, that there is a difference of degrees in men’s understandings, apprehensions, and reasonings, to so great a latitude that one may, without doing injury to mankind, affirm that there is a greater distance between some men and others in this respect, than between some men and some beasts.6 Locke is strikingly indifferent to the source of cognitive differences and strikingly harsh in his judgment about their size. But that does not mean he believed people to have different rights. They are equal in rights, Locke proclaimed, though they be unequal in everything else. Those rights, however, are negative rights (to impose contemporary terminology): They give all human beings the right not to have certain things done to them</em></p>
<ul>
<li>Page 622 (location ~ 9536-9551)</li>
</ul>
<p><em>But with Locke also arose a confusion, which has grown steadily with passing time. For most contemporary Americans who are aware of Locke at all, he is identified with the idea of man as tabula rasa, a blank slate on which experience writes. Without experience, Locke is often believed to have said, individuals are both equal and empty, a blank slate to be written upon by the environment. Many contemporary libertarians who draw their inspiration from Locke are hostile to the possibility of genetic differences in intelligence because of their conviction that equal rights apply only if in fact people at birth are tabulae rasae. With that in mind, consider these remarks about human intelligence from Locke’s An Essay on Human Understanding: Now that there is such a difference between men in respect of their understandings, I think nobody who has had any conversation with his neighbors will question . . . . Which great difference in men’s intellectuals, whether it rises from any defect in the organs of the body particularly adapted to thinking, or in the dullness or untractableness of those faculties for want of use, or, as some think, in the natural differences of men’s souls themselves; or some or all of these together, it matters not here to examine. Only this is evident, that there is a difference of degrees in men’s understandings, apprehensions, and reasonings, to so great a latitude that one may, without doing injury to mankind, affirm that there is a greater distance between some men and others in this respect, than between some men and some beasts.6 Locke is strikingly indifferent to the source of cognitive differences and strikingly harsh in his judgment about their size. But that does not mean he believed people to have different rights. They are equal in rights, Locke proclaimed, though they be unequal in everything else. Those rights, however, are negative rights (to impose contemporary terminology): They give all human beings the right not to have certain things done to them by the state or by other human beings, not the right to anything, except freedom of action.</em></p>
<ul>
<li>Page 622 (location ~ 9536-9552)</li>
</ul>
<p><em>The original concept of equal rights is said to be meaningless cant, outmoded; taking equal rights seriously, it is thought, requires enforcing equal outcomes. The prevailing political attitude is so dismissive toward the older conception of equal rights that it is difficult to think of serious public treatments of it; the Founders just didn’t think hard enough about that problem, it seems to be assumed. If he were alive today, some eminent political scientists have argued, Thomas Jefferson would surely be a social democrat or at least a New Deal Democrat.7 We are asking that you consider the alternative: that the Founders were fully aware of how unequal people are, that they did not try to explain away natural inequalities, and that they nonetheless thought the best way for people to live together was under a system of equal rights.</em></p>
<ul>
<li>Page 623 (location ~ 9553-9559)</li>
</ul>
<p><em>Jefferson saw the consequences of inequalities of ability radiating throughout the institutions of society. The main purpose of education, he believed, was to prepare the natural aristocracy to govern, and he did not mince words. The “best geniuses” should be “raked from the rubbish annually” by competitive grading and examinations, sent on to the next educational stage, and finally called to public life.10 But if the author of the Declaration of Independence was by today’s standards unrepentantly elitist, he was nonetheless a democrat in his belief that the natural aristocracy was “scattered with equal hand through all [of society’s] conditions,”11 and in his confidence that the electorate had the good sense to choose them. “Leave to the citizens the free election and separation of the aristoi from the pseudo-aristoi,” he advised. “In general, they will elect the real good and wise.”12 For Madison, the “great republican principle” was that the common people would have the public-spiritedness and the information necessary to choose “men of virtue and wisdom” to govern them.13 For both Jefferson and Madison, political equality was both right and workable. They would have been amazed by the notion that humans are equal in any other sense.</em></p>
<ul>
<li>Page 624 (location ~ 9564-9575)</li>
</ul>
<p><em>The Founders saw that making a stable and just government was difficult precisely because men were unequal in every respect except their right to advance their own interests. Men had “different and unequal faculties of acquiring property,” Madison reflected in The Federalist.17 This diversity was the very reason why rights of property were so important and why “the protection of those faculties is the first object of Government.” But the diversity was also the defect of populist democracy, because the unequal distribution of property to which it led was “the most common and durable source of factions.” And faction, he argued, was the great danger that the Constitution sought above all to confine and tame. The task of government was to set unequal persons into a system of laws and procedures that would, as nearly as possible, equalize their rights while allowing their differences to express themselves. The result would not necessarily be serene or quiet, but it would be just. It might even work. In reminding you of these views of the men who founded America, we are not appealing to their historical eminence, but to their wisdom. We think they were right. Let us stop using words like factions and faculties and aristoi and state in our own words, briefly and explicitly, how and why we think they were right in ways that apply today.</em></p>
<ul>
<li>Page 626 (location ~ 9587-9597)</li>
</ul>
<p><em>In T. H. White’s version of the Arthurian legend, The Once and Future King, Merlyn transforms young Arthur into an ant as part of his education in governance. In this guise, Arthur approaches the entrance to the ant colony, where over the entrance are written the words, EVERYTHING NOT FORBIDDEN IS COMPULSORY.18 Such, in our view, is where the logic of the egalitarian ideal ultimately leads. It is appropriate in the ant colony or the beehive but not for human beings. Egalitarian tyrannies, whether of the Jacobite or the Leninist variety, are worse than inhumane. They are inhuman. The same atmosphere prevails on a smaller scale wherever “equality” comes to serve as the basis for a diffuse moral outlook. Consider the many small tyrannies in America’s contemporary universities, where it has become objectionable to say that some people are superior to other people in any way that is relevant to life in society. Nor is this outlook confined to judgments about people. In art, literature, ethics, and cultural norms, differences are not to be judged. Such relativism has become the moral high ground for many modern commentators on life and culture.</em></p>
<ul>
<li>Page 627 (location ~ 9608-9617)</li>
</ul>
<p><em>The ideology of equality has done some good. For example, it is not possible as a practical matter to be an identifiable racist or sexist and still hold public office. But most of its effects are bad. Given the power of contemporary news media to imprint a nationwide image overnight, mainstream political figures have found that their allegiance to the rhetoric of equality must extend very far indeed, for a single careless remark can irretrievably damage or even end a public career. In everyday life, the ideology of equality censors and straitjackets everything from pedagogy to humor. The ideology of equality has stunted the range of moral dialogue to triviality. In daily life—conversations, the lessons taught in public schools, the kinds of screenplays or newspaper feature stories that people choose to write—the moral ascendancy of equality has made it difficult to use concepts such as virtue, excellence, beauty and—above all—truth.</em></p>
<ul>
<li>Page 628 (location ~ 9623-9630)</li>
</ul>
<p><em>In personal life, the idea of forbidding people from interfering with members of other groups (blacks, homosexuals, women) as they went about their lives has been extended to the idea of compelling people to “treat them the same.” It is a mark of how far things have gone that many people no longer can see the distinction between “not interfering” and “treating the same.” Our views on all of these issues are decidedly traditional. We think that rights are embedded in our freedom to act, not in the obligations we may impose on others to act; that equality of rights is crucial while equality of outcome is not; that concepts such as virtue, excellence, beauty, and truth should be reintroduced into moral discourse. We are comfortable with the idea that some things are better than others—not just according to our subjective point of view but according to enduring standards of merit and inferiority—and at the same time reject the thought that we (or anyone else) should have the right to impose those standards. We are enthusiastic about diversity—the rich, unending diversity that free human beings generate as a matter of course, not the imposed diversity of group quotas. And so we come to this final chapter, discussing the broadest policy implications of all that has gone before. We bring to our recommendations a predisposition, believing that the original American conceptions of human equality and the pursuit of happiness still offer the wisest guidance for thinking about how to run today’s America. These have been some of our reasons why.</em></p>
<ul>
<li>Page 629 (location ~ 9638-9650)</li>
</ul>
<p><em>The Goal and a Definition The broadest goal is a society in which people throughout the functional range of intelligence can find, and feel they have found, a valued place for themselves. For “valued place,” we offer a pragmatic definition: You occupy a valued place if other people would miss you if you were gone. The fact that you would be missed means that you were valued. Both the quality and quantity of valued places are important. Most people hope to find a soulmate for life, and that means someone who would “miss you” in the widest and most intense way. The definition captures the reason why children are so important in defining a valued place. But besides the quality of the valuing, quantity too is important. If a single person would miss you and no one else, you have a fragile hold on your place in society, no matter how much that one person cares for you.</em></p>
<ul>
<li>Page 630 (location ~ 9653-9660)</li>
</ul>
<p><em>THE ECONOMIC ARGUMENT. The cognitive elite has pulled away from the rest of the population economically, becoming more prosperous even as real wages in the rest of the economy stagnated or fell. The divergence has been most conspicuous in the lowest-skilled jobs. From their high point in 1973, the median earnings of full-time workers in general nonfarm labor had fallen by 36 percent by 1990, far more than for any other category.20 A strong back isn’t worth what it used to be. Workers in those occupations have been demoralized. They have lost their valued place in the workplace. So far, we agree that economics plays an important role in taking valued places in the workplace from those with low cognitive ability. But the argument typically widens, asserting that economic change also explains why people in low-skill occupations experience the loss of other valued places evidenced by falling marriage rates and rising illegitimacy: Men in low-skill jobs no longer make enough money to support a family, it is said. This common argument is too simplistic. In constant dollars, the income of a full-time, year-round male worker in general nonfarm labor in 1991 was at the level of his counterpart in 1958, when the norm was still one income per family, marriage rates were as high as ever, and illegitimacy was a fraction of its current levels. We may look back still further: The low-skill laborer in 1991 made about twice the real income of his counterpart in 1920, a year when no one thought to question whether a laborer could support a family.</em></p>
<ul>
<li>Page 633 (location ~ 9705-9717)</li>
</ul>
<p><em>The cognitive elite may not detect the declining vitality in the local community. For many of them, the house is important—its size, location, view, grounds. They may want the right kind of address and the right kind of neighbors. But their lives are centered outside a geographic community; their professional associates and friends may be scattered over miles of suburbs, or for that matter across the nation and the world. For large segments of American society, however, the geographic neighborhood is the major potential resource for infusing life with much of its meaning. Even the cognitive elite needs local communities, if not for itself, then for those of its children who happen not to land at the top of the cognitive ability distribution. The massive transfer of functions from the locality to the government has stripped neighborhoods of their traditional shared tasks. Instead, we have neighborhoods that are merely localities, not communities of people tending to their communal affairs. Valued places in a neighborhood are created only to the extent that the people in a neighborhood have valued tasks to do. People who have never lived in such a neighborhood—and as time goes on this includes more and more of the cognitive elite and the affluent in general—often find this hard to believe. It is another case of the isolation we discussed in Chapter 21: They may read about such communities in books, but surely they no longer exist in real life. But they do. Thumb through a few weeks’ issues of the newspaper from any small town, and you will find an America that is still replete with fund-raising suppers for the local child who has cancer, drives to collect food and clothing for a family that has suffered a reverse, and even barn raisings. They may exist as well (though they are less well documented) in urban working-class neighborhoods that have managed to retain their identity. It is through such activities that much of the real good for the disadvantaged is accomplished. Beyond that, they have a crucial role, so hard to see from a Washington office, of creating ways for people of a wide level of incomes and abilities to play a part. It creates ways for them to be known—not just as a name but as a helpful fellow, a useful person to know, the woman you can always count on. It creates ways in which you would be missed if you were gone. Thus arises our first general policy prescription: A wide range of social functions should</em></p>
<ul>
<li>Page 635 (location ~ 9732-9750)</li>
</ul>
<p><em>The cognitive elite may not detect the declining vitality in the local community. For many of them, the house is important—its size, location, view, grounds. They may want the right kind of address and the right kind of neighbors. But their lives are centered outside a geographic community; their professional associates and friends may be scattered over miles of suburbs, or for that matter across the nation and the world. For large segments of American society, however, the geographic neighborhood is the major potential resource for infusing life with much of its meaning. Even the cognitive elite needs local communities, if not for itself, then for those of its children who happen not to land at the top of the cognitive ability distribution. The massive transfer of functions from the locality to the government has stripped neighborhoods of their traditional shared tasks. Instead, we have neighborhoods that are merely localities, not communities of people tending to their communal affairs. Valued places in a neighborhood are created only to the extent that the people in a neighborhood have valued tasks to do. People who have never lived in such a neighborhood—and as time goes on this includes more and more of the cognitive elite and the affluent in general—often find this hard to believe. It is another case of the isolation we discussed in Chapter 21: They may read about such communities in books, but surely they no longer exist in real life. But they do. Thumb through a few weeks’ issues of the newspaper from any small town, and you will find an America that is still replete with fund-raising suppers for the local child who has cancer, drives to collect food and clothing for a family that has suffered a reverse, and even barn raisings. They may exist as well (though they are less well documented) in urban working-class neighborhoods that have managed to retain their identity. It is through such activities that much of the real good for the disadvantaged is accomplished. Beyond that, they have a crucial role, so hard to see from a Washington office, of creating ways for people of a wide level of incomes and abilities to play a part. It creates ways for them to be known—not just as a name but as a helpful fellow, a useful person to know, the woman you can always count on. It creates ways in which you would be missed if you were gone. Thus arises our first general policy prescription: A wide range of social functions should be restored to the neighborhood when possible and otherwise to the municipality. The reason for doing so, in the context of this book, is not to save money, not even because such services will be provided more humanely and efficiently by neighborhoods (though we believe that generally to be the case), but because this is one of the best ways to multiply the valued places that people can fill. As the chapter continues, we will offer some other possibilities for accomplishing this and collateral objectives. But before arguing about how it is to be done, we hope that there can be wide agreement on the importance of the goal: In a decent postindustrial society, neighborhoods shall not have lost their importance as a source of human satisfactions and as a generator of valued places that all sorts of people can fill. Government policy can do much to foster the vitality of neighborhoods by trying to do less for them.</em></p>
<ul>
<li>Page 635 (location ~ 9732-9756)</li>
</ul>
<p><em>As the cognitive elite busily goes about making the world a better place, it is not so important to them that they are complicating ordinary lives. It’s not so complicated to them. The same burden of complications that are only a nuisance to people who are smart are much more of a barrier to people who are not. In many cases, such barriers effectively block off avenues for people who are not cognitively equipped to struggle through the bureaucracy. In other cases, they reduce the margin of success so much that they make the difference between success and failure. “Sweat equity,” though the phrase itself has been recently coined, is as distinctively an American concept as “equality before the law” and “liberty.” You could get ahead by plain hard work. No one would stand in your way. Today that is no longer true. American society has erected barriers to individual sweat equity, by saying, in effect, “Only people who are good at navigating complex rules need apply.” Anyone who has tried to open or run a small business in recent years can supply evidence of how formidable those barriers have become.</em></p>
<ul>
<li>Page 638 (location ~ 9772-9780)</li>
</ul>
<p><em>CRIME. Imagine living in a society where the rules about crime are simple and the consequences are equally simple. “Crime” consists of a few obviously wrong acts: assault, rape, murder, robbery, theft, trespass, destruction of another’s property, fraud. Someone who commits a crime is probably caught—and almost certainly punished. The punishment almost certainly hurts (it is meaningful). Punishment follows arrest quickly, within a matter of days or weeks. The members of the society subscribe to the underlying codes of conduct with enthusiasm and near unanimity. They teach and enforce them whenever appropriate. Living in such a world, the moral compass shows simple, easily understood directions. North is north, south is south, right is right, wrong is wrong. Now imagine that all the rules are made more complicated. The number of acts defined as crimes has multiplied, so that many things that are crimes are not nearly as obviously “wrong” as something like robbery or assault. The link between moral transgression and committing crime is made harder to understand. Fewer crimes lead to an arrest. Fewer arrests lead to prosecution. Many times, the prosecutions are not for something the accused person did but for an offense that the defense lawyer and the prosecutor agreed upon. Many times, people who are prosecuted are let off, though everyone (including the accused) acknowledges that the person was guilty. When people are convicted, the consequences have no apparent connection to how much harm they have done. These events are typically spread out over months and sometimes years. To top it all off, even the “wrongness” of the basic crimes is called into question. In the society at large (and translated onto the television and movie screens), it is commonly argued that robbery, for example, is not always wrong if it is in a good cause (stealing medicine to save a dying wife) or if it is in response to some external condition (exploitation, racism, etc.). At every level, it becomes fashionable to point out the complexities of moral decisions, and all the ways in</em></p>
<ul>
<li>Page 640 (location ~ 9799-9813)</li>
</ul>
<p><em>Our policy prescription in this instance is to return marriage to its formerly unique legal status. If you are married, you take on obligations. If you are not married, you don’t. In particular, we urge that marriage once again become the sole legal institution through which rights and responsibilities regarding children are exercised. If you are an unmarried mother, you have no legal basis for demanding that the father of the child provide support. If you are an unmarried father, you have no legal standing regarding the child—not even a right to see the child, let alone any basis honored by society for claiming he or she is “yours” or that you are a “father.” We do not expect such changes miraculously to resuscitate marriage in the lowest cognitive classes, but they are a step in the return to a simpler valuation of it. A family is unique and highly desirable. To start one, you have to get married. The role of the state in restoring the rewards of marriage is to validate once again the rewards that marriage naturally carries with it.</em></p>
<ul>
<li>Page 642 (location ~ 9843-9850)</li>
</ul>
<p><em>Policy is usually complicated because it has been built incrementally through a political process, not because it has needed to become more complicated. The time has come to make simplification a top priority in reforming policy—not for a handful of regulations but across the board. More broadly, we urge that it is possible once again to make a core of common law, combined with the original concepts of negligence and liability in tort law, the mechanism for running society—easily understood by all and a basis for the straightforward lessons that parents at all levels of cognitive ability above the lowest can teach their children about how to behave as they grow up. We readily acknowledge that modernity requires some amplifications of this simple mechanism, but the nation needs to think through those amplifications from the legal equivalent of zero-based budgeting. As matters stand, the legal edifice has become a labyrinth that only the rich and the smart can navigate.</em></p>
<ul>
<li>Page 643 (location ~ 9855-9862)</li>
</ul>
<p><em>We are silent partly because we are as apprehensive as most other people about what might happen when a government decides to social-engineer who has babies and who doesn’t. We can imagine no recommendation for using the government to manipulate fertility that does not have dangers. But this highlights the problem: The United States already has policies that inadvertently social-engineer who has babies, and it is encouraging the wrong women. If the United States did as much to encourage high-IQ women to have babies as it now does to encourage low-IQ women, it would rightly be described as engaging in aggressive manipulation of fertility. The technically precise description of America’s fertility policy is that it subsidizes births among poor women, who are also disproportionately at the low end of the intelligence distribution. We urge generally that these policies, represented by the extensive network of cash and services for low-income women who have babies, be ended. The government should stop subsidizing births to anyone, rich or poor. The other generic recommendation, as close to harmless as any government program we can imagine, is to make it easy for women to make good on their prior decision not to get pregnant by making available birth control mechanisms that are increasingly flexible, foolproof, inexpensive, and safe.</em></p>
<ul>
<li>Page 646 (location ~ 9896-9905)</li>
</ul>
<p><em>Our third answer has gone to specific issues in raising the cognitive functioning of the disadvantaged (Chapter 17) and in improving education for all (Chapter 18). Part of our answer has been cautionary: Much of public policy toward the disadvantaged starts from the premise that interventions can make up for genetic or environmental disadvantages, and that premise is overly optimistic. Part of our answer has been positive: Much can and should be done to improve education, especially for those who have the greatest potential. Our fourth answer has been that group differences in cognitive ability, so desperately denied for so long, can best be handled—can only be handled—by a return to individualism. A person should not be judged as a member of a group but as an individual. With that cornerstone of the American doctrine once again in place, group differences can take their appropriately insignificant place in affecting American life. But until that</em></p>
<ul>
<li>Page 648 (location ~ 9925-9932)</li>
</ul>
<p><em>Our third answer has gone to specific issues in raising the cognitive functioning of the disadvantaged (Chapter 17) and in improving education for all (Chapter 18). Part of our answer has been cautionary: Much of public policy toward the disadvantaged starts from the premise that interventions can make up for genetic or environmental disadvantages, and that premise is overly optimistic. Part of our answer has been positive: Much can and should be done to improve education, especially for those who have the greatest potential. Our fourth answer has been that group differences in cognitive ability, so desperately denied for so long, can best be handled—can only be handled—by a return to individualism. A person should not be judged as a member of a group but as an individual. With that cornerstone of the American doctrine once again in place, group differences can take their appropriately insignificant place in affecting American life. But until that cornerstone is once again in place, the anger, the hurt, and the animosities will continue to grow.</em></p>
<ul>
<li>Page 648 (location ~ 9925-9933)</li>
</ul>
<p><em>Cognitive partitioning will continue. It cannot be stopped, because the forces driving it cannot be stopped. But America can choose to preserve a society in which every citizen has access to the central satisfactions of life. Its people can, through an interweaving of choice and responsibility, create valued places for themselves in their worlds. They can live in communities—urban or rural—where being a good parent, a good neighbor, and a good friend will give their lives purpose and meaning. They can weave the most crucial safety nets together, so that their mistakes and misfortunes are mitigated and withstood with a little help from their friends. All of these good things are available now to those who are smart enough or rich enough—if they can exploit the complex rules to their advantage, buy their way out of the social institutions that no longer function, and have access to the rich human interconnections that are growing, not diminishing, for the cognitively fortunate. We are calling upon our readers, so heavily concentrated among those who fit that description, to recognize the ways in which public policy has come to deny those good things to those who are not smart enough and rich enough.</em></p>
<ul>
<li>Page 649 (location ~ 9942-9950)</li>
</ul>
<p><em>Inequality of endowments, including intelligence, is a reality. Trying to pretend that inequality does not really exist has led to disaster. Trying to eradicate inequality with artificially manufactured outcomes has led to disaster. It is time for America once again to try living with inequality, as life is lived: understanding that each human being has strengths and weaknesses, qualities we admire and qualities we do not admire, competencies and incompetences, assets and debits; that the success of each human life is not measured externally but internally; that of all the rewards we can confer on each other, the most precious is a place as a valued fellow citizen.</em></p>
<ul>
<li>Page 650 (location ~ 9954-9959)</li>
</ul>



        <div class="footer">
   <div class = 'row' style='text-align:center;'><a href = "/privacy">Terms and Privacy</a>&nbsp;-&nbsp;<a href = "/tags">Index</a></div>
   <div class = 'row' style='text-align:center;'><em>â€œThe difference between a flower and a weed is judgement.â€</em> â€“ Unknown</div>
   
   </br>
   
   
</div>
    </div>
  </body>
</html>
